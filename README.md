# Price_Forecasting
# LG-Demand_Forecasting [(Link)](https://dacon.io/competitions/official/236381/leaderboard)
# 인기상 [(Link)](https://dacon.io/competitions/official/236417/leaderboard)

## 🏆 Result
## **Public score 1st** 0.08605 | **Private score 1st** 0.07665 | 최종 1등

<img width="100%" src="https://github.com/user-attachments/assets/51ed525a-5ab5-439a-8086-cc0ac25b2eca"/>
주최 : ```디지털플랫폼정부위원회, 농림축산식품부```

규모 : 총 1500여명 참가
  

  
## 🧐 About
국민생활과 밀접한 10개 농산물 품목의 가격 예측
(배추, 무, 양파, 사과, 배, 건고추, 깐마늘, 감자, 대파, 상추)
  
## [대회 방식]
### 본 경진대회는 1차 예선, 2차 예선 그리고 본선으로 진행

### ```1차 예선``` : Private 리더보드 상위 20팀이 2차 예선에 진출(평가 산식 : NMAE)  
[문제 상세 설명]  
1) 학습 데이터는 2018년 ~ 2021년의 순 단위(10일)의 데이터가 주어지며,  

2) 평가 데이터는 추론 시점 T가 비식별화된 2022년의 순 단위의 데이터가 주어집니다.  

3) 평가 데이터 추론은 추론 시점 T 기준으로 최대 3개월의 순 단위의 입력 데이터를 바탕으로 T+1순, T+2순, T+3순의 평균가격을 예측해야합니다.  


### ```2차 예선``` : 별도의 대회 페이지에서 진행하고 추가된 데이터가 제공되며, 2차 예선의 Private 리더보드 점수와 추가 평가 점수를 합산한 점수 상위 10팀이 본선에 진출(평가 산식 : Weighted NMAE + 추론 시간)  
[문제 상세 설명]  
1) 학습 데이터는 2018년 ~ 2022년의 순 단위(10일)의 데이터가 주어지며,  

2) 평가 데이터는 식별화된 추론 시점 T가 2023년 ~ 2024년의 순 단위의 데이터가 주어집니다.  

3) 평가 데이터 추론은 추론 시점 T 기준으로 최대 3개월의 순 단위의 입력 데이터를 바탕으로 T+1순, T+2순, T+3순의 평균가격을 예측해야합니다.  


### ```본선``` : 오프라인 발표 평가를 통해 최종 수상자가 선정(평가 : 발표평가 50%(EDA, 모델링, 모델 활용)+ 정량평가 50%(2차 예선 최종 환산 점수))  
[본선 산출물]  

1) 결과보고서(모델링) 자료 : 2차 예선 대회에서 개발한 AI 모델의 결과보고서 작성  

2) 발표 자료 : 작성한 결과보고서를 바탕으로 평가 항목에 따른 발표 자료 작성  


## 🔥**대회 접근법 및 배운점**

### ```1차 예선```

1. 농산물 데이터를 통합하여 모델링할지, 아니면 각 품목별로 개별 모델링을 할지  
2. 동일한 품목명 아래 **여러 품종명(예: 감자의 수미, 대지 품종 등)**이 존재할 때, 이 데이터를 어떻게 활용할지  
3. 예측에 사용할 모델로 시계열 모델과 머신러닝 모델 중 어느 것이 더 적합할지  



1) 먼저, 모든 농산물을 하나의 통합 모델로 학습할지, 아니면 품목별로 개별 모델링할지를 결정하기 위해 고민했습니다. 이때 각 농산물이 유사한 추세, 계절성, 분포를 보인다면 통합 모델링이 적합할 수 있습니다. 통합 모델은 데이터를 더 많이 활용할 수 있어 일반화 성능이 높아지는 장점이 있기 때문입니다. 그러나, 실제 EDA를 통해 분석한 결과, 농산물마다 고유한 계절성 패턴과 가격 변동 특성이 다르게 나타났습니다. 예를 들어, 배추는 김장철에 가격이 급등하는 반면, 감자는 여름철 기후에 더 민감한 반응을 보였습니다.  

이러한 품목별 특성의 차이를 무시하고 통합 모델링을 진행할 경우, 고유한 패턴을 제대로 반영하지 못해 오히려 예측의 정확도가 떨어지고 노이즈가 증가할 가능성이 높습니다. 특히, 한 품목에서의 계절적 급등 현상이 다른 품목에는 존재하지 않기 때문에, 이러한 특이점이 통합 모델에서는 혼란을 줄 수 있습니다.  

따라서, 시간에 따른 가격 변동 EDA 결과를 바탕으로, 농산물의 특성을 반영하기 위해 품목별 모델링을 선택했습니다. 이는 각 품목의 고유한 패턴을 효과적으로 학습하고, 예측 성능을 높이는 데 도움이 되었습니다.  


2) 동일 품목명이라도 여러 품종이 존재(예: 감자의 '수미', '대지' 품종)하는 경우, 이 데이터를 학습에 어떻게 활용할지에 대해 고민했습니다. 먼저, 동일 품목 내에서는 유사한 추세, 계절성, 분포를 보일 것이라는 가정을 세웠습니다. 그 이유는, 같은 품목에 속하는 품종들은 비슷한 재배 환경과 수확 시기를 가지기 때문에, 가격 변동 패턴에서도 공통적인 특성이 나타날 가능성이 높기 때문입니다. 예를 들어, '수미'와 '대지' 감자는 재배 및 유통 과정에서 계절성 영향을 유사하게 받습니다.  

이 가정을 검증하기 위해, UMAP 분석과 시간에 따른 가격 변동 EDA를 수행했습니다. UMAP 분석을 통해 품종별 가격 변동 패턴을 시각화한 결과, 동일 품목 내의 품종들은 비슷한 군집을 형성하는 경향이 있음을 확인했습니다. 또한, 시간에 따른 EDA에서도 동일 품목 내 품종들 간의 계절성 패턴과 가격 변동이 유사하게 나타났습니다.  

따라서, 동일 품목명 내의 다른 품종명들은 하나의 모델에서 다변량 데이터로 학습시키는 것이 적합하다고 판단했습니다. 이를 통해 모델은 품종별로 미세한 차이를 반영하면서도, 공통적인 패턴을 학습할 수 있도록 하였고, 이 접근법을 통해 데이터의 양을 증가시켜 모델의 일반화 성능을 높이도록 의도했습니다.   

3) "모델링 접근에서는 머신러닝 모델과 시계열 딥러닝 모델 중 어떤 것을 사용할지 고민했습니다. 먼저, 머신러닝 모델을 선택한 이유는 비선형 관계 학습과 다양한 파생 변수의 활용이 가능하기 때문입니다. 농산물 가격은 기후, 경제적 요인, 외부 개입 등 다양한 비선형적 영향을 받기 때문에, 이를 반영하기 위해 머신러닝 모델(LGBM)을 사용했습니다. 반면, 시계열 딥러닝 모델은 최근의 시간적 흐름과 계절성 패턴을 학습하기에 유리해, 단기 예측의 정확도를 높이기 위해 사용했습니다.  

머신러닝 모델에서는 시계열 데이터를 다루는 방식에 대해 추가적인 고민이 필요했습니다. 이를 위해 3가지 방법을 고려했습니다:  

1) 시계열 데이터를 시점에 맞게 입력하는 방법:  

각 시점의 데이터를 그대로 사용해 현재 시점의 예측에 활용했습니다. 이 방법은 간단하면서도 시점별 독립적인 피처를 반영할 수 있는 장점이 있습니다.  

2) 이전 시점 데이터를 Transpose하여 피처로 활용하는 방법:  

과거 데이터를 Transpose(전치)하여 현재 시점의 피처로 추가했습니다. 이를 통해 시간적 흐름과 과거 패턴을 반영할 수 있으며, 시계열 데이터를 피처 형식으로 변환해 머신러닝 모델의 학습 성능을 높일 수 있었습니다.  

3) 다변량 형식으로 다른 품종명들의 가격을 포함시키는 방법:  

동일 품목 내의 다른 품종명 데이터를 다변량 형식으로 함께 입력했습니다. 이를 통해 다양한 품종 간의 상호 관계를 학습할 수 있었으며, 특히 비슷한 계절성 패턴을 가진 품종들의 데이터를 함께 사용함으로써 모델의 예측 정확도를 높였습니다.  
각 방법의 장점은 다음과 같습니다:  

1. 첫 번째 방법은 시점별 독립성을 보장하면서, 간단한 구조로 빠른 학습이 가능합니다.  
2. 두 번째 방법은 시간적 패턴을 반영해, 과거의 영향을 효과적으로 학습할 수 있습니다.  
3. 세 번째 방법은 다변량 데이터의 장점을 활용해, 품종 간의 상호작용과 공통적인 패턴을 학습할 수 있어 예측 성능을 향상시켰습니다.  

결과적으로, 시계열 딥러닝 모델은 최근의 시간적 흐름과 계절성을 학습해 단기 예측에 강점을 보였고, 머신러닝 모델은 다양한 비선형 관계를 반영해 장기 예측에서 우수한 성능을 나타냈습니다. 이를 바탕으로, 단기 예측에는 시계열 모델의 가중치를 더 두고, 장기 예측에는 머신러닝 모델의 가중치를 두는 앙상블 전략을 구축하여 최종 예측 성능을 극대화했습니다.  



### ```2차 예선``` 


### ```본선```   




이번 대회는 수요 예측에 대한 Task였습니다.    
데이터는 15900여개의 제품의 2022년1월1일부터 2023년4월25일까지의 실제 일별 판매량과 실제 일별 총 판매금액, 브랜드의 연관키워드 언급량, 제품 특성의 메타 데이터로 구성되어 있었고   
2023년 4월26일~5월14일까지의 총 21일(3주)간의 실제 판매량을 예측하는 대회였습니다.  
실제 train 데이터에는 예측해야 하는 ID별로 제품 코드, 대분류, 중분류, 소분류, 브랜드 정보가 추가적으로 존재하였는데,  
15900여개의 제품들을 대분류, 중분류, 소분류, 브랜드로 나누어서 추세, 주기성, 계절성과 같은 시계열성 정보를 확인해보니, 직관적으로 알기가 힘들었습니다.  
그래서 퓨리에 변환,Hierarchical Clustering, 유클리드 거리, cosine similarity 등으로 유사한 시계열성 정보를 가진 ID들을 분류하려 했지만,   
ID별로 워낙 판매량이 다 달라서 분류를 할 수 없었습니다.   
그래서 이러한 ID들을 각자 모델에 학습시켜 총 15900개의 모델을 만드는 것이,  
정확한 예측을 할 수 있지 않을까? 라는 생각이 들었습니다.  
하지만 15900개의 딥러닝 모델을 만드는 것은 시간이 오래걸리기 때문에,  
최근 트랜스포머의 정확도에 의문을 가지며 등장한 LSTF Linear 모델들을 활용해보았습니다. (LSTF Linear, DLinear, NLinear)  
하지만 ID들을 따로 따로 학습시켰을 때 정확도가 많이 올라가지 않았습니다.  
그 이유가 무엇일까 하며 계속해서 EDA를 해 보았고, 판매량이 0일 때의 시점들에 주목하였습니다.  
판매량이 0으로 라벨링이 되어있는 시점은, 실제로 팔리지 않았거나 수요가 있지만 공급이 되지 않을 때를 의미하기 때문에,  
이러한 정보를 잘 살려야 하지 않을까 생각을 하였고, 0의 값을 impuation 하는 방법으로 접근을 하였습니다.  
처음에는 모든 0의 값을 수요가 있지만 공급이 되지 않을 때로 가정하는 것은,  
위험한 가정이라 생각을 하여 2022/01/01부터 2023/04/04 까지의 날짜 중 70%이하의 날이 0으로 구성되어야 수요가 있지만 공급이 되지 않을 때로 가정하였습니다.  
그렇게 70%의 제품들을 필터링 후 0의 값들을 interpolate하여 선형 및 ffill, bfill로 값을 채워주었더니, ```모델의 예측 정확도가 크게 상승```하였습니다.  
나의 가설이 맞아 떨어져서 정말 기분이 좋았던 순간이었고 팀장으로서의 역할을 제대로 하고 있는 것 같아 뿌듯했습니다.  
이제 ```나의 imputation 방법을 develope 시키는 방법에 대해서 고민하였는데, 정확도를 평가하는 평가산식을 활용```을 하였습니다.  
이 TASK의 평가산식은 PSFA로 대분류 별 Pseudo 예측 정확도의 평균이었습니다. 어떻게 활용했는지를 설명하기 전, PSFA에 대해서 간단히 설명을 하자면  

PSFA"라는 지표는 우리가 예측한 판매량이 얼마나 정확한지를 측정하기 위한 도구로 이 지표는 크게 두 부분으로 나뉘는데, 예시를 들어서 이해하기 쉽게 설명을 하면  

대분류별 Pseudo 예측 정확도 (PSFA Am) :  
상품을 일정한 기준에 따라 여러 그룹으로 나눕니다. 예를 들어, 과일, 야채, 음료 등으로 나눌 수 있습니다.  
각 그룹 내에서 하루하루 얼마나 팔렸는지와 얼마나 팔릴 것이라고 예측했는지를 비교합니다.  
예를 들어, 사과가 하루에 100개 팔렸다고 해봅시다. 만약 우리 예측이 110개라면, 그 차이는 작은 편입니다. 하지만 예측이 200개라면, 그 차이는 큰 편이죠.  
이 차이를 각 상품과 날짜별로 계산해서, 그룹 전체의 평균 차이를 구합니다.  
전체 Pseudo 예측 정확도 (PSFA)  
이제 모든 그룹 (과일, 야채, 음료 등)에 대해 계산한 평균 차이를 하나로 합쳐 전체적인 예측의 정확도를 측정합니다.  
이 지표는 '어느 상품이나 날짜에서 예측이 얼마나 빗나갔는지'를 알려주는 평가지표이고,  
더 나아가, 많이 팔린 상품에서의 예측 오차는 덜 팔린 상품에서의 예측 오차보다 더 중요하게 취급 됩니다.  
왜냐하면 많이 팔린 상품이 비즈니스에 더 큰 영향을 미치기 때문이라고 생각할 수 있기 때문입니다.  
이 평가 지표에 따르면 만약 실제 판매량이 0이 되면 오차가 (∣0−p∣) / (max(0,p)) 되는데, 이때 예측값이 100이든 100000이든 평가지표에는 영향을 끼치지 않습니다.  
그렇기 때문에 이 전에 수행했던 imputation에서의 필터링이 과연 의미가 있을까? 라는 의문이 들기 시작하였고,  
train데이터 기간에 0이 엄청 많이 나온 ID들은 실제 판매량도 0이 될 가능성이 높고 모델도 실제로 0의 값으로 많이 예측을 할텐데,  
평가지표에 의해 수요가 있지만 공급이 없는 경우보다, 공급이 더 중요한 평가지표라 판단이 되어.   
미리 수요에 대한 공급을 준비해 주기 위해 0이 아닌 이 값들을 train 기간의 0을 제외한 중앙값으로 대체를 해 주었습니다.   
중앙값으로 대체한 이유는 할인 기간같은 특별 세일 기간에 판매량이 엄청나게 증가하는 경우가 있어, 평균으로 하면 안될 것 같아 0을 제외한 중앙값을 사용하였습니다.  

마지막으로 예측값들에 대한 강건함을 늘리기 위해, 예측값들의 평균으로 21일간의 값을 치환해주엇습니다.  

이러한 모델링으로 강건한 결과를 가져왔습니다.  
  
이러한 경험을 통해, ```개개인에 대한 세부적인 데이터 분석이 불가능할 때, 어떻게 접근해야 할 지와 평가지표를 어떻게 이해해서 모델링에 적용시킬 지에 대해서 깨달```았습니다.  
... 


---

## 📖 Dataset
```

Dataset Info.

1. 학습(Train) 데이터셋 (39607개)
ID : 실제 판매되고 있는 고유 ID
제품 : 제품 코드
대분류 : 제품의 대분류 코드
중분류 : 제품의 중분류 코드
소분류 : 제품의 소분류 코드
브랜드 : 제품의 브랜드 코드
쇼핑몰 : 쇼핑몰 코드
2022-01-01 ~ 2023-04-24 : 실제 일별 판매량
단, 제품이 동일하여도 판매되고 있는 고유 ID 별로 기재한 분류 정보가 상이할 수 있음
즉 고유 ID가 다르다면, 제품이 같더라도 다른 판매 채널

2. sales.csv - 메타(Meta) 정보
ID : 실제 판매되고 있는 고유 ID
제품 : 제품 코드
대분류 : 제품의 대분류 코드
중분류 : 제품의 중분류 코드
소분류 : 제품의 소분류 코드
브랜드 : 제품의 브랜드 코드
쇼핑몰 : 쇼핑몰 코드
2022-01-01 ~ 2023-04-24 : 실제 일별 총 판매금액
단, 제품이 동일하여도 판매되고 있는 고유 ID 별로 기재한 분류 정보가 상이할 수 있음
즉 고유 ID가 다르다면, 제품이 같더라도 다른 판매 채널


3. brand_keyword_cnt.csv - 메타(Meta) 정보
브랜드 : 브랜드 코드
2022-01-01 ~ 2023-04-24 : 브랜드의 연관키워드 언급량을 정규화한 일별 데이터


4. product_info.csv - 메타(Meta) 정보
제품 : 제품 코드
제품특성 : 제품 특성 데이터(Text)
train.csv에 존재하는 모든 제품 코드가 포함되어 있지 않음. 또는 product_info.csv에 존재하는 제품 코드가 train.csv에 존재하지 않을 수 있음


```


## 🔧 Feature Engineering
```

* Custom Imputation

* Custom Post Processing

```

## 🎈 Modeling

**Predict Model**
```
LSTF-Linear
LSTM
```
