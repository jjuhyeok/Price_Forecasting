# Price_Forecasting
# LG-Demand_Forecasting [(Link)](https://dacon.io/competitions/official/236381/leaderboard)
# 인기상 [(Link)](https://dacon.io/competitions/official/236417/leaderboard)

## 🏆 Result
## **Public score 1st** 0.08605 | **Private score 1st** 0.07665 | 최종 1등

<img width="100%" src="https://github.com/user-attachments/assets/51ed525a-5ab5-439a-8086-cc0ac25b2eca"/>
주최 : ``` 디지털플랫폼정부위원회, 농림축산식품부 ```

규모 : 총 1500여명 참가
  

  
## 🧐 About
국민생활과 밀접한 10개 농산물 품목의 가격 예측
(배추, 무, 양파, 사과, 배, 건고추, 깐마늘, 감자, 대파, 상추)
  
## [대회 방식]
### 본 경진대회는 1차 예선, 2차 예선 그리고 본선으로 진행

### 1차 예선 : Private 리더보드 상위 20팀이 2차 예선에 진출

### 2차 예선 : 별도의 대회 페이지에서 진행하고 추가된 데이터가 제공되며, 2차 예선의 Private 리더보드 점수와 추가 평가 점수를 합산한 점수 상위 10팀이 본선에 진출

### 본선은 오프라인 발표 평가를 통해 최종 수상자가 선정


### ```LG Aimers 1```  
1년전 LG Aimers를 통해서 첫 인공지능 대회의 경험을 하였고,   
처음엔 열심히 배우고 성장하자고 팀을 빌딩하여 시작하였지만,   
점점 순위가 오르더니 결국 전체 리더보드 1등으로 마무리 했던 그 시간은 아직도 생생히 기억에 남습니다.   
코드 검증을 통과한 후, 수상을 위해 남은 단계인 발표 평가를 준비하기 위해 몇주간의 시간이 주어졌었고   
나는 팀장으로서 어떻게든 발표에서 뷰족한 모습을 보여주고 싶지 않아,   
스스로 책도 여러권 사며 밤을 새며 발표 준비를 했었었습니다.   
그렇게 발표도 마치고, 팀원들도 발표를 잘했다며 칭찬을 해주셨습니다.   
또한 LG 이노텍의 심사위원분께서 칼만필터를 사용한 근거와 활용에 대해서 칭찬을 많이 해주신 부분에 대해서   
그때만 생각한다면 노력의 보상을 받은 것 같아 아직도 기분이 좋습니다.   
그리고 최종 수상 발표까지 하루하루를 기대하며 기다리고 있었는데,   
최종 수상 발표 하루 전날 갑작스럽게 실격 통보를 받았습니다.   
이동 평균을 사용하였기 때문입니다.   
사용한 이유와 그 외의 부분은 LG AI_RAIDAR 링크를 봐주시면 좋을 것 같습니다.  
기대가 정말 컸던 만큼, 갑작스러운 실격에 대한 멘탈의 타격도 컸습니다.  
하지만 그만큼 다음 LG 대회에는 무조건 우승을 할 것이라고 다짐 또 다짐을 하였습니다.  

### ```LG Aimers 2``` 
반년을 기다린 후 드디어 LG 대회가 시작되었습니다.   
이번엔 정말 우승을 위해서, 대회 기간 전까지 다른 여러 AI 대회에 참여하며   
좋은 성적 및 수상들을 하며 정말 열심히 준비했습니다.   
이번 기수부터는 코로나 영향을 받지 않아서인지 온라인과 오프라인 대회 2번으로 나누어서 진행되었습니다.   
온라인 대회에서 좋은 성적을 거둔 한정된 인원만 오프라인 대회에 진출하게 되는데,   
온라인 대회에서 열심히 하여, 오프라인 대회에 진출하게 되었습니다.   
온라인 대회에서 팀장으로서 2번의 큰 결정을 했어야 했는데  
2번의 큰 결정은 LG Smart_Factory 링크를 봐주시면 좋을 것 같습니다.  
결론적으로 최종 5팀까지 할 수 있는 발표평가까지 올라가서  
발표평가에서 최종수상까지는 하지 못하였습니다.  
그래서 그 소식을 들은 후 LG 인화원에서 집까지 가는 길에 너무나 아쉽고 힘들었습니다.  
하지만 후회한다고 해도 결과는 바뀌지 않고,   
빨리 털고 일어나 더 열심히 노력해서 다음 LG 대회에선 꼭 우승할거라는 다짐을 한번 더 하게 되었습니다..  


### ```LG Aimers 3```   
이번 대회엔 무조건 우승할거야! 라는 포부를 안고 또 다시 LG 대회를 시작하였습니다.     
이번 대회는 1,2 와는 다르게 초반에는 모델 예측 성능 고도화에 문제를 많이 겪었습니다.  
하지만 결국 끝없는 EDA를 통해 성능 고도화 및 Stable 방법을 찾았습니다.  
이 방법은 데이터와, 가설, 평가 수식, 모델 특징을 모두 융합한 방법으로 밑에서 자세히 설명드리겠습니다.  
또한 LG Aimers 2에서 겪었던, PPT 문제에 대해  
이번 대회에서는 같은 일이 발생하지 않게, 특정 팀원분에게 PPT에 관련한 대부분의 물리적 작업을 맡겼고   
그 결과 2기에 비해 PPT 통일성 및 완성도가 매우 뛰어났습니다.    
그렇게 드디어 1년간 갈망하던  
**우승**을 하게 되었습니다..!  
정말 어느 순간보다 기쁘고 행복했던 순간이었습니다.  

## 🔥**대회 접근법 및 배운점**

이번 대회는 수요 예측에 대한 Task였습니다.    
데이터는 15900여개의 제품의 2022년1월1일부터 2023년4월25일까지의 실제 일별 판매량과 실제 일별 총 판매금액, 브랜드의 연관키워드 언급량, 제품 특성의 메타 데이터로 구성되어 있었고   
2023년 4월26일~5월14일까지의 총 21일(3주)간의 실제 판매량을 예측하는 대회였습니다.  
실제 train 데이터에는 예측해야 하는 ID별로 제품 코드, 대분류, 중분류, 소분류, 브랜드 정보가 추가적으로 존재하였는데,  
15900여개의 제품들을 대분류, 중분류, 소분류, 브랜드로 나누어서 추세, 주기성, 계절성과 같은 시계열성 정보를 확인해보니, 직관적으로 알기가 힘들었습니다.  
그래서 퓨리에 변환,Hierarchical Clustering, 유클리드 거리, cosine similarity 등으로 유사한 시계열성 정보를 가진 ID들을 분류하려 했지만,   
ID별로 워낙 판매량이 다 달라서 분류를 할 수 없었습니다.   
그래서 이러한 ID들을 각자 모델에 학습시켜 총 15900개의 모델을 만드는 것이,  
정확한 예측을 할 수 있지 않을까? 라는 생각이 들었습니다.  
하지만 15900개의 딥러닝 모델을 만드는 것은 시간이 오래걸리기 때문에,  
최근 트랜스포머의 정확도에 의문을 가지며 등장한 LSTF Linear 모델들을 활용해보았습니다. (LSTF Linear, DLinear, NLinear)  
하지만 ID들을 따로 따로 학습시켰을 때 정확도가 많이 올라가지 않았습니다.  
그 이유가 무엇일까 하며 계속해서 EDA를 해 보았고, 판매량이 0일 때의 시점들에 주목하였습니다.  
판매량이 0으로 라벨링이 되어있는 시점은, 실제로 팔리지 않았거나 수요가 있지만 공급이 되지 않을 때를 의미하기 때문에,  
이러한 정보를 잘 살려야 하지 않을까 생각을 하였고, 0의 값을 impuation 하는 방법으로 접근을 하였습니다.  
처음에는 모든 0의 값을 수요가 있지만 공급이 되지 않을 때로 가정하는 것은,  
위험한 가정이라 생각을 하여 2022/01/01부터 2023/04/04 까지의 날짜 중 70%이하의 날이 0으로 구성되어야 수요가 있지만 공급이 되지 않을 때로 가정하였습니다.  
그렇게 70%의 제품들을 필터링 후 0의 값들을 interpolate하여 선형 및 ffill, bfill로 값을 채워주었더니, ```모델의 예측 정확도가 크게 상승```하였습니다.  
나의 가설이 맞아 떨어져서 정말 기분이 좋았던 순간이었고 팀장으로서의 역할을 제대로 하고 있는 것 같아 뿌듯했습니다.  
이제 ```나의 imputation 방법을 develope 시키는 방법에 대해서 고민하였는데, 정확도를 평가하는 평가산식을 활용```을 하였습니다.  
이 TASK의 평가산식은 PSFA로 대분류 별 Pseudo 예측 정확도의 평균이었습니다. 어떻게 활용했는지를 설명하기 전, PSFA에 대해서 간단히 설명을 하자면  

PSFA"라는 지표는 우리가 예측한 판매량이 얼마나 정확한지를 측정하기 위한 도구로 이 지표는 크게 두 부분으로 나뉘는데, 예시를 들어서 이해하기 쉽게 설명을 하면  

대분류별 Pseudo 예측 정확도 (PSFA Am) :  
상품을 일정한 기준에 따라 여러 그룹으로 나눕니다. 예를 들어, 과일, 야채, 음료 등으로 나눌 수 있습니다.  
각 그룹 내에서 하루하루 얼마나 팔렸는지와 얼마나 팔릴 것이라고 예측했는지를 비교합니다.  
예를 들어, 사과가 하루에 100개 팔렸다고 해봅시다. 만약 우리 예측이 110개라면, 그 차이는 작은 편입니다. 하지만 예측이 200개라면, 그 차이는 큰 편이죠.  
이 차이를 각 상품과 날짜별로 계산해서, 그룹 전체의 평균 차이를 구합니다.  
전체 Pseudo 예측 정확도 (PSFA)  
이제 모든 그룹 (과일, 야채, 음료 등)에 대해 계산한 평균 차이를 하나로 합쳐 전체적인 예측의 정확도를 측정합니다.  
이 지표는 '어느 상품이나 날짜에서 예측이 얼마나 빗나갔는지'를 알려주는 평가지표이고,  
더 나아가, 많이 팔린 상품에서의 예측 오차는 덜 팔린 상품에서의 예측 오차보다 더 중요하게 취급 됩니다.  
왜냐하면 많이 팔린 상품이 비즈니스에 더 큰 영향을 미치기 때문이라고 생각할 수 있기 때문입니다.  
이 평가 지표에 따르면 만약 실제 판매량이 0이 되면 오차가 (∣0−p∣) / (max(0,p)) 되는데, 이때 예측값이 100이든 100000이든 평가지표에는 영향을 끼치지 않습니다.  
그렇기 때문에 이 전에 수행했던 imputation에서의 필터링이 과연 의미가 있을까? 라는 의문이 들기 시작하였고,  
train데이터 기간에 0이 엄청 많이 나온 ID들은 실제 판매량도 0이 될 가능성이 높고 모델도 실제로 0의 값으로 많이 예측을 할텐데,  
평가지표에 의해 수요가 있지만 공급이 없는 경우보다, 공급이 더 중요한 평가지표라 판단이 되어.   
미리 수요에 대한 공급을 준비해 주기 위해 0이 아닌 이 값들을 train 기간의 0을 제외한 중앙값으로 대체를 해 주었습니다.   
중앙값으로 대체한 이유는 할인 기간같은 특별 세일 기간에 판매량이 엄청나게 증가하는 경우가 있어, 평균으로 하면 안될 것 같아 0을 제외한 중앙값을 사용하였습니다.  

마지막으로 예측값들에 대한 강건함을 늘리기 위해, 예측값들의 평균으로 21일간의 값을 치환해주엇습니다.  

이러한 모델링으로 강건한 결과를 가져왔습니다.  
  
이러한 경험을 통해, ```개개인에 대한 세부적인 데이터 분석이 불가능할 때, 어떻게 접근해야 할 지와 평가지표를 어떻게 이해해서 모델링에 적용시킬 지에 대해서 깨달```았습니다.  
... 


---

## 📖 Dataset
```

Dataset Info.

1. 학습(Train) 데이터셋 (39607개)
ID : 실제 판매되고 있는 고유 ID
제품 : 제품 코드
대분류 : 제품의 대분류 코드
중분류 : 제품의 중분류 코드
소분류 : 제품의 소분류 코드
브랜드 : 제품의 브랜드 코드
쇼핑몰 : 쇼핑몰 코드
2022-01-01 ~ 2023-04-24 : 실제 일별 판매량
단, 제품이 동일하여도 판매되고 있는 고유 ID 별로 기재한 분류 정보가 상이할 수 있음
즉 고유 ID가 다르다면, 제품이 같더라도 다른 판매 채널

2. sales.csv - 메타(Meta) 정보
ID : 실제 판매되고 있는 고유 ID
제품 : 제품 코드
대분류 : 제품의 대분류 코드
중분류 : 제품의 중분류 코드
소분류 : 제품의 소분류 코드
브랜드 : 제품의 브랜드 코드
쇼핑몰 : 쇼핑몰 코드
2022-01-01 ~ 2023-04-24 : 실제 일별 총 판매금액
단, 제품이 동일하여도 판매되고 있는 고유 ID 별로 기재한 분류 정보가 상이할 수 있음
즉 고유 ID가 다르다면, 제품이 같더라도 다른 판매 채널


3. brand_keyword_cnt.csv - 메타(Meta) 정보
브랜드 : 브랜드 코드
2022-01-01 ~ 2023-04-24 : 브랜드의 연관키워드 언급량을 정규화한 일별 데이터


4. product_info.csv - 메타(Meta) 정보
제품 : 제품 코드
제품특성 : 제품 특성 데이터(Text)
train.csv에 존재하는 모든 제품 코드가 포함되어 있지 않음. 또는 product_info.csv에 존재하는 제품 코드가 train.csv에 존재하지 않을 수 있음


```


## 🔧 Feature Engineering
```

* Custom Imputation

* Custom Post Processing

```

## 🎈 Modeling

**Predict Model**
```
LSTF-Linear
LSTM
```
