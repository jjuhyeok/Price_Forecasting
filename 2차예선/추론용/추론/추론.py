# -*- coding: utf-8 -*-
"""추론_최적화.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d12KbT-A7zqMUT3hAXfhv1NwUffp7LRx
"""

import pandas as pd
import numpy as np
import os
from FE.common_FE import common_FE
import joblib
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
import warnings
warnings.filterwarnings("ignore")

start = time.time()

"""# preprocessing

## 외부 데이터

### 반입 물량
"""

file_paths = {
    '깐마늘(국산)': '마늘_반입물량.xlsx',
    '무': '무_반입물량.xlsx',
    '배': '배_반입물량.xlsx',
    '배추': '배추_반입물량.xlsx',
    '사과': '사과_반입물량.xlsx',
    '상추': '상추_반입물량.xlsx',
    '양파': '양파_반입물량.xlsx',
    '감자 수미': '감자 수미_반입물량.xlsx',
    '건고추': '건고추_반입물량.xlsx'
}

renamed_dataframes = {}

for item, path in file_paths.items():
    p = '6_감자 수미_반입물량.xlsx_241023/'
    excel_data = pd.ExcelFile(p+path)

    df = excel_data.parse(excel_data.sheet_names[0])

    if 'DATE' in df.columns:
        df.rename(columns={'DATE': 'YYYYMMSOON'}, inplace=True)

    renamed_dataframes[item] = df

for item, df in renamed_dataframes.items():
    csv_file_path = f'6_감자 수미_반입물량.xlsx_241023/{item}_반입물량.csv'
    df.to_csv(csv_file_path, index=False, encoding='CP949')

"""### 확정거래물량"""

file_paths = {
    '깐마늘(국산)': '깐마늘(수입)_확정거래물량.csv',
    '무': '열무_확정거래물량.csv',
    '배': '배_확정거래물량.csv',
    '배추': '배추_확정거래물량.csv',
    '사과': '사과_확정거래물량.csv',
    #'상추': '상추_확정거래물량.csv',
    '양파': '양파_거래확정물량.csv',
    '감자 수미': '감자_확정거래물량.csv',
    '건고추': '고추_거래확정물량.csv',
    '대파(일반)': '대파_확정거래물량.csv'
}

renamed_dataframes = {}

for item, path in file_paths.items():
    #excel_data = pd.ExcelFile(path)
    #df = excel_data.parse(excel_data.sheet_names[0])
    p = '농촌경제연구원/'
    df = pd.read_csv(p+path, encoding = 'cp949')
    # '거래일자' 컬럼 값 변환
    df['YYYYMMSOON'] = df['거래일자'].str.replace('-', '').str.replace('하', '하순').str.replace('중', '중순').str.replace('상', '상순')
    df.drop('거래일자',axis=1, inplace = True)
    if item == '사과':
        df = df[df['품목명'] == '후지']
    # 모든 컬럼에서 결측치가 있으면 인덱스 기준으로 선형 보간
    df = df.interpolate(method='linear')

    renamed_dataframes[item] = df

for item, df in renamed_dataframes.items():
    csv_file_path = f'농촌경제연구원/{item}_확정거래물량.csv'
    df.to_csv(csv_file_path, index=False, encoding='CP949')

"""### 경락정보_전국 도매"""

def create_shifted_features(df, num_shifts=8):
  for col in df.columns.difference(['YYYYMMSOON','시점']):
    for i in range(1, num_shifts + 1):
        df[f'{col}_T-{i}'] = df[col].shift(i)
  return df

file_paths = [f'test/meta/TEST_경락정보_전국도매_{i:02d}.csv' for i in range(52)]

time1 = []
time2 = []
all_data = []
with ThreadPoolExecutor() as executor:
    futures = {
        executor.submit(
            lambda file_path: (
                (data := pd.read_csv(file_path, usecols=['YYYYMMSOON', '품목명', '총반입량(kg)']))
                .groupby(['YYYYMMSOON', '품목명'], as_index=False)['총반입량(kg)']
                .sum()
                .pivot(index='YYYYMMSOON', columns='품목명', values='총반입량(kg)')
                .fillna(pd.NA)
                .reset_index(),
                data['YYYYMMSOON'].max(),
                os.path.basename(file_path).replace('.csv', '').replace('_경락정보_전국도매', '')
            ),
            file_path
        ): file_path for file_path in file_paths}
    for future in as_completed(futures):
        data, origin_T, 시점 = future.result()
        data['시점'] = 시점
        all_data.append(data)
        time1.append(origin_T)
        time2.append(시점)

test_1 = pd.concat(all_data, ignore_index=True)
time_pairs = list(zip(time1, time2))

test_1.drop('순무', axis = 1, inplace = True)
test_1 = test_1.rename(columns={
    'YYYYMMSOON':'YYYYMMSOON',
    "감자": "감자 수미_총반입량",
    "대파": "대파(일반)_총반입량",
    "마늘": "깐마늘(국산)_총반입량",
    "무": "무_총반입량",
    "배": "배_총반입량",
    "배추": "배추_총반입량",
    "사과": "사과_총반입량",
    "상추": "상추_총반입량",
    "양파": "양파_총반입량"})

final_data =  create_shifted_features(test_1)
filtered_df_list = []

for t1, t2 in time_pairs:
    temp_df = final_data[(final_data['YYYYMMSOON'] == t1) & (final_data['시점'] == t2)]
    if not temp_df.empty:
        filtered_df_list.append(temp_df)

if filtered_df_list:
    final_data = pd.concat(filtered_df_list)
else:
    final_data = pd.DataFrame()

final_data = final_data.reset_index(drop = True)
final_data.to_csv('wide_test.csv',index=False, encoding='CP949')

"""### 기상 데이터"""

import pandas as pd
def convert_to_yyyymmsoon(date):
    year_month = date.replace("-", "").replace(" ", "")[:6]
    day = int(date[-2:])  # Extracts 'DD' as an integer

    # Determine '순' based on the day
    if day <= 10:
        soon = "상순"
    elif day <= 20:
        soon = "중순"
    else:
        soon = "하순"

    return f"{year_month}{soon}"

def process_precipitation_data(file_path, encoding='cp949', skiprows=12, max_cols=20, columns=None):
    prefix = file_path.split('/')[-1].split('_')[0]  # 파일 경로 마지막 부분에서 '_' 앞부분 추출

    # 모든 행을 읽으며, 부족한 열은 NaN으로 채우기
    data = pd.read_csv(file_path, encoding=encoding, skiprows=skiprows, names=range(max_cols))

    # 첫 번째 행을 컬럼으로 지정하고 해당 행 삭제
    data.columns = data.loc[0].str.strip()
    data.drop(0, axis=0, inplace=True)

    # 선택한 열만 남기기
    data = data[columns]

    # '일시' 열이 있는 경우 'YYYYMMSOON' 형식으로 변환
    if '일시' in data.columns:
        data['YYYYMMSOON'] = data['일시'].apply(convert_to_yyyymmsoon)
        data.drop('일시', axis=1, inplace=True)

    # 마지막 열을 제외한 나머지 열을 numeric type으로 변환
    cols_to_convert = data.columns[:-1]  # 마지막 열 제외
    data[cols_to_convert] = data[cols_to_convert].apply(pd.to_numeric, errors='coerce')

    data.columns = [f"{prefix}_{col}" if col != 'YYYYMMSOON' else col for col in data.columns]

    # NaN 값을 0으로 채움
    data = data.fillna(0)
    return data

rain = process_precipitation_data('기상데이터/강원영동_강수량.csv',columns = ['일시', '평균일강수량(mm)']).drop('YYYYMMSOON', axis = 1)
temp = process_precipitation_data('기상데이터/강원영동_기온.csv', columns = ['일시', '평균기온(℃)']).drop('YYYYMMSOON', axis = 1)
humid = process_precipitation_data('기상데이터/강원영동_습도.csv', columns = ['일시', '평균습도(%rh)','최저습도(%rh)']).drop('YYYYMMSOON', axis = 1)
sun = process_precipitation_data('기상데이터/강원영동_일조일사.csv', columns = ['일시', '일조합(hr)','일사합(MJ/m2)'])
merged_data1 = pd.concat([rain,temp,sun, humid], axis=1).reset_index(drop = True).groupby('YYYYMMSOON', as_index=False).mean()
merged_data1.to_csv('weather.csv', encoding = 'cp949', index = False)

"""### 수출입 데이터"""

import pandas as pd
from concurrent.futures import ThreadPoolExecutor

# inout 함수 정의
def inout(inpath, outpath, category):
    total = pd.DataFrame()

    # 수입 데이터 처리
    data = pd.ExcelFile(inpath)
    df = data.parse(data.sheet_names[0])
    df = df[['DATE', '중량']].groupby('DATE').mean().reset_index()
    total[f'{category}_수입'] = df['중량']

    # 수출 데이터 처리
    data = pd.ExcelFile(outpath)
    df = data.parse(data.sheet_names[0])
    df = df[['DATE', '중량']].groupby('DATE').mean().reset_index()
    total[f'{category}_수출'] = df['중량']

    return total
df_inout = pd.DataFrame()
data = pd.ExcelFile('수출입/감자_수입.xlsx')
data = data.parse(data.sheet_names[0], index = False)
data = data[['DATE', '중량']].groupby('DATE').mean().reset_index()
df_inout['DATE'] = data['DATE']
df1= inout('수출입/감자_수입.xlsx', '수출입/감자_수출.xlsx', '감자 수미')
df2= inout('수출입/무_수입.xlsx', '수출입/무_수출.xlsx', '무')
df3= inout('수출입/양파_수입.xlsx', '수출입/양파_수출.xlsx', '양파')
df4= inout('수출입/배추_수입.xlsx', '수출입/배추_수출.xlsx', '배추')
df5= inout('수출입/파_수입.xlsx', '수출입/파_수출.xlsx', '대파(일반)')
df6= inout('수출입/고추_수입.xlsx', '수출입/고추_수출.xlsx', '건고추')
df7= inout('수출입/마늘_수입.xlsx', '수출입/마늘_수출.xlsx', '깐마늘(국산)')
df8= inout('수출입/사과_수입.xlsx', '수출입/사과_수출.xlsx', '사과')
df9= inout('수출입/배_수입.xlsx', '수출입/배_수출.xlsx', '배')
df10= inout('수출입/상치_수입.xlsx', '수출입/상치_수출.xlsx', '상추')

df_final = pd.concat([df_inout, df1,df2,df3,df4,df5,df6,df7,df8,df9,df10], axis=1).reset_index(drop = True)



### Train 데이터 기간인 2018~2022년 통계값에 기반함
df_final['양파_수출'].fillna(568.6271186440678 , inplace=True)
df_final['배추_수입'].fillna(72816.54549707602 , inplace=True)
df_final['배추_수출'].fillna(167377.60120478648  , inplace=True)
df_final['대파(일반)_수출'].fillna(0, inplace=True)
df_final['상추_수입'].fillna(125537.73146892656 , inplace=True)
df_final['상추_수출'].fillna(5631.400059141424, inplace=True)

import pandas as pd
def expand_with_YYYYMMSOON(df):
    # 결과를 저장할 리스트
    result = []

    # 각 행에 대해 처리
    for _, row in df.iterrows():
        date_str = str(int(row['DATE']))  # 소수점 문제를 해결하기 위해 int로 변환 후 문자열로 변환
        year = int(date_str[:4])
        month = int(date_str[4:6])
        
        if month == 12:
            prev_year = year + 1
            prev_month = 1
        else:
            prev_year = year
            prev_month = month + 1
        ## 과거의 데이터
        prev_date = f"{prev_year}{prev_month:02d}"
        date = f"{year}{month:02d}"
        for period in ['상순', '중순', '하순']:
            new_row = row.copy()
            new_row['YYYYMMSOON'] = f"{prev_date}{period}"
            result.append(new_row)



    # 결과 리스트를 데이터프레임으로 변환
    expanded_df = pd.DataFrame(result)
    return expanded_df


# 함수 호출
expanded_df = expand_with_YYYYMMSOON(df_final)
expanded_df.drop('DATE', axis = 1, inplace = True)
expanded_df.to_csv('inout.csv', index = False)

"""### 유가 데이터"""

def convert_to_yyyymmsoon(date):
    year_month = date.replace("-", "").replace(" ", "")[:6]
    day = int(date[-2:])  # Extracts 'DD' as an integer

    # Determine '순' based on the day
    if day <= 10:
        soon = "상순"
    elif day <= 20:
        soon = "중순"
    else:
        soon = "하순"

    return f"{year_month}{soon}"

df = pd.read_csv('WTI유 선물 과거 데이터.csv')
df['YYYYMMSOON'] = df['날짜'].apply(convert_to_yyyymmsoon)
df = df[['YYYYMMSOON', '종가']]
df = df.groupby('YYYYMMSOON').mean().reset_index()
df.to_csv('oil.csv', index = False)

"""## function"""

def process_file1(data):
    columns_to_shift = [
        'YYYYMMSOON',
        '평균가격(원)',
        '전순 평균가격(원) PreVious SOON',
        '전달 평균가격(원) PreVious MMonth',
        '전년 평균가격(원) PreVious YeaR',
        '평년 평균가격(원) Common Year SOON'
    ]
    group_cols = ['품목(품종)명', '가락시장 품목코드(5자리)', '거래단위', '등급(특 5% 상 35% 중 40% 하 20%)', '시점']
    num_shifts = 8
    for col in columns_to_shift:
        for i in range(1, num_shifts + 1):
            data[f'{col}_T-{i}'] = data.groupby(group_cols)[col].shift(i)

    data['1순'] = 0
    data['2순'] = 0
    data['3순'] = 0
    return data

def process_file2(data):
    columns_to_shift = [
        'YYYYMMSOON',
        '평균가격(원)',
        '전순 평균가격(원) PreVious SOON',
        '전달 평균가격(원) PreVious MMonth',
        '전년 평균가격(원) PreVious YeaR',
        '평년 평균가격(원) Common Year SOON'
    ]
    group_cols = ['품목명', '품목코드 ', '품종코드 ', '품종명','등급명', '유통단계별 무게 ', '유통단계별 단위 ','시점']
    num_shifts = 8

    for col in columns_to_shift:
        for i in range(1, num_shifts + 1):
            data[f'{col}_T-{i}'] = data.groupby(group_cols)[col].shift(i)
    data['1순'] = 0
    data['2순'] = 0
    data['3순'] = 0

    return data

def process_item_data1(train_data, item_list, item_name):
    train_item = train_data[train_data['품목(품종)명'].str.contains(item_name, na=False)]
    train_item['sort'] = train_item['품목(품종)명'] + train_item['거래단위'] + train_item['등급(특 5% 상 35% 중 40% 하 20%)']
    train_item = train_item[train_item['sort'].isin(item_list)]
    train_item = train_item.sort_values(by=['sort', 'YYYYMMSOON']).reset_index(drop=True)
    train_item.drop(['sort'], axis=1, inplace=True)
    return train_item

def process_item_data2(train_data, item_list, item_name):
    train_item = train_data[train_data['품목명'].str.contains(item_name, na=False)]
    train_item['sort'] = train_item['품목명'] + train_item['품종명'] + train_item['유통단계별 단위 '].astype(str) + train_item['등급명']
    train_item = train_item[train_item['sort'].isin(item_list)]
    train_item = train_item.sort_values(by=['sort', 'YYYYMMSOON']).reset_index(drop=True)
    if item_name == '사과':
      train_item.loc[(train_item['품종명'] == '후지'), '품종명'] = '후지홍로'
      train_item.loc[(train_item['품종명'] == '홍로'), '품종명'] = '후지홍로'
      train_item.loc[(train_item['품종명'] == '후지홍로'), '품종코드 '] = 0
    train_item.drop(['sort'], axis=1, inplace=True)
    return train_item

def create_shifted_features(df, column_name, num_shifts=8):
    for i in range(1, num_shifts + 1):
        df[f'{column_name}_T-{i}'] = df[column_name].shift(i)
    return df

def load_data(i):
    file_name = f'TEST_{i:02d}_1.csv'
    file_path = os.path.join('test/', file_name)
    file_name_other = f'TEST_경락정보_가락도매_{i:02d}.csv'
    file_path_other = os.path.join('test/meta/', file_name_other)
    data = pd.concat([pd.read_csv(file_path), pd.read_csv(file_path_other)], axis=0)
    시점 = file_name.replace('.csv', '')
    data['시점'] = 시점
    origin_T = data['YYYYMMSOON'].max()
    return data.reset_index(drop=True), origin_T, 시점

def load_and_concat_files(file_path, file_path_other):
    data = pd.concat([
        pd.read_csv(file_path),
        pd.read_csv(file_path_other)
    ], axis=0, ignore_index=True)
    시점 = os.path.basename(file_path).replace('.csv', '')
    data['시점'] = 시점
    return data

def load_and_collect_time(file_path, file_path_other):
    data = pd.concat([
        pd.read_csv(file_path),
        pd.read_csv(file_path_other)
    ], axis=0, ignore_index=True)
    origin_T = data['YYYYMMSOON'].max()
    시점 = os.path.basename(file_path).replace('.csv', '')
    data['시점'] = 시점
    return data, origin_T, 시점

"""## test 1"""

all_data = []
time1 = []
time2 = []

with ThreadPoolExecutor() as executor:
    results = list(executor.map(load_data, range(52)))

all_data, time1, time2 = zip(*results)

test_1 = pd.concat(all_data, ignore_index=True)

time_pairs = list(zip(time1, time2))

cabbage_list = ['알배기배추8키로상자상', '알배기배추8키로상자특', '알배기배추8키로상자중', '쌈배추8키로상자하', '얼갈이배추4키로상자하',
                '쌈배추8키로상자특', '배추10키로망대하', '얼갈이배추4키로상자상', '얼갈이배추4키로상자중', '배추10키로망대상',
                '배추10키로망대중', '쌈배추8키로상자상', '쌈배추8키로상자중', '알배기배추8키로상자하', '배추10키로망대특']
moo_list = ['무20키로상자중', '열무4키로상자중', '열무4키로상자하', '무20키로상자상', '열무1.5키로단상', '무20키로상자하',
            '열무1.5키로단중', '열무1.5키로단하', '무20키로상자특', '열무4키로상자상']
onion_list = ['양파1키로중', '양파12키로특', '양파15키로중', '양파12키로하', '양파1키로상', '양파15키로하', '양파15키로상',
              '양파1키로하', '양파12키로중', '양파15키로특', '양파1키로특', '양파12키로상']
potato_list = ['감자 수미20키로상자특', '감자 수미20키로상자하', '감자 수미20키로상자상', '감자 수미20키로상자중']
daepa_list = ['대파(일반)1키로단상', '대파(일반)1키로단중', '대파(일반)1키로단하', '대파(일반)1키로단특']

test_1_cabbage = process_item_data1(test_1, cabbage_list, '배추')
test_1_moo = process_item_data1(test_1, moo_list, '무')
test_1_onion= process_item_data1(test_1, onion_list, '양파')
test_1_potato = process_item_data1(test_1, potato_list, '감자')
test_1_daepa = process_item_data1(test_1, daepa_list, '대파')
test_1_all = pd.concat([test_1_cabbage, test_1_moo, test_1_onion, test_1_potato, test_1_daepa], axis=0)

final_data = process_file1(test_1_all)
filtered_df_list = []

for t1, t2 in time_pairs:
    temp_df = final_data[(final_data['YYYYMMSOON'] == t1) & (final_data['시점'] == t2)]
    if not temp_df.empty:
        filtered_df_list.append(temp_df)

if filtered_df_list:
    final_data = pd.concat(filtered_df_list)
else:
    final_data = pd.DataFrame()

final_data = final_data.reset_index(drop = True)
final_data.to_csv('test_1_v2_bf.csv',index=False, encoding='CP949')
final_data_potato = final_data[(final_data['품목(품종)명'] == '감자 수미') & (final_data['거래단위'] == '20키로상자') & (final_data['등급(특 5% 상 35% 중 40% 하 20%)'] == '상')].reset_index(drop = True)
final_data_moo = final_data[(final_data['품목(품종)명'] == '무') & (final_data['거래단위'] == '20키로상자') & (final_data['등급(특 5% 상 35% 중 40% 하 20%)'] == '상')].reset_index(drop = True)
final_data_cabbage = final_data[(final_data['품목(품종)명'] == '배추') & (final_data['거래단위'] == '10키로망대') & (final_data['등급(특 5% 상 35% 중 40% 하 20%)'] == '상')].reset_index(drop = True)
final_data_onion = final_data[(final_data['품목(품종)명'] == '양파') & (final_data['거래단위'] == '1키로') & (final_data['등급(특 5% 상 35% 중 40% 하 20%)'] == '상')].reset_index(drop = True)
final_data_daepa = final_data[(final_data['품목(품종)명'] == '대파(일반)') & (final_data['거래단위'] == '1키로단') & (final_data['등급(특 5% 상 35% 중 40% 하 20%)'] == '상')].reset_index(drop = True)

Filter_final_data = pd.concat([final_data_potato, final_data_moo,  final_data_cabbage, final_data_onion, final_data_daepa],axis=0).reset_index(drop = True)
Filter_final_data.to_csv('test_1_v2.csv',index=False, encoding='CP949')

test_df = Filter_final_data
train_df = final_data

data = {
    '품목(품종)명': ['배추', '무', '양파', '감자 수미', '대파(일반)'],
    '거래단위': ['10키로망대', '20키로상자', '1키로', '20키로상자', '1키로단'],
    '등급(특 5% 상 35% 중 40% 하 20%)': ['상', '상', '상', '상', '상']
}
df = pd.DataFrame(data)

transformed_item_dfs = {}

for _, criteria in df.iterrows():
    item = criteria['품목(품종)명']
    main_unit = criteria['거래단위']
    main_grade = criteria['등급(특 5% 상 35% 중 40% 하 20%)']

    main_variety_df = train_df[
        (train_df['품목(품종)명'] == item) &
        (train_df['거래단위'] == main_unit) &
        (train_df['등급(특 5% 상 35% 중 40% 하 20%)'] == main_grade)
    ].reset_index(drop=True)

    other_varieties_df = train_df[
        (train_df['품목(품종)명'] == item) &
        ~((train_df['거래단위'] == main_unit) &
          (train_df['등급(특 5% 상 35% 중 40% 하 20%)'] == main_grade))
    ].reset_index(drop=True)

    pivoted_varieties_df = other_varieties_df.pivot_table(
        index='YYYYMMSOON',
        columns=['거래단위', '등급(특 5% 상 35% 중 40% 하 20%)'],
        values=[col for col in other_varieties_df.columns
                if col not in ['YYYYMMSOON', '품목(품종)명', '거래단위', '등급(특 5% 상 35% 중 40% 하 20%)']],
        aggfunc='mean'
    ).reset_index()

    pivoted_varieties_df.columns = ['_'.join([str(c) for c in col if c]).strip()
                                    if isinstance(col, tuple) else col for col in pivoted_varieties_df.columns]
    merged_df = pd.merge(main_variety_df, pivoted_varieties_df, on='YYYYMMSOON', how='left')

    if item not in transformed_item_dfs:
        transformed_item_dfs[item] = []
    transformed_item_dfs[item].append(merged_df)

for item, dfs in transformed_item_dfs.items():
    for i in range(len(dfs)):
        dfs[i] = dfs[i].drop(['시점'], axis=1)

final_item_dfs = {item: pd.concat(dfs, ignore_index=True) for item, dfs in transformed_item_dfs.items()}

columns_to_keep = ['1순', '2순', '3순']
for item, df in final_item_dfs.items():
    columns_to_exclude = df.columns[df.columns.str.contains('1순|2순|3순') & ~df.columns.isin(columns_to_keep)]
    final_item_dfs[item] = df.drop(columns=columns_to_exclude)

for item, df in final_item_dfs.items():

    if (item != '대파(일반)'):
      meta1 = pd.read_csv(f'6_감자 수미_반입물량.xlsx_241023/{item}_반입물량.csv', encoding = 'cp949').sort_values('YYYYMMSOON').reset_index(drop = True)
      meta1 = meta1[['YYYYMMSOON','총반입량']]
      meta1 = create_shifted_features(meta1,'총반입량').dropna()
    meta2 = pd.read_csv(f'농촌경제연구원/{item}_확정거래물량.csv', encoding = 'cp949').sort_values('YYYYMMSOON').reset_index(drop = True)
    meta2.drop('품목명', axis = 1, inplace = True)
    for col in meta2.columns.difference(['품목명', 'YYYYMMSOON']):
      meta2 = create_shifted_features(meta2,col)
    meta2.dropna()
    merge_df = pd.merge(df, meta1, on='YYYYMMSOON', how='left')
    merge_df = pd.merge(merge_df, meta2, on='YYYYMMSOON', how='left')

    weather = pd.read_csv('weather.csv', encoding = 'cp949').reset_index(drop = True)
    for col in weather.columns.difference(['YYYYMMSOON']):
      weather = create_shifted_features(weather, col)
    merge_df = pd.merge(merge_df, weather, on='YYYYMMSOON', how='left')

    inout = pd.read_csv('inout.csv', encoding = 'utf-8').reset_index(drop = True)
    item_df = inout[[col for col in inout.columns if item in col] + ['YYYYMMSOON']]  # 'item' 키워드가 포함된 컬럼만 선택

    for col in item_df.columns.difference(['YYYYMMSOON']):
      item_df = create_shifted_features(item_df, col)
    merge_df = pd.merge(merge_df, item_df, on='YYYYMMSOON', how='left')

    oil = pd.read_csv('oil.csv').reset_index(drop = True)
    merge_df = pd.merge(merge_df, oil, on='YYYYMMSOON', how='left')

    wide = pd.read_csv('wide_test.csv', encoding = 'cp949').reset_index(drop = True)
    wide_df = wide[[col for col in wide.columns if item in col and f"{item}추" not in col] + ['YYYYMMSOON']]
    merge_df = pd.merge(merge_df, wide_df, on='YYYYMMSOON', how='left')

    merge_df.to_csv(f'test_{item}.csv', index=False, encoding='cp949')

"""## test 2"""

file_paths = [(f'test/TEST_{i:02d}_2.csv', f'test/meta/TEST_중도매_{i:02d}.csv') for i in range(52)]

with ThreadPoolExecutor() as executor:
    all_data = list(executor.map(lambda paths: load_and_concat_files(*paths), file_paths))
test_2 = pd.concat(all_data, ignore_index=True)

gochu_list = ['건고추화건30.0중품', '건고추화건30.0상품']
garlic_list = ['깐마늘(국산)깐마늘(남도)20.0중품', '깐마늘(국산)깐마늘(국산)20.0상품', '깐마늘(국산)깐마늘(대서)20.0중품']

test_2_gochu = process_item_data2(test_2, gochu_list, '고추')
test_2_garlic = process_item_data2(test_2, garlic_list, '마늘')

file_paths = [(f'test/TEST_{i:02d}_2.csv', f'test/meta/TEST_소매_{i:02d}.csv') for i in range(52)]

time1 = []
time2 = []

with ThreadPoolExecutor() as executor:
    results = list(executor.map(lambda paths: load_and_collect_time(*paths), file_paths))

all_data = []
for data, origin_T, 시점 in results:
    all_data.append(data)
    time1.append(origin_T)
    time2.append(시점)

test_2 = pd.concat(all_data, ignore_index=True)
time_pairs = list(zip(time1, time2))


lettuce_list = ['상추적100.0중품', '상추청100.0상품', '상추적100.0상품']
pear_list = ['배신고10.0중품', '배신고10.0상품']
apple_list = ['사과후지10.0상품', '사과후지10.0중품', '사과홍로10.0중품', '사과홍로10.0상품']

test_2_lettuce = process_item_data2(test_2, lettuce_list, '상추')
test_2_pear = process_item_data2(test_2, pear_list, '배')

test_2_apple = test_2[test_2['품목명'].str.contains('사과', na=False)]
apple = ['사과후지10.0상품', '사과후지10.0중품', '사과홍로10.0중품', '사과홍로10.0상품']
test_2_apple['sort'] = test_2_apple['품목명'] + test_2_apple['품종명'] + test_2_apple['유통단계별 단위 '].astype(str) + test_2_apple['등급명']
test_2_apple.sort_values(by=['YYYYMMSOON','sort'], inplace=True)
test_2_apple = test_2_apple[test_2_apple['sort'].isin(apple)]
test_2_apple = test_2_apple.reset_index(drop = True)

test_2_apple.loc[(test_2_apple['품종명'] == '후지'), '품종명'] = '후지홍로'
test_2_apple.loc[(test_2_apple['품종명'] == '홍로'), '품종명'] = '후지홍로'
test_2_apple.loc[(test_2_apple['품종명'] == '후지홍로'), '품종코드 '] = 0
test_2_apple.drop(['sort'],axis=1,inplace=True)

test_2_all = pd.concat([test_2_gochu, test_2_garlic, test_2_lettuce, test_2_pear, test_2_apple], axis=0).reset_index(drop=True)
final_data = process_file2(test_2_all)

filtered_df_list = []

for t1, t2 in time_pairs:
    temp_df = final_data[(final_data['YYYYMMSOON'] == t1) & (final_data['시점'] == t2)].copy()  # 먼저 time1 조건으로 필터링
    if not temp_df.empty:
        filtered_df_list.append(temp_df)

if filtered_df_list:
    final_data = pd.concat(filtered_df_list)
else:
    final_data = pd.DataFrame()
final_data = final_data.reset_index(drop = True)
final_data.to_csv('test_2_v2_bf.csv',index=False, encoding='CP949')

final_data_gochu = final_data[(final_data['품목명'] == '건고추') & (final_data['품종명'] == '화건') & (final_data['유통단계별 단위 '] == 30) & (final_data['등급명'] == '상품')].reset_index(drop = True)
final_data_apple = final_data[(final_data['품목명'] == '사과') & (final_data['품종명'] == '후지홍로') & (final_data['유통단계별 단위 '] == 10) & (final_data['등급명'] == '상품')].reset_index(drop = True)
final_data_pear = final_data[(final_data['품목명'] == '배') & (final_data['품종명'] == '신고') & (final_data['유통단계별 단위 '] == 10) & (final_data['등급명'] == '상품')].reset_index(drop = True)
final_data_garlic = final_data[(final_data['품목명'] == '깐마늘(국산)') & (final_data['품종명'] == '깐마늘(국산)') & (final_data['유통단계별 단위 '] == 20) & (final_data['등급명'] == '상품')].reset_index(drop = True)
final_data_lettuce = final_data[(final_data['품목명'] == '상추') & (final_data['품종명'] == '청') & (final_data['유통단계별 단위 '] == 100) & (final_data['등급명'] == '상품')].reset_index(drop = True)
Filter_final_data = pd.concat([final_data_gochu, final_data_apple, final_data_pear, final_data_garlic, final_data_lettuce],axis=0).reset_index(drop = True)
Filter_final_data.to_csv('test_2_v2.csv',index=False, encoding='CP949')

test_df = Filter_final_data
train_df = final_data

data = {
    '품목명': ['건고추', '깐마늘(국산)', '상추', '사과', '배'],
    '품종명' : ['화건', '깐마늘(국산)', '청', '후지홍로', '신고'],
    '유통단계별 단위 ': [30, 20, 100, 10, 10],
    '등급명': ['상품', '상품', '상품', '상품', '상품']
}

df = pd.DataFrame(data)
transformed_item_dfs = {}

for _, criteria in df.iterrows():
    item = criteria['품목명']
    main_variety = criteria['품종명']
    main_unit = criteria['유통단계별 단위 ']
    main_grade = criteria['등급명']

    main_variety_df = train_df[
        (train_df['품목명'] == item) &
        (train_df['품종명'] == main_variety) &
        (train_df['유통단계별 단위 '] == main_unit) &
        (train_df['등급명'] == main_grade)
    ].reset_index(drop=True)

    other_varieties_df = train_df[
        (train_df['품목명'] == item) &
        ~(
            (train_df['품종명'] == main_variety) &
            (train_df['유통단계별 단위 '] == main_unit) &
            (train_df['등급명'] == main_grade)
        )
    ].reset_index(drop=True)

    pivoted_varieties_df = other_varieties_df.pivot_table(
        index='YYYYMMSOON',
        columns=['품종명', '유통단계별 단위 ', '등급명'],
        values=[col for col in other_varieties_df.columns if col not in ['YYYYMMSOON', '품목명', '품종명', '유통단계별 단위 ', '등급명']],
        aggfunc='mean'
    ).reset_index()

    pivoted_varieties_df.columns = ['_'.join([str(c) for c in col if c]).strip() if isinstance(col, tuple) else col for col in pivoted_varieties_df.columns]
    merged_df = pd.merge(main_variety_df, pivoted_varieties_df, on='YYYYMMSOON', how='left')

    if item not in transformed_item_dfs:
        transformed_item_dfs[item] = []
    transformed_item_dfs[item].append(merged_df)

for item, dfs in transformed_item_dfs.items():
    for i in range(len(dfs)):
        dfs[i] = dfs[i].drop(['시점'], axis=1)

final_item_dfs = {item: pd.concat(dfs, ignore_index=True) for item, dfs in transformed_item_dfs.items()}

columns_to_keep = ['1순', '2순', '3순']
for item, df in final_item_dfs.items():
    columns_to_exclude = df.columns[df.columns.str.contains('1순|2순|3순') & ~df.columns.isin(columns_to_keep)]
    final_item_dfs[item] = df.drop(columns=columns_to_exclude)


for item, df in final_item_dfs.items():
    if (item != '건고추'):
      meta1 = pd.read_csv(f'6_감자 수미_반입물량.xlsx_241023/{item}_반입물량.csv', encoding = 'cp949').sort_values('YYYYMMSOON').reset_index(drop = True)
      meta1 = meta1[['YYYYMMSOON','총반입량']]
      meta1 = create_shifted_features(meta1,'총반입량').dropna()

    if (item != '상추'):
      meta2 = pd.read_csv(f'농촌경제연구원/{item}_확정거래물량.csv', encoding = 'cp949').sort_values('YYYYMMSOON').reset_index(drop = True)
      meta2.drop('품목명', axis = 1, inplace = True)
      for col in meta2.columns.difference(['품목명', 'YYYYMMSOON']):
        meta2 = create_shifted_features(meta2,col)
    meta2.dropna()
    merge_df = pd.merge(df, meta1, on='YYYYMMSOON', how='inner')
    merge_df = pd.merge(merge_df, meta2, on='YYYYMMSOON', how='inner')

    weather = pd.read_csv('weather.csv', encoding = 'cp949').reset_index(drop = True)
    for col in weather.columns.difference(['YYYYMMSOON']):
      weather = create_shifted_features(weather, col)
    merge_df = pd.merge(merge_df, weather, on='YYYYMMSOON', how='left')

    inout = pd.read_csv('inout.csv', encoding = 'utf-8').reset_index(drop = True)
    item_df = inout[[col for col in inout.columns if item in col and f"{item}추" not in col] + ['YYYYMMSOON']]

    for col in item_df.columns.difference(['YYYYMMSOON']):
      item_df = create_shifted_features(item_df, col)
    merge_df = pd.merge(merge_df, item_df, on='YYYYMMSOON', how='left')

    oil = pd.read_csv('oil.csv').reset_index(drop = True)
    merge_df = pd.merge(merge_df, oil, on='YYYYMMSOON', how='left')

    if (item != '건고추'):
        wide = pd.read_csv('wide_test.csv', encoding = 'cp949').reset_index(drop=True)
        wide_df = wide[[col for col in wide.columns if item in col and f"{item}추" not in col] + ['YYYYMMSOON']]
        merge_df = pd.merge(merge_df, wide_df, on='YYYYMMSOON', how='left')

    merge_df.to_csv(f'test_{item}.csv', index=False, encoding='cp949')

import os
import torch
import glob
import random
import pickle
import numpy as np
import pandas as pd
import torch.nn as nn

import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import StandardScaler
device = torch.device("cpu")
import warnings
warnings.filterwarnings('ignore')
script_dir = os.path.dirname(os.path.abspath(__file__))


### 기본 설정 및 함수
def seed_everything(seed):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = True
seed_everything(42)

def normalize_data(data):
    scaler = StandardScaler()
    normalized_data = scaler.fit_transform(data)
    return normalized_data, scaler

def inverse_normalize(data, scaler):
    return scaler.inverse_transform(data)

def interpolate_zeros(df, column):
    col = df[column]
    # 값이 0인 위치를 찾음
    zeros = col == 0
    # 0인 값들을 NaN으로 대체
    col[zeros] = np.nan
    # 보간 수행
    col.interpolate(method='linear', inplace=True, limit_direction='both')
    # 결과를 데이터프레임에 반영
    df[column] = col

품목_리스트 = ["감자 수미", "무", "양파", "배추", "대파(일반)", "건고추", "깐마늘(국산)", "사과", "상추", "배"]
group1 = ['배추', '무', '양파', '감자 수미', '대파(일반)']
group2 = ['건고추', '깐마늘(국산)']
group3 = ['상추', '사과', '배']

item_columns = {
    "감자 수미": ["YYYYMMSOON", "평균가격(원)"],
    "무": [ "YYYYMMSOON","평균가격(원)"],
    "양파": ["YYYYMMSOON","평균가격(원)"],

    "배추": ["YYYYMMSOON", "평균가격(원)"],
    "대파(일반)": ["YYYYMMSOON", "평균가격(원)"],

    "건고추": ["YYYYMMSOON", "평균가격(원)"],
    "깐마늘(국산)": [ "YYYYMMSOON","평균가격(원)"],
    "사과": ["YYYYMMSOON" , "평균가격(원)"],

    "상추": ["YYYYMMSOON","평균가격(원)"],

    "배": [ "YYYYMMSOON","평균가격(원)"]
}


# 사용 예시
selected_dome = ['감자_수미_100000', '대파_대파(일반)_100000', '마늘_깐마늘_100000',
                 '무_기타무_100000', '배_신고_100000', '배추_기타배추_100000',
                 '상추_포기찹_100000']
dome_items = ['감자 수미', '대파(일반)', '깐마늘(국산)', '무', '배', '배추', '상추']
dome_cols = [
    '감자_수미_100000_경매 건수', '마늘_깐마늘_100000_총반입량(kg)', '대파_대파(일반)_100000_총반입량(kg)',
    '배추_기타배추_100000_총반입량(kg)', '상추_포기찹_100000_경매 건수', '상추_포기찹_100000_고가(20%) 평균가',
    '배_신고_100000_고가(20%) 평균가', '무_기타무_100000_평균가(원/kg)'
]


class RevIN(nn.Module):
    def __init__(self, num_features: int, eps=1e-5, affine=True, subtract_last=False):
        """
        :param num_features: the number of features or channels
        :param eps: a value added for numerical stability
        :param affine: if True, RevIN has learnable affine parameters
        """
        super(RevIN, self).__init__()
        self.num_features = num_features
        self.eps = eps
        self.affine = affine
        self.subtract_last = subtract_last
        if self.affine:
            self._init_params()

    def forward(self, x, mode:str):
        if mode == 'norm':
            self._get_statistics(x)
            x = self._normalize(x)
        elif mode == 'denorm':
            x = self._denormalize(x)
        else: raise NotImplementedError
        return x

    def _init_params(self):
        self.affine_weight = nn.Parameter(torch.ones(self.num_features))
        self.affine_bias = nn.Parameter(torch.zeros(self.num_features))

    def _get_statistics(self, x):
        dim2reduce = tuple(range(1, x.ndim-1))
        if self.subtract_last:
            self.last = x[:,-1,:].unsqueeze(1)
        else:
            self.mean = torch.mean(x, dim=dim2reduce, keepdim=True).detach()
        self.stdev = torch.sqrt(torch.var(x, dim=dim2reduce, keepdim=True, unbiased=False) + self.eps).detach()

    def _normalize(self, x):
        if self.subtract_last:
            x = x - self.last
        else:
            x = x - self.mean
        x = x / self.stdev
        if self.affine:
            x = x * self.affine_weight
            x = x + self.affine_bias
        return x

    def _denormalize(self, x):
        if self.affine:
            x = x - self.affine_bias
            x = x / (self.affine_weight + self.eps*self.eps)
        x = x * self.stdev
        if self.subtract_last:
            x = x + self.last
        else:
            x = x + self.mean
        return x



class moving_avg(nn.Module):
    """
    Moving average block to highlight the trend of time series
    """
    def __init__(self, kernel_size, stride):
        super(moving_avg, self).__init__()
        self.kernel_size = kernel_size
        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)

    def forward(self, x):
        # padding on the both ends of time series
        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)
        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)
        x = torch.cat([front, x, end], dim=1)
        x = self.avg(x.permute(0, 2, 1))
        x = x.permute(0, 2, 1)
        return x
class momentum(nn.Module):
    def __init__(self, window_size):
        super(momentum, self).__init__()
        self.window_size = window_size

    def forward(self, x):
        # x: [Batch, Seq_len, Channels]
        momentum = x[:, self.window_size:, :] - x[:, :-self.window_size, :]
        padding = torch.zeros(x.size(0), self.window_size, x.size(2)).to(x.device)
        momentum = torch.cat([padding, momentum], dim=1)
        return momentum

class series_decomp2(nn.Module):
    def __init__(self, kernel_size, momentum_window):
        super(series_decomp2, self).__init__()
        self.moving_avg = moving_avg(kernel_size, stride=1)
        self.momentum = momentum(momentum_window)

    def forward(self, x):
        moving_mean = self.moving_avg(x)
        res = x - moving_mean
        momentums =self.momentum(x)
        return res, moving_mean , momentums
class series_decomp(nn.Module):
    """
    Series decomposition block
    """
    def __init__(self, kernel_size):
        super(series_decomp, self).__init__()
        self.moving_avg = moving_avg(kernel_size, stride=1)

    def forward(self, x):
        moving_mean = self.moving_avg(x)
        res = x - moving_mean
        return res, moving_mean

#DlinwithAttn
class ModelWithMultiheadAttention(nn.Module):
    def __init__(self, configs):
        super(ModelWithMultiheadAttention, self).__init__()
        self.seq_len = configs.window_size
        self.pred_len = configs.forecast_size
        self.n_heads = configs.n_heads
        self.channels = configs.feature_size
        self.kernel_size =configs.kernel_size
        self.momentum_window =configs.momentum_window
        self.individual = configs.individual


        self.decomposition = series_decomp2(self.kernel_size , self.momentum_window)
        # Multihead Attention 레이어
        self.multihead_attn = nn.MultiheadAttention(embed_dim=self.seq_len, num_heads=self.n_heads, batch_first=True)

        if configs.individual:
            self.Linear_Seasonal = nn.ModuleList()
            self.Linear_Trend = nn.ModuleList()
            for i in range(self.channels):
                self.Linear_Seasonal.append(nn.Linear(self.seq_len, self.pred_len))
                self.Linear_Trend.append(nn.Linear(self.seq_len, self.pred_len))
        else:
            self.Linear_Seasonal = nn.Linear(self.seq_len, self.pred_len)
            self.Linear_Trend = nn.Linear(self.seq_len, self.pred_len)

    def forward(self, x):
        seasonal_init, trend_init, momentum_init = self.decomposition(x)
        # 계절성, 트렌드성 추출하기
        seasonal_init, trend_init,momentum_init = seasonal_init.permute(0, 2, 1), trend_init.permute(0, 2, 1) ,momentum_init.permute(0,2,1)
        combined_features = trend_init + seasonal_init + momentum_init
        attn_output, _ = self.multihead_attn(query=trend_init, key=momentum_init, value=seasonal_init)


        if self.individual:
            seasonal_output = torch.zeros([attn_output.size(0), self.channels, self.pred_len], dtype=attn_output.dtype).to(attn_output.device)
            trend_output = torch.zeros([attn_output.size(0), self.channels, self.pred_len], dtype=attn_output.dtype).to(attn_output.device)

            for i in range(self.channels):
                seasonal_output[:, i, :] = self.Linear_Seasonal[i](attn_output[:, i, :])
                trend_output[:, i, :] = self.Linear_Trend[i](trend_init[:, i, :])
        else:
            seasonal_output = self.Linear_Seasonal(attn_output)
            trend_output = self.Linear_Trend(trend_init)

        x = seasonal_output + trend_output
        return x.permute(0, 2, 1)  # [Batch, Output length, Channel]로 변환

# Linear
class LinModel(nn.Module):
    """
    Just one Linear layer
    """
    def __init__(self, configs):
        super(LinModel, self).__init__()
        self.seq_len = configs.window_size
        self.pred_len = configs.forecast_size
        self.channels = configs.feature_size
        self.individual = configs.individual
        if self.individual:
            self.Linear = nn.ModuleList()
            for i in range(self.channels):
                self.Linear.append(nn.Linear(self.seq_len,self.pred_len))
        else:
            self.Linear = nn.Linear(self.seq_len, self.pred_len)

    def forward(self, x):
        # x: [Batch, Input length, Channel]
        if self.individual:
            output = torch.zeros([x.size(0),self.pred_len,x.size(2)],dtype=x.dtype).to(x.device)
            for i in range(self.channels):
                output[:,:,i] = self.Linear[i](x[:,:,i])
            x = output
        else:
            x = self.Linear(x.permute(0,2,1)).permute(0,2,1)
        return x # [Batch, Output length, Channel]

# Dlinear
class LTSF_DLinear(torch.nn.Module):
    def __init__(self,config):
        super(LTSF_DLinear, self).__init__()
        self.window_size = config.window_size
        self.forecast_size = config.forecast_size
        self.decomposition = series_decomp(config.kernel_size)
        self.individual = config.individual
        self.channels = config.feature_size
        if self.individual:
            self.Linear_Seasonal = torch.nn.ModuleList()
            self.Linear_Trend = torch.nn.ModuleList()
            for i in range(self.channels):
                self.Linear_Trend.append(torch.nn.Linear(self.window_size, self.forecast_size))
                self.Linear_Trend[i].weight = torch.nn.Parameter((1 / self.window_size) * torch.ones([self.forecast_size, self.window_size]))
                self.Linear_Seasonal.append(torch.nn.Linear(self.window_size, self.forecast_size))
                self.Linear_Seasonal[i].weight = torch.nn.Parameter((1 / self.window_size) * torch.ones([self.forecast_size, self.window_size]))
        else:
            self.Linear_Trend = torch.nn.Linear(self.window_size, self.forecast_size)
            self.Linear_Trend.weight = torch.nn.Parameter((1 / self.window_size) * torch.ones([self.forecast_size, self.window_size]))
            self.Linear_Seasonal = torch.nn.Linear(self.window_size, self.forecast_size)
            self.Linear_Seasonal.weight = torch.nn.Parameter((1 / self.window_size) * torch.ones([self.forecast_size, self.window_size]))

    def forward(self, x):
        trend_init, seasonal_init = self.decomposition(x)
        trend_init, seasonal_init = trend_init.permute(0, 2, 1), seasonal_init.permute(0, 2, 1)
        if self.individual:
            trend_output = torch.zeros([trend_init.size(0), trend_init.size(1), self.forecast_size], dtype=trend_init.dtype).to(trend_init.device)
            seasonal_output = torch.zeros([seasonal_init.size(0), seasonal_init.size(1), self.forecast_size], dtype=seasonal_init.dtype).to(seasonal_init.device)
            for idx in range(self.channels):
                trend_output[:, idx, :] = self.Linear_Trend[idx](trend_init[:, idx, :])
                seasonal_output[:, idx, :] = self.Linear_Seasonal[idx](seasonal_init[:, idx, :])
        else:
            trend_output = self.Linear_Trend(trend_init)
            seasonal_output = self.Linear_Seasonal(seasonal_init)
        x = seasonal_output + trend_output
        return x.permute(0, 2, 1)




# 전국 도매 데이터

selected_dome = ['감자_수미_100000', '대파_대파(일반)_100000', '마늘_깐마늘_100000',
                 '무_기타무_100000', '배_신고_100000', '배추_기타배추_100000',
                 '상추_포기찹_100000']
dome_items = ['감자 수미', '대파(일반)', '깐마늘(국산)', '무', '배', '배추', '상추']
dome_cols = [
    '감자_수미_100000_경매 건수', '마늘_깐마늘_100000_총반입량(kg)', '대파_대파(일반)_100000_총반입량(kg)',
    '배추_기타배추_100000_총반입량(kg)', '상추_포기찹_100000_경매 건수', '상추_포기찹_100000_고가(20%) 평균가',
    '배_신고_100000_고가(20%) 평균가', '무_기타무_100000_평균가(원/kg)'
]




##### Functions

def process_data(raw_file, meta_file, 품목명, scaler=None):
    # 데이터 파일 로드
    raw_data = pd.read_csv(raw_file)
    meta_data = pd.read_csv(meta_file)

    # '품목명' 컬럼이 없을 경우, '품목(품종)명'을 사용하여 생성
    if '품목명' not in raw_data.columns:
        if '품목(품종)명' in raw_data.columns:
            raw_data['품목명'] = raw_data['품목(품종)명']

    # 선택한 품목에 대한 raw_data 필터링
    raw_품목 = raw_data[raw_data['품목명'] == 품목명]

    # 품목명에 따른 필터링 조건
    meta_conditions = {
        '감자 수미': lambda x: (x['품목(품종)명'] == '감자 수미') & (x['등급(특 5% 상 35% 중 40% 하 20%)'] == '특'),
        '무': lambda x: (x['품목(품종)명'] == '무') & (x['거래단위'] == '20키로상자아아'),
        '양파': lambda x: (x['품목(품종)명'] == '양파') & (x['등급(특 5% 상 35% 중 40% 하 20%)'] == '상') & (x['거래단위'] == '12키로'),
        '배추': lambda x: (x['품목(품종)명'] == '알배기배추') & (x['등급(특 5% 상 35% 중 40% 하 20%)'] == '상'),
        '대파(일반)': lambda x: (x['품목(품종)명'] == '대파(일반이이)') | ((x['품목(품종)명'] == '쪽파') & (x['등급(특 5% 상 35% 중 40% 하 20%)'] == '상')),
        '건고추': lambda x: (x['품목명'] == '건고추') & (x['품종명'] == '화건') & (x['등급명'] == '중품'),
        '깐마늘(국산)': lambda x: (x['품목명'] == '깐마늘(국산산)'),
        '상추': lambda x: (x['품목명'] == '상추') & (x['품종명'] == '청') & (x['등급명'] == '중품'),
        '사과': lambda x: (x['품목명'] == '사과아'),
        '배': lambda x: (x['품목명'] == '배') & (x['품종명'] == '신고오')
    }

    # 메타데이터 필터링
    filtered_meta = meta_data[meta_conditions[품목명](meta_data)].copy()

    # '품목명_거래단위_등급' 열 생성
    if 품목명 in ['감자 수미', '무', '양파', '배추', '대파(일반)']:
        filtered_meta['품목명_거래단위_등급'] = filtered_meta['품목(품종)명'] + '_' + filtered_meta['거래단위'] + '_' + filtered_meta['등급(특 5% 상 35% 중 40% 하 20%)']
    else:
        filtered_meta['품목명_거래단위_등급'] = (
            filtered_meta['품목명'] + '_' + filtered_meta['품종명'] + '_' + filtered_meta['등급명'] + '_' + filtered_meta['유통단계별 단위 '].astype(str)
        )

    # 필요한 열만 선택
    columns_to_keep = ['YYYYMMSOON', '품목명_거래단위_등급', '평균가격(원)', '평년 평균가격(원) Common Year SOON']
    filtered_meta = filtered_meta[columns_to_keep]

    # 피벗 테이블 생성
    filtered_meta_pivot = filtered_meta.pivot_table(
        index='YYYYMMSOON',
        columns='품목명_거래단위_등급',
        values=['평균가격(원)', '평년 평균가격(원) Common Year SOON']
    )
    filtered_meta_pivot.columns = ['_'.join(col).strip() for col in filtered_meta_pivot.columns.values]
    filtered_meta_pivot.reset_index(inplace=True)

    # 원본 데이터와 피벗 테이블 병합
    train_data = pd.merge(raw_품목, filtered_meta_pivot, on='YYYYMMSOON', how='left')

    return train_data



fin_cols1 = {
    '감자 수미': ['평균가격(원)_감자 수미_20키로상자_특', '감자_수미_100000_경매 건수'],
    '건고추': ['평균가격(원)_건고추_화건_중품_30'],
    '깐마늘(국산)': ['마늘_깐마늘_100000_총반입량(kg)'],
    '대파(일반)': ['평균가격(원)_쪽파_10키로상자_상', '1000000000_대파_대파(일반)_11_총반입량(kg)'],
    '무': ['무_기타무_100000_평균가(원/kg)', '1000000000_무_기타무_11_총반입량(kg)'],
    '배추': ['평년 평균가격(원) Common Year SOON', '평균가격(원)_알배기배추_8키로상자_상'],
    '사과': ['평년 평균가격(원) Common Year SOON', '사과_금액', '사과_평년 반입량 증감률(%)'],
    '상추': ['상추_포기찹_100000_경매 건수', '상추_포기찹_100000_고가(20%) 평균가'],
    '양파': ['평균가격(원)_양파_12키로_상'],
    '배': ['배_신고_100000_고가(20%) 평균가', '배_반입량']
}


fin_cols2 = {
    '감자 수미': ['평균가격-평년가격', '평균가격(원)_감자 수미_20키로상자_특', '감자_수미_100000_경매 건수'],
    '건고추': ['평균가격-평년가격', '평균가격(원)_건고추_화건_중품_30'],
    '깐마늘(국산)': ['마늘_깐마늘_100000_총반입량(kg)'],
    '대파(일반)': ['평균가격-평년가격', '평균가격(원)_쪽파_10키로상자_상', '대파_대파(일반)_100000_총반입량(kg)'],
    '배': ['평균가격-평년가격', '배_신고_100000_고가(20%) 평균가'],
    '배추': ['평균가격-평년가격', '평년 평균가격(원) Common Year SOON', '평균가격(원)_알배기배추_8키로상자_상', '배추_기타배추_100000_총반입량(kg)'],
    '사과': ['평균가격-평년가격', '평년 평균가격(원) Common Year SOON', '사과_금액', '사과_평년 반입량 증감률(%)'],
    '상추': ['평균가격-평년가격', '상추_포기찹_100000_경매 건수'],
    '양파': ['평균가격-평년가격', '평균가격(원)_양파_12키로_상'],
    '무': ['무_기타무_100000_평균가(원/kg)', '1000000000_무_기타무_11_경매 건수', '1000000000_무_기타무_11_총반입량(kg)']
}


## config
class potato_config1:
    def __init__(self):
        self.seed = 258
        self.learning_rate = 0.001
        self.epoch = 71
        self.batch_size = 16
        self.optimizer = 'adam'
        self.weight_decay = 1e-8
        self.scheduler = 'reduce_on_plateau'
        self.patience = 6
        self.step_size = 20
        self.gamma = 0.5

        self.model = 'D'
        self.window_size = 3
        self.fin_cols = ['평균가격(원)_감자 수미_20키로상자_특', '감자_수미_100000_경매 건수']
        self.forecast_size = 2
        self.kernel_size = 17
        self.individual = False
        self.feature_size = 3
        self.year = 2018

class garlic_config1:
    def __init__(self):
        self.seed = 97
        self.learning_rate = 0.0015
        self.epoch = 109
        self.batch_size = 8
        self.optimizer = 'rmsprop'
        self.weight_decay = 0
        self.scheduler = 'reduce_on_plateau'
        self.patience = 4
        self.step_size = 20
        self.gamma = 0.5

        self.model = 'D'
        self.window_size = 3
        self.fin_cols = ['마늘_깐마늘_100000_총반입량(kg)']
        self.forecast_size = 2
        self.kernel_size = 19
        self.individual = True
        self.feature_size = 2
        self.year = 2019

class apple_config1:
    def __init__(self):
        self.seed = 319
        self.learning_rate = 0.0025
        self.epoch = 125
        self.batch_size = 16
        self.optimizer = 'adam'
        self.weight_decay = 0
        self.scheduler = 'none'
        self.patience = 3
        self.step_size = 20
        self.gamma = 0.5
        self.model = 'D'
        self.window_size = 3
        self.fin_cols = ['평년 평균가격(원) Common Year SOON', '사과_금액', '사과_평년 반입량 증감률(%)']
        self.forecast_size = 2
        self.kernel_size = 13
        self.individual = True
        self.feature_size = 4
        self.year = 2018

class lettuce_config1:
    def __init__(self):
        self.seed = 435
        self.learning_rate = 0.002
        self.epoch = 99
        self.batch_size = 16
        self.optimizer = 'rmsprop'
        self.weight_decay = 0
        self.scheduler = 'none'
        self.patience = 6
        self.step_size = 20
        self.gamma = 0.5
        self.model = 'D'
        self.window_size = 3
        self.fin_cols = ['상추_포기찹_100000_경매 건수', '상추_포기찹_100000_고가(20%) 평균가']
        self.forecast_size = 2
        self.kernel_size = 19
        self.individual = True
        self.feature_size = 3
        self.year = 2021

class pepper_config1:
    def __init__(self):
        self.seed = 81
        self.learning_rate = 0.002
        self.epoch = 115
        self.batch_size = 32
        self.optimizer = 'rmsprop'
        self.weight_decay = 1e-09
        self.scheduler = 'reduce_on_plateau'
        self.patience = 5
        self.step_size = 20
        self.gamma = 0.5

        self.fin_cols = ['평균가격(원)_건고추_화건_중품_30']
        self.window_size = 3
        self.forecast_size = 2
        self.kernel_size = 17
        self.individual = True
        self.feature_size = 2
        self.momentum_window = 2
        self.n_heads = 3
        self.year = 2020

class daepa_config1:
    def __init__(self):
        self.seed = 800
        self.learning_rate = 0.003
        self.epoch = 140
        self.batch_size = 8
        self.optimizer = 'adam'
        self.weight_decay = 1e-10
        self.scheduler = 'reduce_on_plateau'
        self.patience = 3
        self.step_size = 20
        self.gamma = 0.5
        self.fin_cols = ['평균가격(원)_쪽파_10키로상자_상', '1000000000_대파_대파(일반)_11_총반입량(kg)']
        self.window_size = 3
        self.forecast_size = 2
        self.kernel_size = 15
        self.individual = True
        self.feature_size = 3
        self.momentum_window = 1
        self.n_heads = 3
        self.year = 2020

class moo_config1:
    def __init__(self):
        self.seed = 2551
        self.learning_rate = 0.003
        self.epoch = 81
        self.batch_size = 8
        self.optimizer = 'adamw'
        self.weight_decay = 0
        self.scheduler = 'none'
        self.patience = 5
        self.step_size = 20
        self.gamma = 0.5
        self.fin_cols = ['무_기타무_100000_평균가(원/kg)', '1000000000_무_기타무_11_총반입량(kg)']
        self.window_size = 3
        self.forecast_size = 2
        self.kernel_size = 15
        self.individual = True
        self.feature_size = 3
        self.momentum_window = 2
        self.n_heads = 1
        self.year = 2018


class cabbage_config1:
    def __init__(self):
        self.seed = 318
        self.learning_rate = 0.0009
        self.epoch = 72
        self.batch_size = 16
        self.optimizer = 'rmsprop'
        self.weight_decay = 1e-8
        self.scheduler = 'none'
        self.patience = 3
        self.step_size = 20
        self.gamma = 0.5
        self.fin_cols = ['평년 평균가격(원) Common Year SOON', '평균가격(원)_알배기배추_8키로상자_상']
        self.window_size = 3
        self.forecast_size = 2
        self.kernel_size = 21
        self.individual = True
        self.feature_size = 3
        self.momentum_window = 3
        self.n_heads = 1
        self.year = 2019

class onion_config1:
    def __init__(self):
        self.seed = 321
        self.learning_rate = 0.0025
        self.epoch = 145
        self.batch_size = 32
        self.optimizer = 'adam'
        self.weight_decay = 0
        self.scheduler = 'none'
        self.patience = 3
        self.step_size = 20
        self.gamma = 0.5
        self.fin_cols = ['평균가격(원)_양파_12키로_상']
        self.window_size = 3
        self.forecast_size = 2
        self.kernel_size = 21
        self.individual = False
        self.feature_size = 2
        self.momentum_window = 1
        self.n_heads = 3
        self.year = 2020

class pear_config1:
    def __init__(self):
        self.seed = 2713
        self.learning_rate = 0.003
        self.epoch = 156
        self.batch_size = 16
        self.optimizer = 'adamw'
        self.weight_decay = 0
        self.scheduler = 'none'
        self.patience = 4
        self.step_size = 20
        self.gamma = 0.5
        self.fin_cols = ['배_신고_100000_고가(20%) 평균가', '배_반입량']
        self.window_size = 3
        self.forecast_size = 2
        self.kernel_size = 19
        self.individual = False
        self.feature_size = 3
        self.momentum_window = 1
        self.n_heads = 3
        self.year = 2019

class potato_config2:
    def __init__(self):
        self.seed = 199
        self.learning_rate = 0.003
        self.epoch = 90
        self.patience = 4
        self.batch_size = 16
        self.optimizer = 'rmsprop'
        self.weight_decay = 0
        self.scheduler = 'none'

        self.model = 'L'
        self.window_size = 9
        self.fin_cols = ['평균가격-평년가격', '평균가격(원)_감자 수미_20키로상자_특', '감자_수미_100000_경매 건수']
        self.forecast_size = 3
        self.kernel_size = 15
        self.individual = False
        self.feature_size = len(self.fin_cols) + 1  # 주요 특징의 개수에 따라 조정
        self.year = 2018

class garlic_config2:
    def __init__(self):
        self.seed = 25
        self.learning_rate = 0.002
        self.epoch = 113
        self.patience = 5
        self.batch_size = 8
        self.optimizer = 'adam'
        self.weight_decay = 1e-09
        self.scheduler = 'none'

        self.model = 'D'
        self.window_size = 9
        self.fin_cols = ['마늘_깐마늘_100000_총반입량(kg)']
        self.forecast_size = 3
        self.kernel_size = 21
        self.individual = True
        self.feature_size = len(self.fin_cols) + 1
        self.year = 2019

class apple_config2:
    def __init__(self):
        self.seed = 332
        self.learning_rate = 0.002
        self.epoch = 120
        self.patience = 6
        self.batch_size = 8
        self.optimizer = 'adam'
        self.weight_decay = 1e-08
        self.scheduler = 'none'

        self.model = 'D'
        self.window_size = 9
        self.fin_cols = ['평균가격-평년가격', '평년 평균가격(원) Common Year SOON', '사과_금액', '사과_평년 반입량 증감률(%)']
        self.forecast_size =3
        self.kernel_size = 13
        self.individual = False
        self.feature_size = len(self.fin_cols) + 1
        self.year = 2018

class lettuce_config2:
    def __init__(self):
        self.seed = 888
        self.learning_rate = 0.002
        self.epoch = 100
        self.patience = 6
        self.batch_size = 8
        self.optimizer = 'rmsprop'
        self.weight_decay = 1e-08
        self.scheduler = 'none'

        self.model = 'D'
        self.window_size = 9
        self.fin_cols = ['평균가격-평년가격', '상추_포기찹_100000_경매 건수']
        self.forecast_size = 3
        self.kernel_size = 21
        self.individual = True
        self.feature_size = len(self.fin_cols) + 1
        self.year = 2021

class pepper_config2:
    def __init__(self):
        self.seed = 221
        self.learning_rate = 0.0015
        self.epoch = 79
        self.patience = 5
        self.batch_size = 32
        self.optimizer = 'adam'
        self.weight_decay = 1e-08
        self.scheduler = 'none'

        self.fin_cols = ['평균가격-평년가격', '평균가격(원)_건고추_화건_중품_30']
        self.window_size = 9
        self.forecast_size = 3
        self.kernel_size = 15
        self.individual = True
        self.feature_size = len(self.fin_cols) + 1
        self.momentum_window = 3
        self.n_heads = 1
        self.year = 2020

class daepa_config2:
    def __init__(self):
        self.seed = 6
        self.learning_rate = 0.001
        self.epoch = 112
        self.patience = 5
        self.batch_size = 8
        self.optimizer = 'rmsprop'
        self.weight_decay = 0
        self.scheduler = 'none'

        self.fin_cols = ['평균가격-평년가격', '평균가격(원)_쪽파_10키로상자_상', '대파_대파(일반)_100000_총반입량(kg)']
        self.window_size = 9
        self.forecast_size = 3
        self.kernel_size = 15
        self.individual = True
        self.feature_size = len(self.fin_cols) + 1
        self.momentum_window = 1
        self.n_heads = 1
        self.year = 2020

class moo_config2:
    def __init__(self):
        self.seed = 101
        self.learning_rate = 0.0025
        self.epoch = 97
        self.batch_size = 16
        self.optimizer = 'adamw'
        self.weight_decay = 1e-10
        self.scheduler = 'none'
        self.patience = 4

        self.fin_cols = ['무_기타무_100000_평균가(원/kg)', '1000000000_무_기타무_11_경매 건수', '1000000000_무_기타무_11_총반입량(kg)']
        self.window_size = 9
        self.forecast_size = 3
        self.kernel_size = 19
        self.individual = False
        self.feature_size = len(self.fin_cols) + 1
        self.momentum_window = 3
        self.n_heads = 3
        self.year = 2018


class cabbage_config2:
    def __init__(self):
        self.seed = 268
        self.learning_rate = 0.0015
        self.epoch = 73
        self.batch_size = 16
        self.optimizer = 'adam'
        self.weight_decay = 0
        self.scheduler = 'none'

        self.fin_cols = ['평균가격-평년가격', '평년 평균가격(원) Common Year SOON', '평균가격(원)_알배기배추_8키로상자_상', '배추_기타배추_100000_총반입량(kg)']
        self.window_size = 9
        self.forecast_size = 3
        self.kernel_size = 21
        self.individual = True
        self.feature_size = len(self.fin_cols) + 1
        self.momentum_window = 3
        self.n_heads = 3
        self.year = 2019


class onion_config2:
    def __init__(self):
        self.seed = 3
        self.learning_rate = 0.0025
        self.epoch = 157
        self.batch_size = 32
        self.optimizer = 'adamw'
        self.weight_decay = 1e-09
        self.scheduler = 'none'

        self.fin_cols = ['평균가격-평년가격', '평균가격(원)_양파_12키로_상']
        self.window_size = 9
        self.forecast_size = 3
        self.kernel_size = 17
        self.individual = False
        self.feature_size = len(self.fin_cols) + 1
        self.momentum_window = 2
        self.n_heads = 3
        self.year = 2020


class pear_config2:
    def __init__(self):
        self.seed = 337
        self.learning_rate = 0.0015
        self.epoch = 134
        self.batch_size = 8
        self.patience = 7
        self.optimizer = 'adam'
        self.weight_decay = 0
        self.step_size = 20
        self.gamma = 0.5
        self.scheduler = 'reduce_on_plateau'

        self.fin_cols = ['평균가격-평년가격', '배_신고_100000_고가(20%) 평균가']
        self.window_size = 9
        self.forecast_size = 3
        self.kernel_size = 21
        self.individual = True
        self.feature_size = len(self.fin_cols) + 1
        self.momentum_window = 3
        self.n_heads = 3
        self.year = 2019



############################################################################################3
#scaler, 추론에 필요한 거 불러오기
print('start')



def jointmarket_filter(df):
    # 필요한 컬럼만 읽어서 메모리 사용 최적화
    df = df[['공판장코드', '품목명', '품종명', '등급코드', '공판장명', 'YYYYMMSOON', '경매 건수', '총반입량(kg)']]

    mask = (
        ((df['품목명'] == '대파') & (df['품종명'] == '대파(일반)') & (df['등급코드'] == 11) & (df['공판장명'] == '*전국농협공판장')) |
        ((df['품목명'] == '무') & (df['품종명'] == '기타무') & (df['등급코드'] == 11) & (df['공판장명'] == '*전국농협공판장'))
    )
    df = df[mask]
    df['item'] = df['공판장코드'].astype(str) + '_' + df['품목명'] + '_' + df['품종명'] + '_' + df['등급코드'].astype(str)
    df = df[['item', 'YYYYMMSOON', '경매 건수', '총반입량(kg)']]

    # 피벗 테이블 생성
    df_pivot = df.pivot_table(index='YYYYMMSOON', columns='item', values=['경매 건수', '총반입량(kg)'], aggfunc='sum')
    df_pivot.columns = [f"{col[1]}_{col[0]}" for col in df_pivot.columns]
    df_pivot = df_pivot.reset_index()
    df_filtered = df_pivot.loc[:, df_pivot.notna().all() & (df_pivot != 0).all()]

    return df_filtered


# 전국 도매 정보 불러오기 및 처리 함수
def get_dome_data(df, selected_dome, final_cols):
    # '품목_품종_시장코드' 컬럼 생성 및 필터링
    df['품목_품종_시장코드'] = df['품목명'].replace({'깐마늘(국산)': '마늘', '대파(일반)': '대파', '감자 수미': '감자'}) + '_' + df['품종명'] + '_' + df['시장코드'].astype(str)
    df_filtered = df[df['품목_품종_시장코드'].isin(selected_dome)][['YYYYMMSOON', '품목_품종_시장코드', '총반입량(kg)', '총거래금액(원)', '평균가(원/kg)', '고가(20%) 평균가', '경매 건수']]

    # 피벗 테이블 생성
    df_pivot = df_filtered.pivot_table(index='YYYYMMSOON', columns='품목_품종_시장코드', values=['총반입량(kg)', '총거래금액(원)', '평균가(원/kg)', '고가(20%) 평균가', '경매 건수'], aggfunc='sum')
    df_pivot.columns = [f'{col[1]}_{col[0]}' for col in df_pivot.columns]
    df_pivot = df_pivot.reset_index()

    # 필요한 컬럼만 유지하여 반환
    return df_pivot[['YYYYMMSOON'] + [col for col in final_cols if col in df_pivot.columns]]

def load_test_jointmarket():
    # 스크립트 파일의 디렉토리 경로 가져오기
    script_dir = os.path.dirname(os.path.abspath(__file__))

    all_data = []
    for i in range(52):
        # 테스트 파일 경로 설정
        file_path = os.path.join(script_dir, f'../data/test/meta/TEST_경락정보_산지공판장_{i:02d}.csv')
        one_test_jointmarket = pd.read_csv(file_path)
        filtered_data = jointmarket_filter(one_test_jointmarket)
        all_data.append(filtered_data)

    # 모든 테스트 데이터를 하나의 DataFrame으로 병합
    test_jointmarket = pd.concat(all_data, axis=0, ignore_index=True)
    test_jointmarket = test_jointmarket.drop_duplicates().reset_index(drop=True)

    return test_jointmarket



def get_deal_info():
    # 스크립트 파일의 디렉토리 경로
    script_dir = os.path.dirname(os.path.abspath(__file__))

    # 데이터 파일의 경로 설정
    apple_file_path = os.path.join(script_dir, '../data/extradata/사과_확정거래물량.csv')
    pear_file_path = os.path.join(script_dir, '../data/extradata/배_확정거래물량.csv')

    # 사과 데이터 로드 및 전처리
    사과_deal_info = pd.read_csv(apple_file_path, encoding='cp949')
    사과_deal_info = 사과_deal_info[사과_deal_info['품목명'] == '후지']
    사과_deal_info = 사과_deal_info.rename(columns={col: f'사과_{col}' for col in 사과_deal_info.columns if col not in ['거래일자', '품목명']})
    사과_deal_info = 사과_deal_info[['거래일자', '사과_금액', '사과_평년 반입량 증감률(%)']]

    # 배 데이터 로드 및 전처리
    배_deal_info = pd.read_csv(pear_file_path, encoding='cp949')
    배_deal_info = 배_deal_info.rename(columns={col: f'배_{col}' for col in 배_deal_info.columns if col not in ['거래일자', '품목명']})
    배_deal_info = 배_deal_info[['거래일자', '배_반입량']]

    # 날짜 형식 변환 함수 정의
    def format_date(row):
        year = row[:4]  # 연도 (예: '2023')
        month = row[5:7]  # 월 (예: '01')
        period = row[8]  # 주기 ('상', '중', '하')
        return f"{year}{month}{period}순"

    # 날짜 형식 변환 적용
    사과_deal_info['거래일자'] = 사과_deal_info['거래일자'].apply(format_date)
    배_deal_info['거래일자'] = 배_deal_info['거래일자'].apply(format_date)

    # 거래일자 기준으로 병합하여 하나의 데이터프레임으로 결합
    combined_deal_info = pd.merge(사과_deal_info, 배_deal_info, on='거래일자', how='outer')

    return combined_deal_info




# 모든 테스트 데이터 로드 함수
def load_all_test_dome(selected_dome, final_cols):
    test_files = glob.glob(os.path.join(script_dir, 'data/test/meta/TEST_경락정보_전국도매_*.csv'))


    all_test_data = pd.concat([get_dome_data(pd.read_csv(file), selected_dome, final_cols) for file in test_files], ignore_index=True)
    return all_test_data.drop_duplicates()


# 모든 테스트 데이터 결합
test_dome = load_all_test_dome(selected_dome, dome_cols)
test_jointmarket =load_test_jointmarket()

deal_info = get_deal_info()




def load_infer_data(folder_name='for_infer'):
    # 스크립트 파일 경로 설정
    script_dir = os.path.dirname(os.path.abspath(__file__))
    load_dir = os.path.join(script_dir, folder_name)

    # 스케일러 파일 경로
    scalers_path = os.path.join(load_dir, 'scalers.pkl')
    with open(scalers_path, 'rb') as f:
        scalers = pickle.load(f)

    return scalers

scalers= load_infer_data()






def infer_dlin2(품목리스트, config, scaler):
    # 감자는 Linear로 하기
    seed_everything(config.seed)
    predicts = {}

    for item in 품목리스트:
        # 모델 불러오기
        model = LinModel(config) if item == '감자 수미' else LTSF_DLinear(config)

        script_dir = os.path.dirname(os.path.abspath(__file__))
        # 상위 폴더로 이동 후 'big/dl_weights2' 경로 지정
        model_path = os.path.join(script_dir, '..', 'dl_weights2', f"{item}_model2_win9.pth")

        model.load_state_dict(torch.load(model_path))
        model.to(device)
        model.eval()
        item_test_tensors = []

        for i in range(52):
            if item in group1:
                test_file = os.path.join(script_dir, f"../data/test/TEST_{i:02d}_1.csv")
                meta_file = os.path.join(script_dir, f"../data/test/meta/TEST_경락정보_가락도매_{i:02d}.csv")
            elif item in group2:
                test_file = os.path.join(script_dir, f"../data/test/TEST_{i:02d}_2.csv")
                meta_file = os.path.join(script_dir, f"../data/test/meta/TEST_중도매_{i:02d}.csv")
            elif item in group3:
                test_file = os.path.join(script_dir, f"../data/test/TEST_{i:02d}_2.csv")
                meta_file = os.path.join(script_dir, f"../data/test/meta/TEST_소매_{i:02d}.csv")

            test_data = process_data(test_file, meta_file, item)
            if item != '깐마늘(국산)':
                interpolate_zeros(test_data, '평년 평균가격(원) Common Year SOON')
                test_data['평균가격-평년가격'] = test_data['평균가격(원)'] - test_data['평년 평균가격(원) Common Year SOON']

            fincols = ['YYYYMMSOON', '평균가격(원)'] + [col for col in config.fin_cols if col in test_data.columns]
            test_data = test_data[fincols]

            dome_cols = ['YYYYMMSOON'] + [col for col in config.fin_cols if col in test_dome.columns]
            test_dome_filtered = test_dome[dome_cols]
            test_data = pd.merge(test_data, test_dome_filtered, how='left', on='YYYYMMSOON')

            if item == '사과':
                deal_cols = ['거래일자'] + [col for col in config.fin_cols if col in deal_info.columns]
                deal_info_filtered = deal_info[deal_cols]
                test_data = pd.merge(test_data, deal_info_filtered, how='left', left_on='YYYYMMSOON', right_on='거래일자')
                interpolate_zeros(test_data, '사과_평년 반입량 증감률(%)')

            final_columns = ['평균가격(원)'] + config.fin_cols
            test_data = test_data[final_columns]
            test_price_df = test_data.reset_index(drop=True)
            test_price_df = test_price_df.iloc[-1 * config.window_size:, :]
            normalized_testdata = scaler.transform(test_price_df)
            test_tensor = torch.tensor(normalized_testdata, dtype=torch.float32)
            item_test_tensors.append(test_tensor)

        item_test_batch = torch.stack(item_test_tensors).to(device)
        with torch.no_grad():
            prediction = model(item_test_batch)

        prediction = prediction.cpu().numpy()
        product_predict = []
        for pred in prediction:
            inverse_pred = inverse_normalize(pred, scaler)
            product_predict.append(inverse_pred[:, 0])

        flatlist = np.concatenate(product_predict).tolist()
        predicts[item] = flatlist
    return predicts


def infer_dlinAttn2(품목리스트, config, scaler):
    seed_everything(config.seed)
    predicts = {}

    for item in 품목리스트:
        model = ModelWithMultiheadAttention(config)

        script_dir = os.path.dirname(os.path.abspath(__file__))
        model_path = os.path.join(script_dir, '..', 'dl_weights2', f"{item}_model2_win9.pth")
        model.load_state_dict(torch.load(model_path))
        model.to(device)
        model.eval()
        item_test_tensors = []

        for i in range(52):
            if item in group1:
                test_file = os.path.join(script_dir, f"../data/test/TEST_{i:02d}_1.csv")
                meta_file = os.path.join(script_dir, f"../data/test/meta/TEST_경락정보_가락도매_{i:02d}.csv")
            elif item in group2:
                test_file = os.path.join(script_dir, f"../data/test/TEST_{i:02d}_2.csv")
                meta_file = os.path.join(script_dir, f"../data/test/meta/TEST_중도매_{i:02d}.csv")
            elif item in group3:
                test_file = os.path.join(script_dir, f"../data/test/TEST_{i:02d}_2.csv")
                meta_file = os.path.join(script_dir, f"../data/test/meta/TEST_소매_{i:02d}.csv")

            test_data = process_data(test_file, meta_file, item)
            if item != '무':
                interpolate_zeros(test_data, '평년 평균가격(원) Common Year SOON')
                test_data['평균가격-평년가격'] = test_data['평균가격(원)'] - test_data['평년 평균가격(원) Common Year SOON']

            fincols = ['YYYYMMSOON', '평균가격(원)'] + [col for col in config.fin_cols if col in test_data.columns]
            test_data = test_data[fincols]

            dome_cols = ['YYYYMMSOON'] + [col for col in config.fin_cols if col in test_dome.columns]
            test_dome_filtered = test_dome[dome_cols]
            test_data = pd.merge(test_data, test_dome_filtered, how='left', on='YYYYMMSOON')

            if item in ['대파(일반)', '무']:
                joint_cols = ['YYYYMMSOON'] + [col for col in config.fin_cols if col in test_jointmarket.columns]
                test_jointmarket_filtered = test_jointmarket[joint_cols]
                test_data = pd.merge(test_data, test_jointmarket_filtered, how='left', on='YYYYMMSOON')
            elif item == '배':
                deal_cols = ['거래일자'] + [col for col in config.fin_cols if col in deal_info.columns]
                deal_info_filtered = deal_info[deal_cols]
                test_data = pd.merge(test_data, deal_info_filtered, how='left', left_on='YYYYMMSOON', right_on='거래일자')

            final_columns = ['평균가격(원)'] + config.fin_cols
            test_data = test_data[final_columns]
            test_price_df = test_data.reset_index(drop=True)
            test_price_df = test_price_df.iloc[-1 * config.window_size:, :]
            normalized_testdata = scaler.transform(test_price_df)
            test_tensor = torch.tensor(normalized_testdata, dtype=torch.float32)
            item_test_tensors.append(test_tensor)

        item_test_batch = torch.stack(item_test_tensors).to(device)
        with torch.no_grad():
            prediction = model(item_test_batch)

        prediction = prediction.cpu().numpy()
        product_predict = []
        for pred in prediction:
            inverse_pred = inverse_normalize(pred, scaler)
            product_predict.append(inverse_pred[:, 0])

        flatlist = np.concatenate(product_predict).tolist()
        predicts[item] = flatlist
    return predicts


def infer_dlinAttn1(품목리스트, config, scaler):
    # windowsize = 3, forecasting size = 2
    seed_everything(config.seed)
    predicts = {}

    for item in 품목리스트:
        print(f"Processing {item}")

        # 모델 불러오기
        model = ModelWithMultiheadAttention(config)
        script_dir = os.path.dirname(os.path.abspath(__file__))
        model_path = os.path.join(script_dir, '..', 'dl_weights2', f"{item}_model1_win3.pth")

        model.load_state_dict(torch.load(model_path))
        model.to(device)
        model.eval()
        item_test_tensors = []

        for i in range(52):
            if item in group1:
                test_file = os.path.join(script_dir, f"../data/test/TEST_{i:02d}_1.csv")
                meta_file = os.path.join(script_dir, f"../data/test/meta/TEST_경락정보_가락도매_{i:02d}.csv")
            elif item in group2:
                test_file = os.path.join(script_dir, f"../data/test/TEST_{i:02d}_2.csv")
                meta_file = os.path.join(script_dir, f"../data/test/meta/TEST_중도매_{i:02d}.csv")
            elif item in group3:
                test_file = os.path.join(script_dir, f"../data/test/TEST_{i:02d}_2.csv")
                meta_file = os.path.join(script_dir, f"../data/test/meta/TEST_소매_{i:02d}.csv")

            test_data = process_data(test_file, meta_file, item)
            fincols = ['YYYYMMSOON', '평균가격(원)'] + [col for col in config.fin_cols if col in test_data.columns]
            test_data = test_data[fincols]
            dome_cols = ['YYYYMMSOON'] + [col for col in config.fin_cols if col in test_dome.columns]
            test_dome_filtered = test_dome[dome_cols]
            test_data = pd.merge(test_data, test_dome_filtered, how='left', on='YYYYMMSOON')

            if item in ['대파(일반)', '무']:
                joint_cols = ['YYYYMMSOON'] + [col for col in config.fin_cols if col in test_jointmarket.columns]
                test_jointmarket_filtered = test_jointmarket[joint_cols]
                test_data = pd.merge(test_data, test_jointmarket_filtered, how='left', on='YYYYMMSOON')
            elif item == '배':
                deal_cols = ['거래일자'] + [col for col in config.fin_cols if col in deal_info.columns]
                deal_info_filtered = deal_info[deal_cols]
                test_data = pd.merge(test_data, deal_info_filtered, how='left', left_on='YYYYMMSOON', right_on='거래일자')

            final_columns = ['평균가격(원)'] + config.fin_cols
            test_data = test_data[final_columns]

            test_price_df = test_data.reset_index(drop=True)
            test_price_df = test_price_df.iloc[-1 * config.window_size:, :]
            normalized_testdata = scaler.transform(test_price_df)
            test_tensor = torch.tensor(normalized_testdata, dtype=torch.float32)
            item_test_tensors.append(test_tensor)

        item_test_batch = torch.stack(item_test_tensors).to(device)
        with torch.no_grad():
            prediction = model(item_test_batch)

        prediction = prediction.cpu().numpy()
        product_predict = []
        for pred in prediction:
            inverse_pred = inverse_normalize(pred, scaler)
            extended_pred = np.append(inverse_pred[:, 0], 0)
            product_predict.append(extended_pred)
        flatlist = np.concatenate(product_predict).tolist()
        predicts[item] = flatlist
    return predicts


def infer_dlin1(품목리스트, config, scaler):
    seed_everything(config.seed)
    predicts = {}

    for item in 품목리스트:
        print(f"Processing {item}")
        model = LTSF_DLinear(config)

        script_dir = os.path.dirname(os.path.abspath(__file__))
        model_path = os.path.join(script_dir, '..',  'dl_weights2', f"{item}_model1_win3.pth")

        model.load_state_dict(torch.load(model_path))
        model.to(device)
        model.eval()

        item_test_tensors = []

        for i in range(52):
            if item in group1:
                test_file = os.path.join(script_dir, f"../data/test/TEST_{i:02d}_1.csv")
                meta_file = os.path.join(script_dir, f"../data/test/meta/TEST_경락정보_가락도매_{i:02d}.csv")
            elif item in group2:
                test_file = os.path.join(script_dir, f"../data/test/TEST_{i:02d}_2.csv")
                meta_file = os.path.join(script_dir, f"../data/test/meta/TEST_중도매_{i:02d}.csv")
            elif item in group3:
                test_file = os.path.join(script_dir, f"../data/test/TEST_{i:02d}_2.csv")
                meta_file = os.path.join(script_dir, f"../data/test/meta/TEST_소매_{i:02d}.csv")
            else:
                continue

            test_data = process_data(test_file, meta_file, item)
            fincols = ['YYYYMMSOON', '평균가격(원)'] + [col for col in config.fin_cols if col in test_data.columns]
            test_data = test_data[fincols]
            dome_cols = ['YYYYMMSOON'] + [col for col in config.fin_cols if col in test_dome.columns]
            test_dome_filtered = test_dome[dome_cols]
            test_data = pd.merge(test_data, test_dome_filtered, how='left', on='YYYYMMSOON')
            if item == '사과':
                deal_cols = ['거래일자'] + [col for col in config.fin_cols if col in deal_info.columns]
                deal_info_filtered = deal_info[deal_cols]
                test_data = pd.merge(test_data, deal_info_filtered, how='left', left_on='YYYYMMSOON', right_on='거래일자')
                interpolate_zeros(test_data, '사과_평년 반입량 증감률(%)')

            final_columns = ['평균가격(원)'] + config.fin_cols
            test_data = test_data[final_columns]

            test_price_df = test_data.reset_index(drop=True)
            test_price_df = test_price_df.iloc[-1 * config.window_size:, :]
            normalized_testdata = scaler.transform(test_price_df)
            test_tensor = torch.tensor(normalized_testdata, dtype=torch.float32)
            item_test_tensors.append(test_tensor)

        item_test_batch = torch.stack(item_test_tensors).to(device)

        with torch.no_grad():
            prediction = model(item_test_batch)

        prediction = prediction.cpu().numpy()

        product_predict = []
        for pred in prediction:
            inverse_pred = inverse_normalize(pred, scaler)
            extended_pred = np.append(inverse_pred[:, 0], 0)
            product_predict.append(extended_pred)

        flatlist = np.concatenate(product_predict).tolist()
        predicts[item] = flatlist

    return predicts



# 각 품목별 예측
potato_preds1 = infer_dlin1(['감자 수미'], potato_config1(), scalers['potato_scaler1'])
garlic_preds1 = infer_dlin1(['깐마늘(국산)'], garlic_config1(), scalers['garlic_scaler1'])
apple_preds1 = infer_dlin1(['사과'], apple_config1(), scalers['apple_scaler1'])
lettuce_preds1 = infer_dlin1(['상추'], lettuce_config1(), scalers['lettuce_scaler1'])
pepper_preds1 = infer_dlinAttn1(['건고추'], pepper_config1(), scalers['pepper_scaler1'])
daepa_preds1 = infer_dlinAttn1(['대파(일반)'], daepa_config1(), scalers['daepa_scaler1'])
moo_preds1 = infer_dlinAttn1(['무'], moo_config1(), scalers['moo_scaler1'])
cabbage_preds1 = infer_dlinAttn1(['배추'], cabbage_config1(), scalers['cabbage_scaler1'])
onion_preds1 = infer_dlinAttn1(['양파'], onion_config1(), scalers['onion_scaler1'])
pear_preds1 = infer_dlinAttn1(['배'], pear_config1(), scalers['pear_scaler1'])

# 장기 모델 추론 (감자, 배 제외)
garlic_preds2 = infer_dlin2(['깐마늘(국산)'], garlic_config2(), scalers['garlic_scaler2'])
apple_preds2 = infer_dlin2(['사과'], apple_config2(), scalers['apple_scaler2'])
lettuce_preds2 = infer_dlin2(['상추'], lettuce_config2(), scalers['lettuce_scaler2'])
pepper_preds2 = infer_dlinAttn2(['건고추'], pepper_config2(), scalers['pepper_scaler2'])
daepa_preds2 = infer_dlinAttn2(['대파(일반)'], daepa_config2(), scalers['daepa_scaler2'])
moo_preds2 = infer_dlinAttn2(['무'], moo_config2(), scalers['moo_scaler2'])
cabbage_preds2 = infer_dlinAttn2(['배추'], cabbage_config2(), scalers['cabbage_scaler2'])
onion_preds2 = infer_dlinAttn2(['양파'], onion_config2(), scalers['onion_scaler2'])
pear_preds2 = infer_dlinAttn2(['배'], pear_config2(), scalers['pear_scaler2'])

# 예측값 딕셔너리 생성
preds_dict = {
    'potato': (potato_preds1, None),
    'garlic': (garlic_preds1, garlic_preds2),
    'apple': (apple_preds1, apple_preds2),
    'lettuce': (lettuce_preds1, lettuce_preds2),
    'pepper': (pepper_preds1, pepper_preds2),
    'daepa': (daepa_preds1, daepa_preds2),
    'moo': (moo_preds1, moo_preds2),
    'cabbage': (cabbage_preds1, cabbage_preds2),
    'onion': (onion_preds1, onion_preds2),
    'pear': (pear_preds1, pear_preds2), 
    
}


# 제출 파일 생성 함수
def generate_submission_files(preds_dict, output_dir='', template_file='../data/sample_submission.csv'):
    # 스크립트 파일의 디렉토리 경로
    script_dir = os.path.dirname(os.path.abspath(__file__))

    # 샘플 제출 파일 불러오기
    dl_model1 = pd.read_csv(os.path.join(script_dir, template_file))
    dl_model2 = pd.read_csv(os.path.join(script_dir, template_file))

    # 예측 결과를 모델1과 모델2에 업데이트
    for item, (preds1, preds2) in preds_dict.items():
        # preds1의 예측값을 dl_model1에 추가
        if preds1 is not None:
            for sub_item, prices in preds1.items():
                if sub_item in dl_model1.columns:
                    dl_model1[sub_item] = prices

        # preds2의 예측값이 있을 때만 dl_model2에 추가
        if preds2 is not None:
            for sub_item, prices in preds2.items():
                if sub_item in dl_model2.columns:
                    dl_model2[sub_item] = prices

    # 저장 경로 설정
    os.makedirs(os.path.join(script_dir, output_dir), exist_ok=True)
    dl_model1_save_path = os.path.join(script_dir, output_dir, 'dl_model1.csv')
    dl_model2_save_path = os.path.join(script_dir, output_dir, 'dl_model2.csv')

    # 결과 파일 저장
    dl_model1.to_csv(dl_model1_save_path, index=False)
    dl_model2.to_csv(dl_model2_save_path, index=False)


# 제출 파일 생성 함수 호출
generate_submission_files(preds_dict)

"""# 머신러닝"""

sub_test_1 = pd.read_csv('test_1_v2.csv',encoding='cp949')
sub_test_2 = pd.read_csv('test_2_v2.csv',encoding='cp949')

group1 = ['배추', '무', '양파', '감자 수미', '대파(일반)']
group2 = ['건고추', '깐마늘(국산)','상추', '사과', '배']

category = ["감자 수미", "무", "양파", "배추", "대파(일반)", "건고추", "깐마늘(국산)", "사과", "상추"]

def prepare_train_test_data(i, test_x, y_preds, dl_pred, c):
    if i == 1:
        return _
    
    dl_pred_1순 = dl_pred[dl_pred['시점'].str.contains('\+1순')].reset_index(drop=True)
    test_x['pred_1순'] = dl_pred_1순[c]

    if i == 2:
        return _
    
    dl_pred_2순 = dl_pred[dl_pred['시점'].str.contains('\+2순')].reset_index(drop=True)
    test_x['pred_2순'] = y_preds['y_pred_2'] * 0.25 + dl_pred_2순[c] * 0.75
    
    return _

def predict_for_year1(year, i, c, test_x):
    model_path = f'LGBM_pkl_9555/LGBM_model_{c}_{i}순_year_{year}_seed_724.pkl'
    loaded_model = joblib.load(model_path)
    return loaded_model.predict(test_x)

def predict_for_year2(year, i, c, test_x, y_preds, dl_pred):
    model_path = f'Time_LGBM_pkl_9555/Time_LGBM_model_{c}_{i}순_year_{year}_seed_9555.pkl'
    loaded_model = joblib.load(model_path)
    
    test_x_copy = test_x.copy()
    
    _ = prepare_train_test_data(i, test_x_copy, y_preds, dl_pred, c)
    
    return loaded_model.predict(test_x_copy)


sub_test_1_1 = sub_test_1.copy()
sub_test_2_1 = sub_test_2.copy()

sub_test_1_2 = sub_test_1.copy()
sub_test_2_2 = sub_test_2.copy()

for c in category:
    unique_years = [2018, 2019, 2020, 2021, 2022]

    train = pd.read_csv(f"train_{c}.csv", encoding='cp949')
    test = pd.read_csv(f"test_{c}.csv", encoding='cp949')
    _, test = common_FE(train, test, c)

##### 1
    test_x_1 = test.drop(['1순', '2순', '3순', '연도'], axis=1)
    y_preds_1 = {}

    for i in range(1, 4):
        with ThreadPoolExecutor() as executor:
            futures = [
                executor.submit(predict_for_year1, year, i, c, test_x_1)
                for year in unique_years]
            year_preds = [future.result() for future in futures]

        y_preds_1[f'y_pred_{i}'] = np.mean(year_preds, axis=0)

    if c in group1:
        for i in range(1, 4):
            sub_test_1_1.loc[sub_test_1_1['품목(품종)명'] == c, f'{i}순'] = y_preds_1[f'y_pred_{i}']
    elif c in group2:
        for i in range(1, 4):
            sub_test_2_1.loc[sub_test_2_1['품목명'] == c, f'{i}순'] = y_preds_1[f'y_pred_{i}']

##### 2
    #train_2 = train.drop(['종가'], axis=1)
    test_2 = test.drop(['종가'], axis=1)
    test_x_2 = test_2.drop(['1순', '2순', '3순', '연도'], axis=1)
    y_preds_2 = {}
    dl_pred = pd.read_csv('dl_model1.csv')
    for i in range(1, 4):

        with ThreadPoolExecutor() as executor:
            futures = [
                executor.submit(predict_for_year2, year, i, c, test_x_2, y_preds_2, dl_pred)
                for year in unique_years
            ]
            year_preds = [future.result() for future in futures]

        y_preds_2[f'y_pred_{i}'] = np.mean(year_preds, axis=0)

    if c in group1:
        for i in range(1, 4):
            sub_test_1_2.loc[sub_test_1['품목(품종)명'] == c, f'{i}순'] = y_preds_2[f'y_pred_{i}']
    elif c in group2:
        for i in range(1, 4):
            sub_test_2_2.loc[sub_test_2['품목명'] == c, f'{i}순'] = y_preds_2[f'y_pred_{i}']

def generate_submission_file(sub_test_1, sub_test_2, output_filename):
    submission_path = 'sample_submission.csv'
    submission_data = pd.read_csv(submission_path, encoding='utf-8')

    submission_data_main = submission_data[['시점', '배추', '무', '양파', '감자 수미', '대파(일반)']].copy()
    submission_data_secondary = submission_data[['시점', '건고추', '깐마늘(국산)', '상추', '사과', '배']].copy()
    submission_data_final = submission_data.copy()

    final_test_data = sub_test_1.copy()
    final_test_filtered = final_test_data[['시점', '품목(품종)명', '1순', '2순', '3순']]
    pivot_test_data = final_test_filtered.pivot(index='시점', columns='품목(품종)명', values=['1순', '2순', '3순'])

    for step in ['1순', '2순', '3순']:
        for product in submission_data_main.columns[1:]:
            col_name = (step, product)
            submission_data_main.loc[submission_data_main['시점'].str.contains(step, regex=False), product] = pivot_test_data[col_name].values

    final_test_data = sub_test_2.copy()
    final_test_filtered = final_test_data[['시점', '품목명', '1순', '2순', '3순']]
    pivot_test_data = final_test_filtered.pivot(index='시점', columns='품목명', values=['1순', '2순', '3순'])

    for step in ['1순', '2순', '3순']:
        for product in submission_data_secondary.columns[1:]:
            col_name = (step, product)
            submission_data_secondary.loc[submission_data_secondary['시점'].str.contains(step, regex=False), product] = pivot_test_data[col_name].values

    for col in submission_data_main.columns[1:]:
        submission_data_final[col] = submission_data_main[col]
    for col in submission_data_secondary.columns[1:]:
        submission_data_final[col] = submission_data_secondary[col]

    submission_data_final.to_csv(output_filename, index=False, encoding='utf-8')

generate_submission_file(sub_test_1_1, sub_test_2_1, '9555_re.csv')
generate_submission_file(sub_test_1_2, sub_test_2_2, 'TML_9555_2.csv')

"""# 앙상블"""

m1 = pd.read_csv('9555_re.csv')
m2 = pd.read_csv('TML_9555_2.csv')

ml = m1.copy()
ml.iloc[:,1:] = (m1.iloc[:,1:]*0.5 + m2.iloc[:,1:]*0.5)

d1 = pd.read_csv('dl_model1.csv')
d2 = pd.read_csv('dl_model2.csv')

dl = d2.copy()

dl.loc[dl['시점'].str.endswith('+1순'), dl.columns != '시점'] = (0.5 * d2.loc[dl['시점'].str.endswith('+1순'), dl.columns != '시점'] + 0.5 * d1.loc[dl['시점'].str.endswith('+1순'), dl.columns != '시점'])

submit = pd.read_csv('sample_submission.csv')
submit.loc[submit['시점'].str.endswith('+1순'), '감자 수미'] = 1 * ml.loc[submit['시점'].str.endswith('+1순'), '감자 수미']
submit.loc[submit['시점'].str.endswith('+1순'), '건고추'] = 0.1 * ml.loc[submit['시점'].str.endswith('+1순'), '건고추'] + 0.9 * dl.loc[submit['시점'].str.endswith('+1순'), '건고추']
submit.loc[submit['시점'].str.endswith('+1순'), '깐마늘(국산)'] = 0.1 * ml.loc[submit['시점'].str.endswith('+1순'), '깐마늘(국산)'] + 0.9 * dl.loc[submit['시점'].str.endswith('+1순'), '깐마늘(국산)']
submit.loc[submit['시점'].str.endswith('+1순'), '대파(일반)'] = 0.7 * ml.loc[submit['시점'].str.endswith('+1순'), '대파(일반)'] + 0.3 * dl.loc[submit['시점'].str.endswith('+1순'), '대파(일반)']
submit.loc[submit['시점'].str.endswith('+1순'), '무'] = 0.5 * ml.loc[submit['시점'].str.endswith('+1순'), '무'] + 0.5 * dl.loc[submit['시점'].str.endswith('+1순'), '무']
submit.loc[submit['시점'].str.endswith('+1순'), '배추'] = 1 * ml.loc[submit['시점'].str.endswith('+1순'), '배추']
submit.loc[submit['시점'].str.endswith('+1순'), '사과'] = 0.5 * ml.loc[submit['시점'].str.endswith('+1순'), '사과'] + 0.5 * dl.loc[submit['시점'].str.endswith('+1순'), '사과']
submit.loc[submit['시점'].str.endswith('+1순'), '상추'] = 0.5 * ml.loc[submit['시점'].str.endswith('+1순'), '상추'] + 0.5 * dl.loc[submit['시점'].str.endswith('+1순'), '상추']
submit.loc[submit['시점'].str.endswith('+1순'), '양파'] = 0.5 * ml.loc[submit['시점'].str.endswith('+1순'), '양파'] + 0.5 * dl.loc[submit['시점'].str.endswith('+1순'), '양파']
submit.loc[submit['시점'].str.endswith('+1순'), '배'] = 1 * dl.loc[submit['시점'].str.endswith('+1순'), '배']

submit.loc[submit['시점'].str.endswith('+2순'), '감자 수미'] = 1 * ml.loc[submit['시점'].str.endswith('+2순'), '감자 수미']
submit.loc[submit['시점'].str.endswith('+2순'), '건고추'] = 0.3 * ml.loc[submit['시점'].str.endswith('+2순'), '건고추'] + 0.7 * dl.loc[submit['시점'].str.endswith('+2순'), '건고추']
submit.loc[submit['시점'].str.endswith('+2순'), '깐마늘(국산)'] = 0.3 * ml.loc[submit['시점'].str.endswith('+2순'), '깐마늘(국산)'] + 0.7 * dl.loc[submit['시점'].str.endswith('+2순'), '깐마늘(국산)']
submit.loc[submit['시점'].str.endswith('+2순'), '대파(일반)'] = 0.5 * ml.loc[submit['시점'].str.endswith('+2순'), '대파(일반)'] + 0.5 * dl.loc[submit['시점'].str.endswith('+2순'), '대파(일반)']
submit.loc[submit['시점'].str.endswith('+2순'), '무'] = 0.9 * ml.loc[submit['시점'].str.endswith('+2순'), '무'] + 0.1 * dl.loc[submit['시점'].str.endswith('+2순'), '무']
submit.loc[submit['시점'].str.endswith('+2순'), '배추'] = 1 * ml.loc[submit['시점'].str.endswith('+2순'), '배추']
submit.loc[submit['시점'].str.endswith('+2순'), '사과'] = 0.9 * ml.loc[submit['시점'].str.endswith('+2순'), '사과'] + 0.1 * dl.loc[submit['시점'].str.endswith('+2순'), '사과']
submit.loc[submit['시점'].str.endswith('+2순'), '상추'] = 0.7 * ml.loc[submit['시점'].str.endswith('+2순'), '상추'] + 0.3 * dl.loc[submit['시점'].str.endswith('+2순'), '상추']
submit.loc[submit['시점'].str.endswith('+2순'), '양파'] = 0.7 * ml.loc[submit['시점'].str.endswith('+2순'), '양파'] + 0.3 * dl.loc[submit['시점'].str.endswith('+2순'), '양파']
submit.loc[submit['시점'].str.endswith('+2순'), '배'] = 1 * dl.loc[submit['시점'].str.endswith('+2순'), '배']

submit.loc[submit['시점'].str.endswith('+3순'), '감자 수미'] = 1 * ml.loc[submit['시점'].str.endswith('+3순'), '감자 수미']
submit.loc[submit['시점'].str.endswith('+3순'), '건고추'] = 0.1 * ml.loc[submit['시점'].str.endswith('+3순'), '건고추'] + 0.9 * dl.loc[submit['시점'].str.endswith('+3순'), '건고추']
submit.loc[submit['시점'].str.endswith('+3순'), '깐마늘(국산)'] = 0.5 * ml.loc[submit['시점'].str.endswith('+3순'), '깐마늘(국산)'] + 0.5 * dl.loc[submit['시점'].str.endswith('+3순'), '깐마늘(국산)']
submit.loc[submit['시점'].str.endswith('+3순'), '대파(일반)'] = 0.5 * ml.loc[submit['시점'].str.endswith('+3순'), '대파(일반)'] + 0.5 * dl.loc[submit['시점'].str.endswith('+3순'), '대파(일반)']
submit.loc[submit['시점'].str.endswith('+3순'), '무'] = 0.9 * ml.loc[submit['시점'].str.endswith('+3순'), '무'] + 0.1 * dl.loc[submit['시점'].str.endswith('+3순'), '무']
submit.loc[submit['시점'].str.endswith('+3순'), '배추'] = 1 * ml.loc[submit['시점'].str.endswith('+3순'), '배추']
submit.loc[submit['시점'].str.endswith('+3순'), '사과'] = 0.9 * ml.loc[submit['시점'].str.endswith('+3순'), '사과'] + 0.1 * dl.loc[submit['시점'].str.endswith('+3순'), '사과']
submit.loc[submit['시점'].str.endswith('+3순'), '상추'] = 0.9 * ml.loc[submit['시점'].str.endswith('+3순'), '상추'] + 0.1 * dl.loc[submit['시점'].str.endswith('+3순'), '상추']
submit.loc[submit['시점'].str.endswith('+3순'), '양파'] = 0.5 * ml.loc[submit['시점'].str.endswith('+3순'), '양파'] + 0.5 * dl.loc[submit['시점'].str.endswith('+3순'), '양파']
submit.loc[submit['시점'].str.endswith('+3순'), '배'] = 1 * dl.loc[submit['시점'].str.endswith('+3순'), '배']

columns_to_round = ['건고추', '배', '사과', '상추','깐마늘(국산)']
submit[columns_to_round] = submit[columns_to_round].round()

submit.to_csv('Final.csv',index=False)

end = time.time()

print(end - start)
