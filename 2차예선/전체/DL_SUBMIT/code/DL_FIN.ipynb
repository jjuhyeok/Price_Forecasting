{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import glob\n",
    "import multiprocessing\n",
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch import Tensor \n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from types import SimpleNamespace\n",
    "from typing import Callable, Optional\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "device = torch.device(\"cpu\")\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 버전 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os version: posix\n",
      "PyTorch version: 2.5.0+cu124\n",
      "random module: built-in module, no version\n",
      "NumPy version: 1.23.5\n",
      "Pandas version: 1.5.3\n",
      "Scikit-learn version: 1.1.3\n",
      "------------------------------------------------------------------------------\n",
      "Operating System: Linux 6.8.0-47-generic\n",
      "Python Version: 3.10.12\n",
      "CPU: x86_64\n",
      "Total Memory: 31.18 GB\n",
      "Available Memory: 19.30 GB\n",
      "CUDA Available: True\n",
      "GPU Device Name: NVIDIA GeForce RTX 4070\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import psutil\n",
    "from sklearn import __version__ as sklearn_version\n",
    "\n",
    "# 라이브러리 버전 출력\n",
    "print(f\"os version: {os.name}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"random module: built-in module, no version\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Scikit-learn version: {sklearn_version}\")\n",
    "\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "# OS 정보\n",
    "print(f\"Operating System: {platform.system()} {platform.release()}\")\n",
    "# Python 버전\n",
    "print(f\"Python Version: {platform.python_version()}\")\n",
    "# CPU 정보\n",
    "print(f\"CPU: {platform.processor()}\")\n",
    "# 메모리 정보\n",
    "mem_info = psutil.virtual_memory()\n",
    "print(f\"Total Memory: {mem_info.total / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Available Memory: {mem_info.available / (1024 ** 3):.2f} GB\")\n",
    "# GPU 정보 (CUDA 확인)\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU Device Name: {torch.cuda.get_device_name(0)}\")\n",
    "except ImportError:\n",
    "    print(\"PyTorch not installed, skipping GPU information.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본 설정 및 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed_everything(42) \n",
    "\n",
    "def normalize_data(data):\n",
    "    scaler = StandardScaler()\n",
    "    normalized_data = scaler.fit_transform(data)\n",
    "    return normalized_data, scaler\n",
    "\n",
    "def inverse_normalize(data, scaler):\n",
    "    return scaler.inverse_transform(data)\n",
    "\n",
    "def interpolate_zeros(df, column):\n",
    "    col = df[column]\n",
    "    # 값이 0인 위치를 찾음\n",
    "    zeros = col == 0\n",
    "    # 0인 값들을 NaN으로 대체\n",
    "    col[zeros] = np.nan\n",
    "    # 보간 수행\n",
    "    col.interpolate(method='linear', inplace=True, limit_direction='both')\n",
    "    # 결과를 데이터프레임에 반영\n",
    "    df[column] = col\n",
    "    \n",
    "품목_리스트 = [\"감자 수미\", \"무\", \"양파\", \"배추\", \"대파(일반)\", \"건고추\", \"깐마늘(국산)\", \"사과\", \"상추\", \"배\"]\n",
    "group1 = ['배추', '무', '양파', '감자 수미', '대파(일반)']\n",
    "group2 = ['건고추', '깐마늘(국산)']\n",
    "group3 = ['상추', '사과', '배']\n",
    "\n",
    "item_columns = {\n",
    "    \"감자 수미\": [\"YYYYMMSOON\", \"평균가격(원)\"],\n",
    "    \"무\": [ \"YYYYMMSOON\",\"평균가격(원)\"],\n",
    "    \"양파\": [\"YYYYMMSOON\",\"평균가격(원)\"],\n",
    "\n",
    "    \"배추\": [\"YYYYMMSOON\", \"평균가격(원)\"],\n",
    "    \"대파(일반)\": [\"YYYYMMSOON\", \"평균가격(원)\"],\n",
    "\n",
    "    \"건고추\": [\"YYYYMMSOON\", \"평균가격(원)\"],\n",
    "    \"깐마늘(국산)\": [ \"YYYYMMSOON\",\"평균가격(원)\"],\n",
    "    \"사과\": [\"YYYYMMSOON\" , \"평균가격(원)\"],\n",
    "    \n",
    "    \"상추\": [\"YYYYMMSOON\",\"평균가격(원)\"],\n",
    "\n",
    "    \"배\": [ \"YYYYMMSOON\",\"평균가격(원)\"]\n",
    "}\n",
    "\n",
    "\n",
    "# 사용 예시\n",
    "selected_dome = ['감자_수미_100000', '대파_대파(일반)_100000', '마늘_깐마늘_100000', \n",
    "                 '무_기타무_100000', '배_신고_100000', '배추_기타배추_100000', \n",
    "                 '상추_포기찹_100000']\n",
    "dome_items = ['감자 수미', '대파(일반)', '깐마늘(국산)', '무', '배', '배추', '상추']\n",
    "dome_cols = [\n",
    "    '감자_수미_100000_경매 건수', '마늘_깐마늘_100000_총반입량(kg)', '대파_대파(일반)_100000_총반입량(kg)', \n",
    "    '배추_기타배추_100000_총반입량(kg)', '상추_포기찹_100000_경매 건수', '상추_포기찹_100000_고가(20%) 평균가', \n",
    "    '배_신고_100000_고가(20%) 평균가', '무_기타무_100000_평균가(원/kg)'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "    \n",
    "def reshape_data(df):\n",
    "    time_series_data = []\n",
    "    for idx, row in df.iterrows():\n",
    "        sales_data = row.values.astype(float)\n",
    "        time_series_data.append(sales_data)\n",
    "    return np.array(time_series_data)\n",
    "def time_slide_df(data, window_size, forecast_size):\n",
    "    data_list = []\n",
    "    dap_list = []\n",
    "    for idx in range(0, len(data) - window_size - forecast_size + 1):\n",
    "        x = data[idx:idx + window_size].reshape(window_size, -1)  \n",
    "        y = data[idx + window_size:idx + window_size + forecast_size]\n",
    "        data_list.append(x)\n",
    "        dap_list.append(y)\n",
    "    return np.array(data_list, dtype='float32'), np.array(dap_list, dtype='float32')\n",
    "def create_dataloader(data, window_size, forecast_size, batch_size):\n",
    "    X, Y = time_slide_df(data, window_size, forecast_size)\n",
    "    ds = Data(X, Y)\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "class NMAELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NMAELoss, self).__init__()\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        mae = torch.mean(torch.abs(y_pred - y_true))\n",
    "        mean_true = torch.mean(torch.abs(y_true))\n",
    "        nmae = mae / mean_true\n",
    "        \n",
    "        return nmae\n",
    "\n",
    "def get_optimizer(model, config):\n",
    "    if config.optimizer.lower() == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "    elif config.optimizer.lower() == 'adamw':\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "    elif config.optimizer.lower() == 'sgd':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "    elif config.optimizer.lower() == 'rmsprop':\n",
    "        optimizer = torch.optim.RMSprop(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported optimizer type: {config.optimizer}\")\n",
    "    return optimizer\n",
    "\n",
    "def get_scheduler(optimizer, config):\n",
    "    if config.scheduler.lower() == 'step_lr':\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=config.step_size, gamma=config.gamma)\n",
    "    elif config.scheduler.lower() == 'reduce_on_plateau':\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=config.patience, factor=config.gamma)\n",
    "    elif config.scheduler.lower() == 'none':\n",
    "        scheduler = None\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported scheduler type: {config.scheduler}\")\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RevIN(nn.Module):\n",
    "    def __init__(self, num_features: int, eps=1e-5, affine=True, subtract_last=False):\n",
    "        \"\"\"\n",
    "        :param num_features: the number of features or channels\n",
    "        :param eps: a value added for numerical stability\n",
    "        :param affine: if True, RevIN has learnable affine parameters\n",
    "        \"\"\"\n",
    "        super(RevIN, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.affine = affine\n",
    "        self.subtract_last = subtract_last\n",
    "        if self.affine:\n",
    "            self._init_params()\n",
    "\n",
    "    def forward(self, x, mode:str):\n",
    "        if mode == 'norm':\n",
    "            self._get_statistics(x)\n",
    "            x = self._normalize(x)\n",
    "        elif mode == 'denorm':\n",
    "            x = self._denormalize(x)\n",
    "        else: raise NotImplementedError\n",
    "        return x\n",
    "\n",
    "    def _init_params(self):\n",
    "        self.affine_weight = nn.Parameter(torch.ones(self.num_features))\n",
    "        self.affine_bias = nn.Parameter(torch.zeros(self.num_features))\n",
    "\n",
    "    def _get_statistics(self, x):\n",
    "        dim2reduce = tuple(range(1, x.ndim-1))\n",
    "        if self.subtract_last:\n",
    "            self.last = x[:,-1,:].unsqueeze(1)\n",
    "        else:\n",
    "            self.mean = torch.mean(x, dim=dim2reduce, keepdim=True).detach()\n",
    "        self.stdev = torch.sqrt(torch.var(x, dim=dim2reduce, keepdim=True, unbiased=False) + self.eps).detach()\n",
    "\n",
    "    def _normalize(self, x):\n",
    "        if self.subtract_last:\n",
    "            x = x - self.last\n",
    "        else:\n",
    "            x = x - self.mean\n",
    "        x = x / self.stdev\n",
    "        if self.affine:\n",
    "            x = x * self.affine_weight\n",
    "            x = x + self.affine_bias\n",
    "        return x\n",
    "\n",
    "    def _denormalize(self, x):\n",
    "        if self.affine:\n",
    "            x = x - self.affine_bias\n",
    "            x = x / (self.affine_weight + self.eps*self.eps)\n",
    "        x = x * self.stdev\n",
    "        if self.subtract_last:\n",
    "            x = x + self.last\n",
    "        else:\n",
    "            x = x + self.mean\n",
    "        return x\n",
    "    \n",
    " \n",
    " \n",
    "class moving_avg(nn.Module):\n",
    "    \"\"\"\n",
    "    Moving average block to highlight the trend of time series\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super(moving_avg, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # padding on the both ends of time series\n",
    "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        x = torch.cat([front, x, end], dim=1)\n",
    "        x = self.avg(x.permute(0, 2, 1))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n",
    "class momentum(nn.Module):\n",
    "    def __init__(self, window_size):\n",
    "        super(momentum, self).__init__()\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [Batch, Seq_len, Channels]\n",
    "        momentum = x[:, self.window_size:, :] - x[:, :-self.window_size, :]\n",
    "        padding = torch.zeros(x.size(0), self.window_size, x.size(2)).to(x.device)\n",
    "        momentum = torch.cat([padding, momentum], dim=1)\n",
    "        return momentum\n",
    "\n",
    "class series_decomp2(nn.Module):\n",
    "    def __init__(self, kernel_size, momentum_window):\n",
    "        super(series_decomp2, self).__init__()\n",
    "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
    "        self.momentum = momentum(momentum_window)\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean = self.moving_avg(x)\n",
    "        res = x - moving_mean\n",
    "        momentums =self.momentum(x) \n",
    "        return res, moving_mean , momentums\n",
    "class series_decomp(nn.Module):\n",
    "    \"\"\"\n",
    "    Series decomposition block\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size):\n",
    "        super(series_decomp, self).__init__()\n",
    "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean = self.moving_avg(x)\n",
    "        res = x - moving_mean\n",
    "        return res, moving_mean\n",
    "\n",
    "#DlinwithAttn \n",
    "class ModelWithMultiheadAttention(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super(ModelWithMultiheadAttention, self).__init__()\n",
    "        self.seq_len = configs.window_size\n",
    "        self.pred_len = configs.forecast_size\n",
    "        self.n_heads = configs.n_heads\n",
    "        self.channels = configs.feature_size\n",
    "        self.kernel_size =configs.kernel_size\n",
    "        self.momentum_window =configs.momentum_window\n",
    "        self.individual = configs.individual\n",
    "        \n",
    "        \n",
    "        self.decomposition = series_decomp2(self.kernel_size , self.momentum_window)\n",
    "        # Multihead Attention 레이어\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim=self.seq_len, num_heads=self.n_heads, batch_first=True)\n",
    "\n",
    "        if configs.individual:\n",
    "            self.Linear_Seasonal = nn.ModuleList()\n",
    "            self.Linear_Trend = nn.ModuleList()\n",
    "            for i in range(self.channels):\n",
    "                self.Linear_Seasonal.append(nn.Linear(self.seq_len, self.pred_len))\n",
    "                self.Linear_Trend.append(nn.Linear(self.seq_len, self.pred_len))\n",
    "        else:\n",
    "            self.Linear_Seasonal = nn.Linear(self.seq_len, self.pred_len)\n",
    "            self.Linear_Trend = nn.Linear(self.seq_len, self.pred_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        seasonal_init, trend_init, momentum_init = self.decomposition(x)\n",
    "        # 계절성, 트렌드성 추출하기 \n",
    "        seasonal_init, trend_init,momentum_init = seasonal_init.permute(0, 2, 1), trend_init.permute(0, 2, 1) ,momentum_init.permute(0,2,1) \n",
    "        combined_features = trend_init + seasonal_init + momentum_init\n",
    "        attn_output, _ = self.multihead_attn(query=trend_init, key=momentum_init, value=seasonal_init)\n",
    "        \n",
    "\n",
    "        if self.individual:\n",
    "            seasonal_output = torch.zeros([attn_output.size(0), self.channels, self.pred_len], dtype=attn_output.dtype).to(attn_output.device)\n",
    "            trend_output = torch.zeros([attn_output.size(0), self.channels, self.pred_len], dtype=attn_output.dtype).to(attn_output.device)\n",
    "            \n",
    "            for i in range(self.channels):\n",
    "                seasonal_output[:, i, :] = self.Linear_Seasonal[i](attn_output[:, i, :])\n",
    "                trend_output[:, i, :] = self.Linear_Trend[i](trend_init[:, i, :])\n",
    "        else:\n",
    "            seasonal_output = self.Linear_Seasonal(attn_output)\n",
    "            trend_output = self.Linear_Trend(trend_init)\n",
    "\n",
    "        x = seasonal_output + trend_output\n",
    "        return x.permute(0, 2, 1)  # [Batch, Output length, Channel]로 변환\n",
    "\n",
    "# Linear\n",
    "class LinModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Just one Linear layer\n",
    "    \"\"\"\n",
    "    def __init__(self, configs):\n",
    "        super(LinModel, self).__init__()\n",
    "        self.seq_len = configs.window_size\n",
    "        self.pred_len = configs.forecast_size\n",
    "        self.channels = configs.feature_size\n",
    "        self.individual = configs.individual\n",
    "        if self.individual:\n",
    "            self.Linear = nn.ModuleList()\n",
    "            for i in range(self.channels):\n",
    "                self.Linear.append(nn.Linear(self.seq_len,self.pred_len))\n",
    "        else:\n",
    "            self.Linear = nn.Linear(self.seq_len, self.pred_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [Batch, Input length, Channel]\n",
    "        if self.individual:\n",
    "            output = torch.zeros([x.size(0),self.pred_len,x.size(2)],dtype=x.dtype).to(x.device)\n",
    "            for i in range(self.channels):\n",
    "                output[:,:,i] = self.Linear[i](x[:,:,i])\n",
    "            x = output\n",
    "        else:\n",
    "            x = self.Linear(x.permute(0,2,1)).permute(0,2,1)\n",
    "        return x # [Batch, Output length, Channel]\n",
    "\n",
    "# Dlinear\n",
    "class LTSF_DLinear(torch.nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(LTSF_DLinear, self).__init__()\n",
    "        self.window_size = config.window_size\n",
    "        self.forecast_size = config.forecast_size\n",
    "        self.decomposition = series_decomp(config.kernel_size)\n",
    "        self.individual = config.individual\n",
    "        self.channels = config.feature_size\n",
    "        if self.individual:\n",
    "            self.Linear_Seasonal = torch.nn.ModuleList()\n",
    "            self.Linear_Trend = torch.nn.ModuleList()\n",
    "            for i in range(self.channels):\n",
    "                self.Linear_Trend.append(torch.nn.Linear(self.window_size, self.forecast_size))\n",
    "                self.Linear_Trend[i].weight = torch.nn.Parameter((1 / self.window_size) * torch.ones([self.forecast_size, self.window_size]))\n",
    "                self.Linear_Seasonal.append(torch.nn.Linear(self.window_size, self.forecast_size))\n",
    "                self.Linear_Seasonal[i].weight = torch.nn.Parameter((1 / self.window_size) * torch.ones([self.forecast_size, self.window_size]))\n",
    "        else:\n",
    "            self.Linear_Trend = torch.nn.Linear(self.window_size, self.forecast_size)\n",
    "            self.Linear_Trend.weight = torch.nn.Parameter((1 / self.window_size) * torch.ones([self.forecast_size, self.window_size]))\n",
    "            self.Linear_Seasonal = torch.nn.Linear(self.window_size, self.forecast_size)\n",
    "            self.Linear_Seasonal.weight = torch.nn.Parameter((1 / self.window_size) * torch.ones([self.forecast_size, self.window_size]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        trend_init, seasonal_init = self.decomposition(x)\n",
    "        trend_init, seasonal_init = trend_init.permute(0, 2, 1), seasonal_init.permute(0, 2, 1)\n",
    "        if self.individual:\n",
    "            trend_output = torch.zeros([trend_init.size(0), trend_init.size(1), self.forecast_size], dtype=trend_init.dtype).to(trend_init.device)\n",
    "            seasonal_output = torch.zeros([seasonal_init.size(0), seasonal_init.size(1), self.forecast_size], dtype=seasonal_init.dtype).to(seasonal_init.device)\n",
    "            for idx in range(self.channels):\n",
    "                trend_output[:, idx, :] = self.Linear_Trend[idx](trend_init[:, idx, :])\n",
    "                seasonal_output[:, idx, :] = self.Linear_Seasonal[idx](seasonal_init[:, idx, :])\n",
    "        else:\n",
    "            trend_output = self.Linear_Trend(trend_init)\n",
    "            seasonal_output = self.Linear_Seasonal(seasonal_init)\n",
    "        x = seasonal_output + trend_output\n",
    "        return x.permute(0, 2, 1)\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 확정거래물량 (사과,배 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>거래일자</th>\n",
       "      <th>사과_금액</th>\n",
       "      <th>사과_평년 반입량 증감률(%)</th>\n",
       "      <th>배_반입량</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202409하순</td>\n",
       "      <td>1.930600e+07</td>\n",
       "      <td>-42.2</td>\n",
       "      <td>323835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202409중순</td>\n",
       "      <td>5.381000e+06</td>\n",
       "      <td>-77.5</td>\n",
       "      <td>1085421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202409상순</td>\n",
       "      <td>3.036950e+07</td>\n",
       "      <td>-41.0</td>\n",
       "      <td>3539181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202408하순</td>\n",
       "      <td>3.937600e+07</td>\n",
       "      <td>-48.7</td>\n",
       "      <td>382044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202408중순</td>\n",
       "      <td>2.617950e+07</td>\n",
       "      <td>-68.9</td>\n",
       "      <td>4320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>201802중순</td>\n",
       "      <td>7.550720e+08</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>900271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>201802상순</td>\n",
       "      <td>6.665168e+09</td>\n",
       "      <td>132.4</td>\n",
       "      <td>4506319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>201801하순</td>\n",
       "      <td>1.818520e+09</td>\n",
       "      <td>-44.4</td>\n",
       "      <td>1428041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>201801중순</td>\n",
       "      <td>1.388682e+09</td>\n",
       "      <td>-55.6</td>\n",
       "      <td>937063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>201801상순</td>\n",
       "      <td>1.453641e+09</td>\n",
       "      <td>-48.8</td>\n",
       "      <td>888982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         거래일자         사과_금액  사과_평년 반입량 증감률(%)    배_반입량\n",
       "0    202409하순  1.930600e+07             -42.2   323835\n",
       "1    202409중순  5.381000e+06             -77.5  1085421\n",
       "2    202409상순  3.036950e+07             -41.0  3539181\n",
       "3    202408하순  3.937600e+07             -48.7   382044\n",
       "4    202408중순  2.617950e+07             -68.9     4320\n",
       "..        ...           ...               ...      ...\n",
       "238  201802중순  7.550720e+08             -55.0   900271\n",
       "239  201802상순  6.665168e+09             132.4  4506319\n",
       "240  201801하순  1.818520e+09             -44.4  1428041\n",
       "241  201801중순  1.388682e+09             -55.6   937063\n",
       "242  201801상순  1.453641e+09             -48.8   888982\n",
       "\n",
       "[243 rows x 4 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_deal_info():\n",
    "    # 사과 데이터 로드 및 전처리\n",
    "    사과_deal_info = pd.read_csv('../data/extradata/사과_확정거래물량.csv', encoding='cp949')\n",
    "    사과_deal_info = 사과_deal_info[사과_deal_info['품목명'] == '후지']\n",
    "    사과_deal_info = 사과_deal_info.rename(columns={col: f'사과_{col}' for col in 사과_deal_info.columns if col not in ['거래일자', '품목명']})\n",
    "    사과_deal_info = 사과_deal_info[['거래일자', '사과_금액', '사과_평년 반입량 증감률(%)']]\n",
    "\n",
    "    # 배 데이터 로드 및 전처리\n",
    "    배_deal_info = pd.read_csv('../data/extradata/배_확정거래물량.csv', encoding='cp949')\n",
    "    배_deal_info = 배_deal_info.rename(columns={col: f'배_{col}' for col in 배_deal_info.columns if col not in ['거래일자', '품목명']})\n",
    "    배_deal_info = 배_deal_info[['거래일자', '배_반입량']]\n",
    "\n",
    "    # 날짜 형식 변환 함수 정의\n",
    "    def format_date(row):\n",
    "        year = row[:4]  # 연도 (예: '2023')\n",
    "        month = row[5:7]  # 월 (예: '01')\n",
    "        period = row[8]  # 주기 ('상', '중', '하')\n",
    "        return f\"{year}{month}{period}순\"\n",
    "\n",
    "    # 날짜 형식 변환 적용\n",
    "    사과_deal_info['거래일자'] = 사과_deal_info['거래일자'].apply(format_date)\n",
    "    배_deal_info['거래일자'] = 배_deal_info['거래일자'].apply(format_date)\n",
    "\n",
    "    # 거래일자 기준으로 병합하여 하나의 데이터프레임으로 결합\n",
    "    combined_deal_info = pd.merge(사과_deal_info, 배_deal_info, on='거래일자', how='outer')\n",
    "\n",
    "    return combined_deal_info\n",
    "\n",
    "# 결과 호출\n",
    "deal_info = get_deal_info()\n",
    "deal_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 공판장(test_jointmarket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jointmarket_filter(df):\n",
    "    # 필요한 컬럼만 읽어서 메모리 사용 최적화\n",
    "    df = df[['공판장코드', '품목명', '품종명', '등급코드', '공판장명', 'YYYYMMSOON', '경매 건수', '총반입량(kg)']]\n",
    "\n",
    "    mask = (        ((df['품목명'] == '대파') & (df['품종명'] == '대파(일반)') & (df['등급코드'] == 11) & (df['공판장명'] == '*전국농협공판장')) |\n",
    "        ((df['품목명'] == '무') & (df['품종명'] == '기타무') & (df['등급코드'] == 11) & (df['공판장명'] == '*전국농협공판장'))\n",
    "    )\n",
    "    df = df[mask]\n",
    "    df['item'] = df['공판장코드'].astype(str) + '_' + df['품목명'] + '_' + df['품종명'] + '_' + df['등급코드'].astype(str)\n",
    "    df = df[['item', 'YYYYMMSOON', '경매 건수', '총반입량(kg)']]\n",
    "    # 피벗 테이블 생성\n",
    "    df_pivot = df.pivot_table(index='YYYYMMSOON', columns='item', values=['경매 건수', '총반입량(kg)'], aggfunc='sum')\n",
    "    df_pivot.columns = [f\"{col[1]}_{col[0]}\" for col in df_pivot.columns]\n",
    "    df_pivot = df_pivot.reset_index()\n",
    "    df_filtered = df_pivot.loc[:, df_pivot.notna().all() & (df_pivot != 0).all()]\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "def add_jointmarket_info(df, item):\n",
    "    # item 단어가 포함된 열을 필터링하여 새로운 DataFrame 생성\n",
    "    df = df[[col for col in df.columns if item in col]]\n",
    "    return df\n",
    "\n",
    "def load_test_jointmarket():\n",
    "    all_data = []\n",
    "    for i in range(52):\n",
    "        file_path = f'../data/test/meta/TEST_경락정보_산지공판장_{i:02d}.csv'\n",
    "        one_test_jointmarket = pd.read_csv(file_path)\n",
    "        filtered_data = jointmarket_filter(one_test_jointmarket)\n",
    "        all_data.append(filtered_data)\n",
    "    test_jointmarket = pd.concat(all_data, axis=0, ignore_index=True)\n",
    "\n",
    "    test_jointmarket = test_jointmarket.drop_duplicates()\n",
    "    test_jointmarket = test_jointmarket.reset_index(drop=True)\n",
    "    return test_jointmarket\n",
    "test_jointmarket =load_test_jointmarket() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 공판장(train_jointmarket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YYYYMMSOON</th>\n",
       "      <th>1000000000_대파_대파(일반)_11_경매 건수</th>\n",
       "      <th>1000000000_무_기타무_11_경매 건수</th>\n",
       "      <th>1000000000_대파_대파(일반)_11_총반입량(kg)</th>\n",
       "      <th>1000000000_무_기타무_11_총반입량(kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201801상순</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>57187.00</td>\n",
       "      <td>194800.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201801중순</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>49875.00</td>\n",
       "      <td>142304.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201801하순</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>69948.00</td>\n",
       "      <td>202378.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201802상순</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>67499.00</td>\n",
       "      <td>149490.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201802중순</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>56272.00</td>\n",
       "      <td>122969.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>202211중순</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>56011.00</td>\n",
       "      <td>69003.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>202211하순</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>54466.05</td>\n",
       "      <td>108812.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>202212상순</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>43784.50</td>\n",
       "      <td>77193.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>202212중순</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>41034.00</td>\n",
       "      <td>181776.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>202212하순</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>37697.40</td>\n",
       "      <td>201909.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    YYYYMMSOON  1000000000_대파_대파(일반)_11_경매 건수  1000000000_무_기타무_11_경매 건수  \\\n",
       "0     201801상순                              8                          8   \n",
       "1     201801중순                              9                          9   \n",
       "2     201801하순                              9                          9   \n",
       "3     201802상순                              9                          9   \n",
       "4     201802중순                              6                          5   \n",
       "..         ...                            ...                        ...   \n",
       "175   202211중순                             10                          9   \n",
       "176   202211하순                             10                         10   \n",
       "177   202212상순                             10                         10   \n",
       "178   202212중순                              8                          7   \n",
       "179   202212하순                             10                          9   \n",
       "\n",
       "     1000000000_대파_대파(일반)_11_총반입량(kg)  1000000000_무_기타무_11_총반입량(kg)  \n",
       "0                            57187.00                     194800.00  \n",
       "1                            49875.00                     142304.00  \n",
       "2                            69948.00                     202378.00  \n",
       "3                            67499.00                     149490.00  \n",
       "4                            56272.00                     122969.00  \n",
       "..                                ...                           ...  \n",
       "175                          56011.00                      69003.00  \n",
       "176                          54466.05                     108812.60  \n",
       "177                          43784.50                      77193.00  \n",
       "178                          41034.00                     181776.02  \n",
       "179                          37697.40                     201909.00  \n",
       "\n",
       "[180 rows x 5 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_jointmarket = pd.read_csv('../data/train/meta/TRAIN_경락정보_산지공판장_2018-2022.csv')\n",
    "train_jointmarket =jointmarket_filter(train_jointmarket)\n",
    "\n",
    "train_jointmarket\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전국 도매 데이터 (train_dome,test_dome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전국 도매 데이터 로드 하기 \n",
    "selected_dome = ['감자_수미_100000', '대파_대파(일반)_100000', '마늘_깐마늘_100000', \n",
    "                 '무_기타무_100000', '배_신고_100000', '배추_기타배추_100000', \n",
    "                 '상추_포기찹_100000']\n",
    "dome_items = ['감자 수미', '대파(일반)', '깐마늘(국산)', '무', '배', '배추', '상추']\n",
    "dome_cols = [\n",
    "    '감자_수미_100000_경매 건수', '마늘_깐마늘_100000_총반입량(kg)', '대파_대파(일반)_100000_총반입량(kg)', \n",
    "    '배추_기타배추_100000_총반입량(kg)', '상추_포기찹_100000_경매 건수', '상추_포기찹_100000_고가(20%) 평균가', \n",
    "    '배_신고_100000_고가(20%) 평균가', '무_기타무_100000_평균가(원/kg)'\n",
    "]\n",
    "# 전국 도매 정보 불러오기 및 처리 함수\n",
    "def get_dome_data(df, selected_dome, final_cols):\n",
    "    # '품목_품종_시장코드' 컬럼 생성 및 필터링\n",
    "    df['품목_품종_시장코드'] = df['품목명'].replace({'깐마늘(국산)': '마늘', '대파(일반)': '대파', '감자 수미': '감자'}) + '_' + df['품종명'] + '_' + df['시장코드'].astype(str)\n",
    "    df_filtered = df[df['품목_품종_시장코드'].isin(selected_dome)][['YYYYMMSOON', '품목_품종_시장코드', '총반입량(kg)', '총거래금액(원)', '평균가(원/kg)', '고가(20%) 평균가', '경매 건수']]\n",
    "    \n",
    "    # 피벗 테이블 생성\n",
    "    df_pivot = df_filtered.pivot_table(index='YYYYMMSOON', columns='품목_품종_시장코드', values=['총반입량(kg)', '총거래금액(원)', '평균가(원/kg)', '고가(20%) 평균가', '경매 건수'], aggfunc='sum')\n",
    "    df_pivot.columns = [f'{col[1]}_{col[0]}' for col in df_pivot.columns]\n",
    "    df_pivot = df_pivot.reset_index()\n",
    "\n",
    "    # 필요한 컬럼만 유지하여 반환\n",
    "    return df_pivot[['YYYYMMSOON'] + [col for col in final_cols if col in df_pivot.columns]]\n",
    "\n",
    "# 전국 도매 데이터 로드\n",
    "nation_dome_info = pd.read_csv('../data/train/meta/TRAIN_경락정보_전국도매_2018-2022.csv')[['YYYYMMSOON', '시장코드', '품목명', '품종명', '총반입량(kg)', '총거래금액(원)', '평균가(원/kg)', '고가(20%) 평균가', '경매 건수']]\n",
    "train_dome = get_dome_data(nation_dome_info, selected_dome, dome_cols)\n",
    "\n",
    "# 모든 테스트 데이터 로드 함수\n",
    "def load_all_test_dome(selected_dome, final_cols):\n",
    "    test_files = glob.glob('../data/test/meta/TEST_경락정보_전국도매_*.csv')\n",
    "    all_test_data = pd.concat([get_dome_data(pd.read_csv(file), selected_dome, final_cols) for file in test_files], ignore_index=True)\n",
    "    return all_test_data.drop_duplicates()\n",
    "\n",
    "# 모든 테스트 데이터 결합\n",
    "test_dome = load_all_test_dome(selected_dome, dome_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(raw_file, meta_file, 품목명, scaler=None):\n",
    "    raw_data = pd.read_csv(raw_file)\n",
    "    meta_data = pd.read_csv(meta_file)\n",
    "\n",
    "    if '품목명' not in raw_data.columns:\n",
    "            if '품목(품종)명' in raw_data.columns:\n",
    "                raw_data['품목명'] = raw_data['품목(품종)명']\n",
    "    raw_품목 = raw_data[raw_data['품목명'] == 품목명]\n",
    "\n",
    "    meta_conditions = {\n",
    "         '감자 수미': lambda x: (x['품목(품종)명'] == '감자 수미') & (x['등급(특 5% 상 35% 중 40% 하 20%)'] == '특'), \n",
    "        '무': lambda x: (x['품목(품종)명'] == '무') &(x['거래단위'] == '20키로상자아아'),\n",
    "        '양파': lambda x: (x['품목(품종)명'] == '양파')& (x['등급(특 5% 상 35% 중 40% 하 20%)'] == '상') & (x['거래단위'] == '12키로'),\n",
    "        '배추': lambda x: (x['품목(품종)명'] == '알배기배추')& (x['등급(특 5% 상 35% 중 40% 하 20%)'] == '상'),\n",
    "        '대파(일반)': lambda x: (x['품목(품종)명'] == '대파(일반이이)')|((x['품목(품종)명'] == '쪽파')&(x['등급(특 5% 상 35% 중 40% 하 20%)'] == '상')) ,\n",
    "        '건고추': lambda x: (x['품목명'] == '건고추')&(x['품종명']=='화건')&(x['등급명'] =='중품') ,\n",
    "        '깐마늘(국산)': lambda x: (x['품목명'] == '깐마늘(국산산)') ,\n",
    "        '상추': lambda x: (x['품목명'] == '상추') & (x['품종명'] == '청') & (x['등급명'] == '중품') ,\n",
    "        '사과': lambda x: (x['품목명'] == '사과아') ,\n",
    "        '배': lambda x: (x['품목명'] == '배')& (x['품종명'] == '신고오') ,    }\n",
    "\n",
    "    filtered_meta = meta_data[meta_conditions[품목명](meta_data)].copy()\n",
    "    # 필요한 열 조합 생성\n",
    "    if 품목명 in['감자 수미', '무', '양파','배추','대파(일반)']: \n",
    "        filtered_meta['품목명_거래단위_등급'] = filtered_meta['품목(품종)명'] + '_' + filtered_meta['거래단위'] + '_' + filtered_meta['등급(특 5% 상 35% 중 40% 하 20%)']\n",
    "    else :\n",
    "        filtered_meta['품목명_거래단위_등급'] = filtered_meta['품목명'] + '_' + filtered_meta['품종명'] + '_' + filtered_meta['등급명'] + '_' + filtered_meta['유통단계별 단위 '].astype(str)\n",
    "\n",
    "    # 필요한 열만 선택\n",
    "    columns_to_keep = ['YYYYMMSOON', '품목명_거래단위_등급', '평균가격(원)',  '평년 평균가격(원) Common Year SOON']\n",
    "    filtered_meta = filtered_meta[columns_to_keep]\n",
    "    filtered_meta_pivot = filtered_meta.pivot_table(\n",
    "        index='YYYYMMSOON',\n",
    "        columns='품목명_거래단위_등급',\n",
    "        values=['평균가격(원)', '평년 평균가격(원) Common Year SOON']    )\n",
    "    filtered_meta_pivot.columns = ['_'.join(col).strip() for col in filtered_meta_pivot.columns.values]\n",
    "    filtered_meta_pivot.reset_index(inplace=True)\n",
    "    train_data = pd.merge(raw_품목, filtered_meta_pivot, on='YYYYMMSOON', how='left')\n",
    "    return train_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다변량 변수들 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_cols1 = {\n",
    "    '감자 수미': ['평균가격(원)_감자 수미_20키로상자_특', '감자_수미_100000_경매 건수'],\n",
    "    '건고추': ['평균가격(원)_건고추_화건_중품_30'],\n",
    "    '깐마늘(국산)': ['마늘_깐마늘_100000_총반입량(kg)'],\n",
    "    '대파(일반)': ['평균가격(원)_쪽파_10키로상자_상', '1000000000_대파_대파(일반)_11_총반입량(kg)'],\n",
    "    '무': ['무_기타무_100000_평균가(원/kg)', '1000000000_무_기타무_11_총반입량(kg)'],\n",
    "    '배추': ['평년 평균가격(원) Common Year SOON', '평균가격(원)_알배기배추_8키로상자_상'],\n",
    "    '사과': ['평년 평균가격(원) Common Year SOON', '사과_금액', '사과_평년 반입량 증감률(%)'],\n",
    "    '상추': ['상추_포기찹_100000_경매 건수', '상추_포기찹_100000_고가(20%) 평균가'],\n",
    "    '양파': ['평균가격(원)_양파_12키로_상'],\n",
    "    '배': ['배_신고_100000_고가(20%) 평균가', '배_반입량']\n",
    "}\n",
    "\n",
    "\n",
    "fin_cols2 = {\n",
    "    '감자 수미': ['평균가격-평년가격', '평균가격(원)_감자 수미_20키로상자_특', '감자_수미_100000_경매 건수'],\n",
    "    '건고추': ['평균가격-평년가격', '평균가격(원)_건고추_화건_중품_30'],\n",
    "    '깐마늘(국산)': ['마늘_깐마늘_100000_총반입량(kg)'],\n",
    "    '대파(일반)': ['평균가격-평년가격', '평균가격(원)_쪽파_10키로상자_상', '대파_대파(일반)_100000_총반입량(kg)'],\n",
    "    '배': ['평균가격-평년가격', '배_신고_100000_고가(20%) 평균가'],\n",
    "    '배추': ['평균가격-평년가격', '평년 평균가격(원) Common Year SOON', '평균가격(원)_알배기배추_8키로상자_상', '배추_기타배추_100000_총반입량(kg)'],\n",
    "    '사과': ['평균가격-평년가격', '평년 평균가격(원) Common Year SOON', '사과_금액', '사과_평년 반입량 증감률(%)'],\n",
    "    '상추': ['평균가격-평년가격', '상추_포기찹_100000_경매 건수'],\n",
    "    '양파': ['평균가격-평년가격', '평균가격(원)_양파_12키로_상'],\n",
    "    '무': ['무_기타무_100000_평균가(원/kg)', '1000000000_무_기타무_11_경매 건수', '1000000000_무_기타무_11_총반입량(kg)']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config \n",
    "\n",
    "* 단기 시계열 : {item}_config1 \n",
    "* 장기 시계열 : {item}_config2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단기 모델 config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class potato_config1:\n",
    "    def __init__(self):\n",
    "        self.seed = 258\n",
    "        self.learning_rate = 0.001\n",
    "        self.epoch = 71\n",
    "        self.batch_size = 16\n",
    "        self.optimizer = 'adam'\n",
    "        self.weight_decay = 1e-8\n",
    "        self.scheduler = 'reduce_on_plateau'\n",
    "        self.patience = 6\n",
    "        self.step_size = 20      \n",
    "        self.gamma = 0.5   \n",
    "        \n",
    "        self.model = 'D'\n",
    "        self.window_size = 3\n",
    "        self.fin_cols = ['평균가격(원)_감자 수미_20키로상자_특', '감자_수미_100000_경매 건수']\n",
    "        self.forecast_size = 2\n",
    "        self.kernel_size = 17\n",
    "        self.individual = False\n",
    "        self.feature_size = 3\n",
    "        self.year = 2018\n",
    "        \n",
    "class garlic_config1:\n",
    "    def __init__(self):\n",
    "        self.seed = 97\n",
    "        self.learning_rate = 0.0015\n",
    "        self.epoch = 109\n",
    "        self.batch_size = 8\n",
    "        self.optimizer = 'rmsprop'\n",
    "        self.weight_decay = 0\n",
    "        self.scheduler = 'reduce_on_plateau'\n",
    "        self.patience = 4\n",
    "        self.step_size = 20      \n",
    "        self.gamma = 0.5   \n",
    "        \n",
    "        self.model = 'D'\n",
    "        self.window_size = 3\n",
    "        self.fin_cols = ['마늘_깐마늘_100000_총반입량(kg)']\n",
    "        self.forecast_size = 2\n",
    "        self.kernel_size = 19\n",
    "        self.individual = True\n",
    "        self.feature_size = 2 \n",
    "        self.year = 2019\n",
    "        \n",
    "class apple_config1:\n",
    "    def __init__(self):\n",
    "        self.seed = 319\n",
    "        self.learning_rate = 0.0025\n",
    "        self.epoch = 125\n",
    "        self.batch_size = 16\n",
    "        self.optimizer = 'adam'\n",
    "        self.weight_decay = 0\n",
    "        self.scheduler = 'none'\n",
    "        self.patience = 3\n",
    "        self.step_size = 20      \n",
    "        self.gamma = 0.5   \n",
    "        self.model = 'D'\n",
    "        self.window_size = 3\n",
    "        self.fin_cols = ['평년 평균가격(원) Common Year SOON', '사과_금액', '사과_평년 반입량 증감률(%)']\n",
    "        self.forecast_size = 2\n",
    "        self.kernel_size = 13\n",
    "        self.individual = True\n",
    "        self.feature_size = 4\n",
    "        self.year = 2018\n",
    "\n",
    "class lettuce_config1:\n",
    "    def __init__(self):\n",
    "        self.seed = 435\n",
    "        self.learning_rate = 0.002\n",
    "        self.epoch = 99\n",
    "        self.batch_size = 16\n",
    "        self.optimizer = 'rmsprop'\n",
    "        self.weight_decay = 0\n",
    "        self.scheduler = 'none'\n",
    "        self.patience = 6\n",
    "        self.step_size = 20      \n",
    "        self.gamma = 0.5   \n",
    "        self.model = 'D'\n",
    "        self.window_size = 3\n",
    "        self.fin_cols = ['상추_포기찹_100000_경매 건수', '상추_포기찹_100000_고가(20%) 평균가']\n",
    "        self.forecast_size = 2\n",
    "        self.kernel_size = 19\n",
    "        self.individual = True\n",
    "        self.feature_size = 3\n",
    "        self.year = 2021\n",
    "\n",
    "class pepper_config1:\n",
    "    def __init__(self):\n",
    "        self.seed = 81\n",
    "        self.learning_rate = 0.002\n",
    "        self.epoch = 115\n",
    "        self.batch_size = 32\n",
    "        self.optimizer = 'rmsprop'\n",
    "        self.weight_decay = 1e-09\n",
    "        self.scheduler = 'reduce_on_plateau'\n",
    "        self.patience = 5\n",
    "        self.step_size = 20      \n",
    "        self.gamma = 0.5   \n",
    "        \n",
    "        self.fin_cols = ['평균가격(원)_건고추_화건_중품_30']\n",
    "        self.window_size = 3\n",
    "        self.forecast_size = 2\n",
    "        self.kernel_size = 17\n",
    "        self.individual = True\n",
    "        self.feature_size = 2\n",
    "        self.momentum_window = 2\n",
    "        self.n_heads = 3\n",
    "        self.year = 2020\n",
    "\n",
    "class daepa_config1:\n",
    "    def __init__(self):\n",
    "        self.seed = 800\n",
    "        self.learning_rate = 0.003\n",
    "        self.epoch = 140\n",
    "        self.batch_size = 8\n",
    "        self.optimizer = 'adam'\n",
    "        self.weight_decay = 1e-10\n",
    "        self.scheduler = 'reduce_on_plateau'\n",
    "        self.patience = 3\n",
    "        self.step_size = 20      \n",
    "        self.gamma = 0.5   \n",
    "        self.fin_cols = ['평균가격(원)_쪽파_10키로상자_상', '1000000000_대파_대파(일반)_11_총반입량(kg)']\n",
    "        self.window_size = 3\n",
    "        self.forecast_size = 2\n",
    "        self.kernel_size = 15\n",
    "        self.individual = True\n",
    "        self.feature_size = 3\n",
    "        self.momentum_window = 1\n",
    "        self.n_heads = 3\n",
    "        self.year = 2020\n",
    "        \n",
    "class moo_config1:\n",
    "    def __init__(self):\n",
    "        self.seed = 2551\n",
    "        self.learning_rate = 0.003\n",
    "        self.epoch = 81\n",
    "        self.batch_size = 8\n",
    "        self.optimizer = 'adamw'\n",
    "        self.weight_decay = 0\n",
    "        self.scheduler = 'none'\n",
    "        self.patience = 5\n",
    "        self.step_size = 20      \n",
    "        self.gamma = 0.5   \n",
    "        self.fin_cols = ['무_기타무_100000_평균가(원/kg)', '1000000000_무_기타무_11_총반입량(kg)']\n",
    "        self.window_size = 3\n",
    "        self.forecast_size = 2\n",
    "        self.kernel_size = 15\n",
    "        self.individual = True\n",
    "        self.feature_size = 3\n",
    "        self.momentum_window = 2\n",
    "        self.n_heads = 1\n",
    "        self.year = 2018\n",
    "        \n",
    "\n",
    "class cabbage_config1:\n",
    "    def __init__(self):\n",
    "        self.seed = 318\n",
    "        self.learning_rate = 0.0009\n",
    "        self.epoch = 72\n",
    "        self.batch_size = 16\n",
    "        self.optimizer = 'rmsprop'\n",
    "        self.weight_decay = 1e-8\n",
    "        self.scheduler = 'none'\n",
    "        self.patience = 3\n",
    "        self.step_size = 20      \n",
    "        self.gamma = 0.5   \n",
    "        self.fin_cols = ['평년 평균가격(원) Common Year SOON', '평균가격(원)_알배기배추_8키로상자_상']\n",
    "        self.window_size = 3\n",
    "        self.forecast_size = 2\n",
    "        self.kernel_size = 21\n",
    "        self.individual = True\n",
    "        self.feature_size = 3\n",
    "        self.momentum_window = 3\n",
    "        self.n_heads = 1\n",
    "        self.year = 2019\n",
    "        \n",
    "class onion_config1:\n",
    "    def __init__(self):\n",
    "        self.seed = 321\n",
    "        self.learning_rate = 0.0025\n",
    "        self.epoch = 145\n",
    "        self.batch_size = 32\n",
    "        self.optimizer = 'adam'\n",
    "        self.weight_decay = 0\n",
    "        self.scheduler = 'none'\n",
    "        self.patience = 3\n",
    "        self.step_size = 20      \n",
    "        self.gamma = 0.5   \n",
    "        self.fin_cols = ['평균가격(원)_양파_12키로_상']\n",
    "        self.window_size = 3\n",
    "        self.forecast_size = 2\n",
    "        self.kernel_size = 21\n",
    "        self.individual = False\n",
    "        self.feature_size = 2\n",
    "        self.momentum_window = 1\n",
    "        self.n_heads = 3\n",
    "        self.year = 2020\n",
    "        \n",
    "class pear_config1:\n",
    "    def __init__(self):\n",
    "        self.seed = 2713\n",
    "        self.learning_rate = 0.003\n",
    "        self.epoch = 156\n",
    "        self.batch_size = 16\n",
    "        self.optimizer = 'adamw'\n",
    "        self.weight_decay = 0\n",
    "        self.scheduler = 'none'\n",
    "        self.patience = 4\n",
    "        self.step_size = 20      \n",
    "        self.gamma = 0.5   \n",
    "        self.fin_cols = ['배_신고_100000_고가(20%) 평균가', '배_반입량']\n",
    "        self.window_size = 3\n",
    "        self.forecast_size = 2\n",
    "        self.kernel_size = 19\n",
    "        self.individual = False\n",
    "        self.feature_size = 3\n",
    "        self.momentum_window = 1\n",
    "        self.n_heads = 3\n",
    "        self.year = 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 장기 모델 config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class potato_config2:\n",
    "    def __init__(self):\n",
    "        self.seed = 199\n",
    "        self.learning_rate = 0.003\n",
    "        self.epoch = 90\n",
    "        self.patience = 4\n",
    "        self.batch_size = 16\n",
    "        self.optimizer = 'rmsprop'\n",
    "        self.weight_decay = 0\n",
    "        self.scheduler = 'none'\n",
    "        \n",
    "        self.model = 'L'\n",
    "        self.window_size = 9\n",
    "        self.fin_cols = ['평균가격-평년가격', '평균가격(원)_감자 수미_20키로상자_특', '감자_수미_100000_경매 건수']\n",
    "        self.forecast_size = 3\n",
    "        self.kernel_size = 15\n",
    "        self.individual = False\n",
    "        self.feature_size = len(self.fin_cols) + 1  # 주요 특징의 개수에 따라 조정\n",
    "        self.year = 2018\n",
    "        \n",
    "class garlic_config2:\n",
    "    def __init__(self):\n",
    "        self.seed = 25\n",
    "        self.learning_rate = 0.002\n",
    "        self.epoch = 113\n",
    "        self.patience = 5\n",
    "        self.batch_size = 8\n",
    "        self.optimizer = 'adam'\n",
    "        self.weight_decay = 1e-09\n",
    "        self.scheduler = 'none'\n",
    "        \n",
    "        self.model = 'D'\n",
    "        self.window_size = 9\n",
    "        self.fin_cols = ['마늘_깐마늘_100000_총반입량(kg)']\n",
    "        self.forecast_size = 3\n",
    "        self.kernel_size = 21\n",
    "        self.individual = True\n",
    "        self.feature_size = len(self.fin_cols) + 1\n",
    "        self.year = 2019\n",
    "\n",
    "class apple_config2:\n",
    "    def __init__(self):\n",
    "        self.seed = 332\n",
    "        self.learning_rate = 0.002\n",
    "        self.epoch = 120\n",
    "        self.patience = 6\n",
    "        self.batch_size = 8\n",
    "        self.optimizer = 'adam'\n",
    "        self.weight_decay = 1e-08\n",
    "        self.scheduler = 'none'\n",
    "        \n",
    "        self.model = 'D'\n",
    "        self.window_size = 9\n",
    "        self.fin_cols = ['평균가격-평년가격', '평년 평균가격(원) Common Year SOON', '사과_금액', '사과_평년 반입량 증감률(%)']\n",
    "        self.forecast_size =3\n",
    "        self.kernel_size = 13\n",
    "        self.individual = False\n",
    "        self.feature_size = len(self.fin_cols) + 1\n",
    "        self.year = 2018\n",
    "\n",
    "class lettuce_config2:\n",
    "    def __init__(self):\n",
    "        self.seed = 888\n",
    "        self.learning_rate = 0.002\n",
    "        self.epoch = 100\n",
    "        self.patience = 6\n",
    "        self.batch_size = 8\n",
    "        self.optimizer = 'rmsprop'\n",
    "        self.weight_decay = 1e-08\n",
    "        self.scheduler = 'none'\n",
    "        \n",
    "        self.model = 'D'\n",
    "        self.window_size = 9\n",
    "        self.fin_cols = ['평균가격-평년가격', '상추_포기찹_100000_경매 건수']\n",
    "        self.forecast_size = 3\n",
    "        self.kernel_size = 21\n",
    "        self.individual = True\n",
    "        self.feature_size = len(self.fin_cols) + 1\n",
    "        self.year = 2021\n",
    "\n",
    "class pepper_config2:\n",
    "    def __init__(self):\n",
    "        self.seed = 221\n",
    "        self.learning_rate = 0.0015\n",
    "        self.epoch = 79\n",
    "        self.patience = 5\n",
    "        self.batch_size = 32\n",
    "        self.optimizer = 'adam'\n",
    "        self.weight_decay = 1e-08\n",
    "        self.scheduler = 'none'\n",
    "        \n",
    "        self.fin_cols = ['평균가격-평년가격', '평균가격(원)_건고추_화건_중품_30']\n",
    "        self.window_size = 9\n",
    "        self.forecast_size = 3\n",
    "        self.kernel_size = 15\n",
    "        self.individual = True\n",
    "        self.feature_size = len(self.fin_cols) + 1\n",
    "        self.momentum_window = 3\n",
    "        self.n_heads = 1\n",
    "        self.year = 2020\n",
    "        \n",
    "class daepa_config2:\n",
    "    def __init__(self):\n",
    "        self.seed = 6\n",
    "        self.learning_rate = 0.001\n",
    "        self.epoch = 112\n",
    "        self.patience = 5\n",
    "        self.batch_size = 8\n",
    "        self.optimizer = 'rmsprop'\n",
    "        self.weight_decay = 0\n",
    "        self.scheduler = 'none'\n",
    "        \n",
    "        self.fin_cols = ['평균가격-평년가격', '평균가격(원)_쪽파_10키로상자_상', '대파_대파(일반)_100000_총반입량(kg)']\n",
    "        self.window_size = 9\n",
    "        self.forecast_size = 3\n",
    "        self.kernel_size = 15\n",
    "        self.individual = True\n",
    "        self.feature_size = len(self.fin_cols) + 1\n",
    "        self.momentum_window = 1\n",
    "        self.n_heads = 1\n",
    "        self.year = 2020\n",
    "\n",
    "class moo_config2:\n",
    "    def __init__(self):\n",
    "        self.seed = 101\n",
    "        self.learning_rate = 0.0025\n",
    "        self.epoch = 97\n",
    "        self.batch_size = 16\n",
    "        self.optimizer = 'adamw'\n",
    "        self.weight_decay = 1e-10\n",
    "        self.scheduler = 'none'\n",
    "        self.patience = 4 \n",
    "        \n",
    "        self.fin_cols = ['무_기타무_100000_평균가(원/kg)', '1000000000_무_기타무_11_경매 건수', '1000000000_무_기타무_11_총반입량(kg)']\n",
    "        self.window_size = 9\n",
    "        self.forecast_size = 3\n",
    "        self.kernel_size = 19\n",
    "        self.individual = False\n",
    "        self.feature_size = len(self.fin_cols) + 1\n",
    "        self.momentum_window = 3\n",
    "        self.n_heads = 3\n",
    "        self.year = 2018\n",
    "\n",
    "\n",
    "class cabbage_config2:\n",
    "    def __init__(self):\n",
    "        self.seed = 268\n",
    "        self.learning_rate = 0.0015\n",
    "        self.epoch = 73\n",
    "        self.batch_size = 16\n",
    "        self.optimizer = 'adam'\n",
    "        self.weight_decay = 0\n",
    "        self.scheduler = 'none'\n",
    "        \n",
    "        self.fin_cols = ['평균가격-평년가격', '평년 평균가격(원) Common Year SOON', '평균가격(원)_알배기배추_8키로상자_상', '배추_기타배추_100000_총반입량(kg)']\n",
    "        self.window_size = 9\n",
    "        self.forecast_size = 3\n",
    "        self.kernel_size = 21\n",
    "        self.individual = True\n",
    "        self.feature_size = len(self.fin_cols) + 1\n",
    "        self.momentum_window = 3\n",
    "        self.n_heads = 3\n",
    "        self.year = 2019\n",
    "        \n",
    "        \n",
    "class onion_config2:\n",
    "    def __init__(self):\n",
    "        self.seed = 3\n",
    "        self.learning_rate = 0.0025\n",
    "        self.epoch = 157\n",
    "        self.batch_size = 32\n",
    "        self.optimizer = 'adamw'\n",
    "        self.weight_decay = 1e-09\n",
    "        self.scheduler = 'none'\n",
    "        \n",
    "        self.fin_cols = ['평균가격-평년가격', '평균가격(원)_양파_12키로_상']\n",
    "        self.window_size = 9\n",
    "        self.forecast_size = 3\n",
    "        self.kernel_size = 17\n",
    "        self.individual = False\n",
    "        self.feature_size = len(self.fin_cols) + 1\n",
    "        self.momentum_window = 2\n",
    "        self.n_heads = 3\n",
    "        self.year = 2020\n",
    "\n",
    "\n",
    "class pear_config2:\n",
    "    def __init__(self):\n",
    "        self.seed = 337\n",
    "        self.learning_rate = 0.0015\n",
    "        self.epoch = 134\n",
    "        self.batch_size = 8\n",
    "        self.patience = 7 \n",
    "        self.optimizer = 'adam'\n",
    "        self.weight_decay = 0\n",
    "        self.step_size = 20      \n",
    "        self.gamma = 0.5 \n",
    "        self.scheduler = 'reduce_on_plateau'\n",
    "        \n",
    "        self.fin_cols = ['평균가격-평년가격', '배_신고_100000_고가(20%) 평균가']\n",
    "        self.window_size = 9\n",
    "        self.forecast_size = 3\n",
    "        self.kernel_size = 21\n",
    "        self.individual = True\n",
    "        self.feature_size = len(self.fin_cols) + 1\n",
    "        self.momentum_window = 3\n",
    "        self.n_heads = 3\n",
    "        self.year = 2019\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델학습 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단기 시계열 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dlin1(품목리스트 , config ):\n",
    "    # 감자, 깐마늘(국산), 사과, 상추 => jointmarket 불필요\n",
    "    seed_everything(config.seed) \n",
    "    \n",
    "    for item in 품목리스트:\n",
    "        config.feature_size = len(config.fin_cols) + 1\n",
    "        config.window_size = 3 \n",
    "        # 데이터 파일 및 메타 파일 설정\n",
    "        if item in group1:\n",
    "            train_file = \"../data/train/train_1.csv\"\n",
    "            meta_file = \"../data/train/meta/TRAIN_경락정보_가락도매_2018-2022.csv\"\n",
    "        elif item in group2:\n",
    "            train_file = \"../data/train/train_2.csv\"\n",
    "            meta_file = \"../data/train/meta/TRAIN_중도매_2018-2022.csv\"\n",
    "        elif item in group3:\n",
    "            train_file = \"../data/train/train_2.csv\"\n",
    "            meta_file = \"../data/train/meta/TRAIN_소매_2018-2022.csv\"\n",
    "        \n",
    "        # 필요한 열만 추려서 데이터 로드 및 병합\n",
    "        train_data = process_data(train_file, meta_file, item)\n",
    "        fincols = ['YYYYMMSOON', '평균가격(원)'] + [col for col in config.fin_cols if col in train_data.columns]\n",
    "        train_data = train_data[fincols]\n",
    "        dome_cols = ['YYYYMMSOON'] + [col for col in config.fin_cols if col in train_dome.columns]\n",
    "        train_dome_filtered = train_dome[dome_cols]\n",
    "        train_data = pd.merge(train_data, train_dome_filtered, how='left', on='YYYYMMSOON')\n",
    "\n",
    "        if item == '사과':\n",
    "            deal_cols = ['거래일자'] + [col for col in config.fin_cols if col in deal_info.columns]\n",
    "            deal_info_filtered = deal_info[deal_cols]\n",
    "            train_data = pd.merge(train_data, deal_info_filtered, how='left', left_on='YYYYMMSOON', right_on='거래일자')\n",
    "            \n",
    "        final_columns = ['평균가격(원)'] + config.fin_cols\n",
    "        train_data = train_data[final_columns]\n",
    "        \n",
    "        for col in train_data.columns:             interpolate_zeros(train_data, col) \n",
    "        \n",
    "        \n",
    "        offset = (config.year - 2018) * 36\n",
    "        train_data = train_data.iloc[offset: (144 + (3 * 12)), :]\n",
    "        train_data = train_data.fillna(0) \n",
    "        \n",
    "        price_df = train_data.reset_index(drop=True)\n",
    "        normalized_timedata, scaler = normalize_data(price_df) \n",
    "        train_dl = create_dataloader(normalized_timedata, config.window_size, config.forecast_size, config.batch_size)\n",
    "        \n",
    "        # dlinear만 사용\n",
    "        model = LTSF_DLinear(config)\n",
    "        model.to(device)\n",
    "        optimizer = get_optimizer(model, config)\n",
    "        scheduler = get_scheduler(optimizer, config)\n",
    "        criterion = NMAELoss()\n",
    "        for ep in range(1, config.epoch + 1):\n",
    "            model.train()\n",
    "            batch_losses = []\n",
    "            for idx, (data_batch, target) in enumerate(train_dl):\n",
    "                data_batch, target = data_batch.to(device), target.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data_batch)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                batch_losses.append(loss.item())\n",
    "            avg_loss = np.mean(batch_losses)\n",
    "            \n",
    "        os.makedirs('dl_weights2', exist_ok=True)\n",
    "        model_save_path = f'dl_weights2/{item}_model1_win3.pth'\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Model for {item} saved at {model_save_path}\")\n",
    "\n",
    "    return scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dlinAttn1(품목리스트,config):\n",
    "    # 건고추, 대파, 무, 배추, 양파, 배\n",
    "    seed_everything(config.seed) \n",
    "    for item in 품목리스트:\n",
    "        config.feature_size = len(config.fin_cols) + 1\n",
    "        \n",
    "        if item in group1:\n",
    "            train_file = \"../data/train/train_1.csv\"\n",
    "            meta_file = \"../data/train/meta/TRAIN_경락정보_가락도매_2018-2022.csv\"\n",
    "        elif item in group2:\n",
    "            train_file = \"../data/train/train_2.csv\"\n",
    "            meta_file = \"../data/train/meta/TRAIN_중도매_2018-2022.csv\"\n",
    "        elif item in group3:\n",
    "            train_file = \"../data/train/train_2.csv\"\n",
    "            meta_file = \"../data/train/meta/TRAIN_소매_2018-2022.csv\"\n",
    "        \n",
    "        # 필요한 열만 추려서 데이터 로드 및 병합\n",
    "        train_data = process_data(train_file, meta_file, item)\n",
    "        # train_data에서 필요한 열 중 실제 존재하는 열만 선택\n",
    "        fincols = ['YYYYMMSOON', '평균가격(원)'] + [col for col in config.fin_cols if col in train_data.columns]\n",
    "        train_data = train_data[fincols]\n",
    "        \n",
    "        # train_dome에서도 필요한 열만 선택\n",
    "        dome_cols = ['YYYYMMSOON'] + [col for col in config.fin_cols if col in train_dome.columns]\n",
    "        train_dome_filtered = train_dome[dome_cols]\n",
    "        train_data = pd.merge(train_data, train_dome_filtered, how='left', on='YYYYMMSOON')\n",
    "        \n",
    "        # 조건에 따라 추가적인 병합 처리\n",
    "        if item in ['대파(일반)', '무']:\n",
    "            joint_cols = ['YYYYMMSOON'] + [col for col in config.fin_cols if col in train_jointmarket.columns]\n",
    "            train_jointmarket_filtered = train_jointmarket[joint_cols]\n",
    "            train_data = pd.merge(train_data, train_jointmarket_filtered, how='left', on='YYYYMMSOON')\n",
    "        elif item == '배':\n",
    "            deal_cols = ['거래일자'] + [col for col in config.fin_cols if col in deal_info.columns]\n",
    "            deal_info_filtered = deal_info[deal_cols]\n",
    "            train_data = pd.merge(train_data, deal_info_filtered, how='left', left_on='YYYYMMSOON', right_on='거래일자')\n",
    "\n",
    "        final_columns = ['평균가격(원)'] + config.fin_cols \n",
    "        train_data = train_data[final_columns]\n",
    "        \n",
    "        \n",
    "        offset = (config.year - 2018) * 36\n",
    "        train_data = train_data.iloc[offset: (144 + (3 * 12)), :]\n",
    "        train_data = train_data.fillna(0) \n",
    "        for col in train_data.columns:\n",
    "            interpolate_zeros(train_data, col)\n",
    "        price_df = train_data.reset_index(drop=True)\n",
    "        normalized_timedata, scaler = normalize_data(price_df) \n",
    "        train_dl = create_dataloader(normalized_timedata, config.window_size, config.forecast_size, config.batch_size)\n",
    "        \n",
    "        model = ModelWithMultiheadAttention(config)\n",
    "        model.to(device)\n",
    "        optimizer = get_optimizer(model, config)\n",
    "        scheduler = get_scheduler(optimizer, config)\n",
    "        criterion = NMAELoss()\n",
    "        \n",
    "        for ep in range(1, config.epoch + 1):\n",
    "            model.train()\n",
    "            batch_losses = []\n",
    "            for idx, (data_batch, target) in enumerate(train_dl):\n",
    "                data_batch, target = data_batch.to(device), target.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data_batch)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                batch_losses.append(loss.item())\n",
    "\n",
    "            if ep % 5 == 0:                avg_loss = np.mean(batch_losses)\n",
    "            \n",
    "        os.makedirs('dl_weights2', exist_ok=True)\n",
    "        model_save_path = f'dl_weights2/{item}_model1_win3.pth'\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Model for {item} saved at {model_save_path}\")\n",
    "    \n",
    "    return scaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 장기 시계열 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dlin2(품목리스트,config):\n",
    "    # 감자, 깐마늘(국산), 사과, 상추 => jointmarket 불필요\n",
    "    # 데이터 선형보간 해야해 \n",
    "    seed_everything(config.seed) \n",
    "    for item in 품목리스트:\n",
    "        config.feature_size = len(config.fin_cols) + 1\n",
    "        \n",
    "        \n",
    "        # 데이터 파일 및 메타 파일 설정\n",
    "        if item in group1:\n",
    "            train_file = \"../data/train/train_1.csv\"\n",
    "            meta_file = \"../data/train/meta/TRAIN_경락정보_가락도매_2018-2022.csv\"\n",
    "        elif item in group2:\n",
    "            train_file = \"../data/train/train_2.csv\"\n",
    "            meta_file = \"../data/train/meta/TRAIN_중도매_2018-2022.csv\"\n",
    "        elif item in group3:\n",
    "            train_file = \"../data/train/train_2.csv\"\n",
    "            meta_file = \"../data/train/meta/TRAIN_소매_2018-2022.csv\"\n",
    "        \n",
    "        # 필요한 열만 추려서 데이터 로드 및 병합\n",
    "        train_data = process_data(train_file, meta_file, item)\n",
    "        if item!='깐마늘(국산)':\n",
    "            interpolate_zeros(train_data,'평년 평균가격(원) Common Year SOON')\n",
    "            train_data['평균가격-평년가격'] = train_data['평균가격(원)']-train_data['평년 평균가격(원) Common Year SOON']\n",
    "    \n",
    "    \n",
    "        fincols = ['YYYYMMSOON', '평균가격(원)'] + [col for col in config.fin_cols if col in train_data.columns]\n",
    "        train_data = train_data[fincols]\n",
    "        dome_cols = ['YYYYMMSOON'] + [col for col in config.fin_cols if col in train_dome.columns]\n",
    "        train_dome_filtered = train_dome[dome_cols]\n",
    "        train_data = pd.merge(train_data, train_dome_filtered, how='left', on='YYYYMMSOON')\n",
    "\n",
    "        if item == '사과':\n",
    "            deal_cols = ['거래일자'] + [col for col in config.fin_cols if col in deal_info.columns]\n",
    "            deal_info_filtered = deal_info[deal_cols]\n",
    "            train_data = pd.merge(train_data, deal_info_filtered, how='left', left_on='YYYYMMSOON', right_on='거래일자')\n",
    "            # interpolate_zeros(train_data, '사과_평년 반입량 증감률(%)')\n",
    "        \n",
    "        final_columns = ['평균가격(원)'] + config.fin_cols\n",
    "        train_data = train_data[final_columns]\n",
    "        # print(train_data.columns) \n",
    "        for col in train_data.columns : interpolate_zeros(train_data,col  )\n",
    "        \n",
    "        offset = (config.year - 2018) * 36\n",
    "        train_data = train_data.iloc[offset: (144 + (3 * 12)), :]\n",
    "        train_data = train_data.fillna(0) \n",
    "        price_df = train_data.reset_index(drop=True)\n",
    "        normalized_timedata, scaler = normalize_data(price_df) \n",
    "        train_dl = create_dataloader(normalized_timedata, config.window_size, config.forecast_size, config.batch_size)\n",
    "        \n",
    "        \n",
    "        if item== '감자 수미' :model = LinModel(config) \n",
    "        else : model = LTSF_DLinear(config) \n",
    "        \n",
    "        model.to(device)\n",
    "        optimizer = get_optimizer(model, config)\n",
    "        scheduler = get_scheduler(optimizer, config)\n",
    "        criterion = NMAELoss()\n",
    "        \n",
    "        for ep in range(1, config.epoch + 1):\n",
    "            model.train()\n",
    "            batch_losses = []\n",
    "            for idx, (data_batch, target) in enumerate(train_dl):\n",
    "                data_batch, target = data_batch.to(device), target.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data_batch)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                batch_losses.append(loss.item())\n",
    "            if ep % 5 == 0:                avg_loss = np.mean(batch_losses)\n",
    "            \n",
    "        os.makedirs('dl_weights2', exist_ok=True)\n",
    "        model_save_path = f'dl_weights2/{item}_model2_win9.pth'\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Model for {item} saved at {model_save_path}\")\n",
    "    return scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dlinAttn2(품목리스트,config):\n",
    "    # 건고추, 대파, 무, 배추, 양파, 배\n",
    "    seed_everything(config.seed) \n",
    "    \n",
    "    for item in 품목리스트:\n",
    "        # 데이터 파일 로드\n",
    "        if item in group1:\n",
    "            train_file = \"../data/train/train_1.csv\"\n",
    "            meta_file = \"../data/train/meta/TRAIN_경락정보_가락도매_2018-2022.csv\"\n",
    "        elif item in group2:\n",
    "            train_file = \"../data/train/train_2.csv\"\n",
    "            meta_file = \"../data/train/meta/TRAIN_중도매_2018-2022.csv\"\n",
    "        elif item in group3:\n",
    "            train_file = \"../data/train/train_2.csv\"\n",
    "            meta_file = \"../data/train/meta/TRAIN_소매_2018-2022.csv\"\n",
    "        \n",
    "        # 필요한 열만 추려서 데이터 로드 및 병합\n",
    "        train_data = process_data(train_file, meta_file, item)\n",
    "        # 평년 가격 보간 이후 평균가격-평년가격 생성 \n",
    "        # if item !='무':\n",
    "        #     interpolate_zeros(train_data,'평년 평균가격(원) Common Year SOON')\n",
    "        #     train_data['평균가격-평년가격'] = train_data['평균가격(원)']-train_data['평년 평균가격(원) Common Year SOON']\n",
    "        if item!='배':\n",
    "            for col in train_data.columns : interpolate_zeros(train_data , col) \n",
    "        train_data['평균가격-평년가격'] = train_data['평균가격(원)']-train_data['평년 평균가격(원) Common Year SOON']\n",
    "            \n",
    "        \n",
    "        # train_data에서 필요한 열 중 실제 존재하는 열만 선택\n",
    "        fincols = ['YYYYMMSOON', '평균가격(원)'] + [col for col in config.fin_cols if col in train_data.columns]\n",
    "        train_data = train_data[fincols]\n",
    "        \n",
    "        # train_dome에서도 필요한 열만 선택\n",
    "        dome_cols = ['YYYYMMSOON'] + [col for col in config.fin_cols if col in train_dome.columns]\n",
    "        train_dome_filtered = train_dome[dome_cols]\n",
    "        train_data = pd.merge(train_data, train_dome_filtered, how='left', on='YYYYMMSOON')\n",
    "        \n",
    "        # 조건에 따라 추가적인 병합 처리\n",
    "        if item in ['대파(일반)', '무']:\n",
    "            joint_cols = ['YYYYMMSOON'] + [col for col in config.fin_cols if col in train_jointmarket.columns]\n",
    "            train_jointmarket_filtered = train_jointmarket[joint_cols]\n",
    "            train_data = pd.merge(train_data, train_jointmarket_filtered, how='left', on='YYYYMMSOON')\n",
    "        elif item == '배':\n",
    "            deal_cols = ['거래일자'] + [col for col in config.fin_cols if col in deal_info.columns]\n",
    "            deal_info_filtered = deal_info[deal_cols]\n",
    "            train_data = pd.merge(train_data, deal_info_filtered, how='left', left_on='YYYYMMSOON', right_on='거래일자')\n",
    "\n",
    "        # if item=='배' :\n",
    "        #     # interpolate_zeros(train_data, '배_신고_100000_고가(20%) 평균가')\n",
    "        #     # for col in train_data.columns : interpolate_zeros(train_data, train_data.columns)\n",
    "        final_columns = ['평균가격(원)'] + config.fin_cols \n",
    "        train_data = train_data[final_columns]\n",
    "        print(train_data.columns) \n",
    "        \n",
    "        offset = (config.year - 2018) * 36\n",
    "        train_data = train_data.iloc[offset: (144 + (3 * 12)), :]\n",
    "        train_data = train_data.fillna(0) \n",
    "\n",
    "        price_df = train_data.reset_index(drop=True)\n",
    "        normalized_timedata, scaler = normalize_data(price_df) \n",
    "        train_dl = create_dataloader(normalized_timedata, config.window_size, config.forecast_size, config.batch_size)\n",
    "        \n",
    "        model = ModelWithMultiheadAttention(config)\n",
    "        model.to(device)\n",
    "        optimizer = get_optimizer(model, config)\n",
    "        scheduler = get_scheduler(optimizer, config)\n",
    "        criterion = NMAELoss()\n",
    "        for ep in range(1, config.epoch + 1):\n",
    "            model.train()\n",
    "            batch_losses = []\n",
    "            for idx, (data_batch, target) in enumerate(train_dl):\n",
    "                data_batch, target = data_batch.to(device), target.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data_batch)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                batch_losses.append(loss.item())\n",
    "\n",
    "            avg_loss = np.mean(batch_losses)\n",
    "            if config.scheduler.lower()=='reduce_on_plateau':scheduler.step(avg_loss)\n",
    "        os.makedirs('dl_weights2', exist_ok=True)\n",
    "        model_save_path = f'dl_weights2/{item}_model2_win9.pth'\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Model for {item} saved at {model_save_path}\")\n",
    "        \n",
    "    return scaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습 및 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단기 모델 학습 및 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for 감자 수미 saved at dl_weights2/감자 수미_model1_win3.pth\n",
      "Model for 건고추 saved at dl_weights2/건고추_model1_win3.pth\n",
      "Model for 깐마늘(국산) saved at dl_weights2/깐마늘(국산)_model1_win3.pth\n",
      "Model for 대파(일반) saved at dl_weights2/대파(일반)_model1_win3.pth\n",
      "Model for 무 saved at dl_weights2/무_model1_win3.pth\n",
      "Model for 배추 saved at dl_weights2/배추_model1_win3.pth\n",
      "Model for 사과 saved at dl_weights2/사과_model1_win3.pth\n",
      "Model for 상추 saved at dl_weights2/상추_model1_win3.pth\n",
      "Model for 양파 saved at dl_weights2/양파_model1_win3.pth\n",
      "Model for 배 saved at dl_weights2/배_model1_win3.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "potato_scaler1 = train_dlin1(['감자 수미'] , potato_config1())\n",
    "pepper_scaler1 = train_dlinAttn1(['건고추'] , pepper_config1())\n",
    "garlic_scaler1 = train_dlin1(['깐마늘(국산)'] , garlic_config1())\n",
    "daepa_scaler1  = train_dlinAttn1(['대파(일반)'] , daepa_config1())\n",
    "moo_scaler1    = train_dlinAttn1(['무'] , moo_config1())\n",
    "cabbage_scaler1= train_dlinAttn1(['배추'] , cabbage_config1())\n",
    "apple_scaler1  = train_dlin1(['사과'] , apple_config1())\n",
    "lettuce_scaler1= train_dlin1(['상추'] , lettuce_config1())\n",
    "onion_scaler1  = train_dlinAttn1(['양파'] , onion_config1())\n",
    "pear_scaler1   = train_dlinAttn1(['배'] , pear_config1())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 장기 모델 학습 및 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for 감자 수미 saved at dl_weights2/감자 수미_model2_win9.pth\n",
      "Index(['평균가격(원)', '평균가격-평년가격', '평균가격(원)_건고추_화건_중품_30'], dtype='object')\n",
      "Model for 건고추 saved at dl_weights2/건고추_model2_win9.pth\n",
      "Model for 깐마늘(국산) saved at dl_weights2/깐마늘(국산)_model2_win9.pth\n",
      "Index(['평균가격(원)', '평균가격-평년가격', '평균가격(원)_쪽파_10키로상자_상',\n",
      "       '대파_대파(일반)_100000_총반입량(kg)'],\n",
      "      dtype='object')\n",
      "Model for 대파(일반) saved at dl_weights2/대파(일반)_model2_win9.pth\n",
      "Index(['평균가격(원)', '무_기타무_100000_평균가(원/kg)', '1000000000_무_기타무_11_경매 건수',\n",
      "       '1000000000_무_기타무_11_총반입량(kg)'],\n",
      "      dtype='object')\n",
      "Model for 무 saved at dl_weights2/무_model2_win9.pth\n",
      "Index(['평균가격(원)', '평균가격-평년가격', '평년 평균가격(원) Common Year SOON',\n",
      "       '평균가격(원)_알배기배추_8키로상자_상', '배추_기타배추_100000_총반입량(kg)'],\n",
      "      dtype='object')\n",
      "Model for 배추 saved at dl_weights2/배추_model2_win9.pth\n",
      "Model for 사과 saved at dl_weights2/사과_model2_win9.pth\n",
      "Model for 상추 saved at dl_weights2/상추_model2_win9.pth\n",
      "Index(['평균가격(원)', '평균가격-평년가격', '평균가격(원)_양파_12키로_상'], dtype='object')\n",
      "Model for 양파 saved at dl_weights2/양파_model2_win9.pth\n",
      "Index(['평균가격(원)', '평균가격-평년가격', '배_신고_100000_고가(20%) 평균가'], dtype='object')\n",
      "Model for 배 saved at dl_weights2/배_model2_win9.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "potato_scaler2 = train_dlin2(['감자 수미'] , potato_config2())\n",
    "pepper_scaler2 = train_dlinAttn2(['건고추'] , pepper_config2())\n",
    "garlic_scaler2 = train_dlin2(['깐마늘(국산)'] , garlic_config2())\n",
    "daepa_scaler2  = train_dlinAttn2(['대파(일반)'] , daepa_config2())\n",
    "moo_scaler2    = train_dlinAttn2(['무'] , moo_config2())\n",
    "cabbage_scaler2= train_dlinAttn2(['배추'] , cabbage_config2())\n",
    "apple_scaler2  = train_dlin2(['사과'] , apple_config2())\n",
    "lettuce_scaler2= train_dlin2(['상추'] , lettuce_config2())\n",
    "onion_scaler2  = train_dlinAttn2(['양파'] , onion_config2())\n",
    "pear_scaler2   = train_dlinAttn2(['배'] , pear_config2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추론 시작 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_dlin2(품목리스트, config, scaler) :\n",
    "    # 감자는 Linear로 하기 \n",
    "    seed_everything(config.seed)\n",
    "    predicts={}\n",
    "    \n",
    "    for item in 품목리스트:\n",
    "        # 모델 불러오기\n",
    "        if item == '감자 수미' :model = LinModel(config) \n",
    "        else :model = LTSF_DLinear(config)\n",
    "        \n",
    "        model_path = f\"dl_weights2/{item}_model2_win9.pth\"\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        item_test_tensors = []\n",
    "        \n",
    "        for i in range(52):\n",
    "            if item in group1:\n",
    "                test_file = f\"../data/test/TEST_{i:02d}_1.csv\"\n",
    "                meta_file = f\"../data/test/meta/TEST_경락정보_가락도매_{i:02d}.csv\"\n",
    "            elif item in group2:\n",
    "                test_file = f\"../data/test/TEST_{i:02d}_2.csv\"\n",
    "                meta_file = f\"../data/test/meta/TEST_중도매_{i:02d}.csv\"\n",
    "            elif item in group3:\n",
    "                test_file = f\"../data/test/TEST_{i:02d}_2.csv\"\n",
    "                meta_file = f\"../data/test/meta/TEST_소매_{i:02d}.csv\"\n",
    "            test_data = process_data(test_file, meta_file, item)\n",
    "            if item!='깐마늘(국산)':\n",
    "                interpolate_zeros(test_data,'평년 평균가격(원) Common Year SOON')\n",
    "                test_data['평균가격-평년가격'] = test_data['평균가격(원)']-test_data['평년 평균가격(원) Common Year SOON']\n",
    "            fincols = ['YYYYMMSOON', '평균가격(원)'] + [col for col in config.fin_cols if col in test_data.columns]\n",
    "            test_data = test_data[fincols]\n",
    "            dome_cols = ['YYYYMMSOON'] + [col for col in config.fin_cols if col in test_dome.columns]\n",
    "            test_dome_filtered = test_dome[dome_cols]\n",
    "            test_data = pd.merge(test_data, test_dome_filtered, how='left', on='YYYYMMSOON')\n",
    "\n",
    "            if item == '사과':\n",
    "                deal_cols = ['거래일자'] + [col for col in config.fin_cols if col in deal_info.columns]\n",
    "                deal_info_filtered = deal_info[deal_cols]\n",
    "                test_data = pd.merge(test_data, deal_info_filtered, how='left', left_on='YYYYMMSOON', right_on='거래일자')\n",
    "                interpolate_zeros(test_data, '사과_평년 반입량 증감률(%)')\n",
    "            final_columns = ['평균가격(원)'] + config.fin_cols\n",
    "            \n",
    "            test_data = test_data[final_columns]\n",
    "            # print(test_data.columns) \n",
    "            # for col in\n",
    "            test_price_df = test_data.reset_index(drop=True)\n",
    "            test_price_df = test_price_df.iloc[-1 * config.window_size:, :]\n",
    "            normalized_testdata = scaler.transform(test_price_df)\n",
    "            test_tensor = torch.tensor(normalized_testdata, dtype=torch.float32)\n",
    "            item_test_tensors.append(test_tensor)\n",
    "            \n",
    "        item_test_batch = torch.stack(item_test_tensors).to(device)  # (52, window_size, feature_size)\n",
    "        # 모델 예측\n",
    "        with torch.no_grad():\n",
    "            prediction = model(item_test_batch)\n",
    "        prediction = prediction.cpu().numpy()  # Shape: (52, forecast_size, feature_size)\n",
    "        product_predict = []\n",
    "        for pred in prediction:\n",
    "            inverse_pred = inverse_normalize(pred, scaler)\n",
    "            product_predict.append(inverse_pred[:, 0])\n",
    "        flatlist = np.concatenate(product_predict).tolist()\n",
    "        predicts[item] = flatlist\n",
    "    return predicts \n",
    "\n",
    "\n",
    "\n",
    "def infer_dlinAttn2(품목리스트,config, scaler) :\n",
    "    seed_everything(config.seed)\n",
    "    predicts={}\n",
    "    \n",
    "    for item in 품목리스트:\n",
    "        # 모델 불러오기\n",
    "        model = ModelWithMultiheadAttention(config)\n",
    "        model_path = f\"dl_weights2/{item}_model2_win9.pth\"\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        item_test_tensors = []\n",
    "        for i in range(52):\n",
    "            if item in group1:\n",
    "                test_file = f\"../data/test/TEST_{i:02d}_1.csv\"\n",
    "                meta_file = f\"../data/test/meta/TEST_경락정보_가락도매_{i:02d}.csv\"\n",
    "            elif item in group2:\n",
    "                test_file = f\"../data/test/TEST_{i:02d}_2.csv\"\n",
    "                meta_file = f\"../data/test/meta/TEST_중도매_{i:02d}.csv\"\n",
    "            elif item in group3:\n",
    "                test_file = f\"../data/test/TEST_{i:02d}_2.csv\"\n",
    "                meta_file = f\"../data/test/meta/TEST_소매_{i:02d}.csv\"\n",
    "            test_data = process_data(test_file, meta_file, item)\n",
    "            if item !='무':\n",
    "                \n",
    "                interpolate_zeros(test_data,'평년 평균가격(원) Common Year SOON')\n",
    "                test_data['평균가격-평년가격'] = test_data['평균가격(원)']-test_data['평년 평균가격(원) Common Year SOON']\n",
    "                # if item =='배' :print('배  평년가격 평균 차이 계산 ')\n",
    "\n",
    "            \n",
    "            fincols = ['YYYYMMSOON', '평균가격(원)'] + [col for col in config.fin_cols if col in test_data.columns]\n",
    "            test_data = test_data[fincols]\n",
    "            \n",
    "            dome_cols = ['YYYYMMSOON'] + [col for col in config.fin_cols if col in test_dome.columns]\n",
    "            test_dome_filtered = test_dome[dome_cols]\n",
    "            test_data = pd.merge(test_data, test_dome_filtered, how='left', on='YYYYMMSOON')\n",
    "            \n",
    "            if item in ['대파(일반)', '무']:\n",
    "                joint_cols = ['YYYYMMSOON'] + [col for col in config.fin_cols if col in test_jointmarket.columns]\n",
    "                test_jointmarket_filtered = test_jointmarket[joint_cols]\n",
    "                test_data = pd.merge(test_data, test_jointmarket_filtered, how='left', on='YYYYMMSOON')\n",
    "            elif item == '배':\n",
    "                deal_cols = ['거래일자'] + [col for col in config.fin_cols if col in deal_info.columns]\n",
    "                deal_info_filtered = deal_info[deal_cols]\n",
    "                test_data = pd.merge(test_data, deal_info_filtered, how='left', left_on='YYYYMMSOON', right_on='거래일자')\n",
    "                \n",
    "            final_columns = ['평균가격(원)'] + config.fin_cols \n",
    "            test_data = test_data[final_columns]\n",
    "            \n",
    "            test_price_df = test_data.reset_index(drop=True)\n",
    "            test_price_df = test_price_df.iloc[-1 * config.window_size:, :]\n",
    "            normalized_testdata = scaler.transform(test_price_df)\n",
    "            test_tensor = torch.tensor(normalized_testdata, dtype=torch.float32)\n",
    "            item_test_tensors.append(test_tensor)\n",
    "        item_test_batch = torch.stack(item_test_tensors).to(device)  # (52, window_size, feature_size)\n",
    "        # 모델 예측\n",
    "        with torch.no_grad():\n",
    "            prediction = model(item_test_batch)\n",
    "        prediction = prediction.cpu().numpy()  # Shape: (52, forecast_size, feature_size)\n",
    "        product_predict = []\n",
    "        for pred in prediction:\n",
    "            inverse_pred = inverse_normalize(pred, scaler)\n",
    "            product_predict.append(inverse_pred[:, 0])\n",
    "        flatlist = np.concatenate(product_predict).tolist()\n",
    "        predicts[item] = flatlist\n",
    "    return predicts \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_dlinAttn1(품목리스트,config, scaler):\n",
    "    # windowsize = 3, forecasting size = 2 \n",
    "    seed_everything(config.seed)\n",
    "    predicts={}\n",
    "    \n",
    "    for item in 품목리스트:\n",
    "        print(f\"Processing {item}\")\n",
    "        # 모델 불러오기\n",
    "        model = ModelWithMultiheadAttention(config)\n",
    "        model_path = f\"dl_weights2/{item}_model1_win{config.window_size}.pth\"\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        item_test_tensors = []\n",
    "        \n",
    "        for i in range(52):\n",
    "            if item in group1:\n",
    "                test_file = f\"../data/test/TEST_{i:02d}_1.csv\"\n",
    "                meta_file = f\"../data/test/meta/TEST_경락정보_가락도매_{i:02d}.csv\"\n",
    "            elif item in group2:\n",
    "                test_file = f\"../data/test/TEST_{i:02d}_2.csv\"\n",
    "                meta_file = f\"../data/test/meta/TEST_중도매_{i:02d}.csv\"\n",
    "            elif item in group3:\n",
    "                test_file = f\"../data/test/TEST_{i:02d}_2.csv\"\n",
    "                meta_file = f\"../data/test/meta/TEST_소매_{i:02d}.csv\"\n",
    "            test_data = process_data(test_file, meta_file, item)\n",
    "            fincols = ['YYYYMMSOON', '평균가격(원)'] + [col for col in config.fin_cols if col in test_data.columns]\n",
    "            test_data = test_data[fincols]\n",
    "            dome_cols = ['YYYYMMSOON'] + [col for col in config.fin_cols if col in test_dome.columns]\n",
    "            test_dome_filtered = test_dome[dome_cols]\n",
    "            test_data = pd.merge(test_data, test_dome_filtered, how='left', on='YYYYMMSOON')\n",
    "            \n",
    "            if item in ['대파(일반)', '무']:\n",
    "                joint_cols = ['YYYYMMSOON'] + [col for col in config.fin_cols if col in test_jointmarket.columns]\n",
    "                test_jointmarket_filtered = test_jointmarket[joint_cols]\n",
    "                test_data = pd.merge(test_data, test_jointmarket_filtered, how='left', on='YYYYMMSOON')\n",
    "            elif item == '배':\n",
    "                deal_cols = ['거래일자'] + [col for col in config.fin_cols if col in deal_info.columns]\n",
    "                deal_info_filtered = deal_info[deal_cols]\n",
    "                test_data = pd.merge(test_data, deal_info_filtered, how='left', left_on='YYYYMMSOON', right_on='거래일자')\n",
    "            \n",
    "            final_columns = ['평균가격(원)'] + config.fin_cols\n",
    "            test_data = test_data[final_columns]\n",
    "            \n",
    "            \n",
    "            test_price_df = test_data.reset_index(drop=True)\n",
    "            test_price_df = test_price_df.iloc[-1 * config.window_size:, :]\n",
    "            normalized_testdata = scaler.transform(test_price_df)\n",
    "            test_tensor = torch.tensor(normalized_testdata, dtype=torch.float32)\n",
    "            item_test_tensors.append(test_tensor)\n",
    "        \n",
    "        # 품목별 테스트 텐서를 하나의 텐서로 결합\n",
    "        item_test_batch = torch.stack(item_test_tensors).to(device)  # (52, window_size, feature_size)\n",
    "        # 모델 예측\n",
    "        with torch.no_grad():\n",
    "            prediction = model(item_test_batch)\n",
    "            \n",
    "        prediction = prediction.cpu().numpy()  # Shape: (52, forecast_size, feature_size)\n",
    "        product_predict = []\n",
    "        for pred in prediction:\n",
    "            inverse_pred = inverse_normalize(pred, scaler)\n",
    "            extended_pred = np.append(inverse_pred[:, 0], 0)\n",
    "            product_predict.append(extended_pred)\n",
    "        flatlist = np.concatenate(product_predict).tolist()\n",
    "        predicts[item] = flatlist\n",
    "    return predicts \n",
    "\n",
    "\n",
    "def infer_dlin1(품목리스트, config, scaler):\n",
    "    seed_everything(config.seed)\n",
    "    predicts = {}\n",
    "    \n",
    "    for item in 품목리스트:\n",
    "        print(f\"Processing {item}\")\n",
    "        # 모델 불러오기\n",
    "        model = LTSF_DLinear(config)\n",
    "        model_path = f\"dl_weights2/{item}_model1_win3.pth\"\n",
    "        \n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.to(device)\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        # 품목별 테스트 데이터를 저장할 리스트\n",
    "        item_test_tensors = []\n",
    "        \n",
    "        for i in range(52):\n",
    "            if item in group1:\n",
    "                test_file = f\"../data/test/TEST_{i:02d}_1.csv\"\n",
    "                meta_file = f\"../data/test/meta/TEST_경락정보_가락도매_{i:02d}.csv\"\n",
    "            elif item in group2:\n",
    "                test_file = f\"../data/test/TEST_{i:02d}_2.csv\"\n",
    "                meta_file = f\"../data/test/meta/TEST_중도매_{i:02d}.csv\"\n",
    "            elif item in group3:\n",
    "                test_file = f\"../data/test/TEST_{i:02d}_2.csv\"\n",
    "                meta_file = f\"../data/test/meta/TEST_소매_{i:02d}.csv\"\n",
    "            else:\n",
    "                continue  # 해당 품목이 어떤 그룹에도 속하지 않으면 넘어감\n",
    "\n",
    "            test_data = process_data(test_file, meta_file, item)\n",
    "            fincols = ['YYYYMMSOON', '평균가격(원)'] + [col for col in config.fin_cols if col in test_data.columns]\n",
    "            test_data = test_data[fincols]\n",
    "            dome_cols = ['YYYYMMSOON'] + [col for col in config.fin_cols if col in test_dome.columns]\n",
    "            test_dome_filtered = test_dome[dome_cols]\n",
    "            test_data = pd.merge(test_data, test_dome_filtered, how='left', on='YYYYMMSOON')\n",
    "            if item == '사과':\n",
    "                deal_cols = ['거래일자'] + [col for col in config.fin_cols if col in deal_info.columns]\n",
    "                deal_info_filtered = deal_info[deal_cols]\n",
    "                test_data = pd.merge(test_data, deal_info_filtered, how='left', left_on='YYYYMMSOON', right_on='거래일자')\n",
    "                interpolate_zeros(test_data, '사과_평년 반입량 증감률(%)')\n",
    "                \n",
    "                \n",
    "            final_columns = ['평균가격(원)'] + config.fin_cols\n",
    "            test_data = test_data[final_columns]\n",
    "            \n",
    "            \n",
    "            \n",
    "            test_price_df = test_data.reset_index(drop=True)\n",
    "            test_price_df = test_price_df.iloc[-1 * config.window_size:, :]\n",
    "            normalized_testdata = scaler.transform(test_price_df)\n",
    "            test_tensor = torch.tensor(normalized_testdata, dtype=torch.float32)\n",
    "            item_test_tensors.append(test_tensor)\n",
    "        \n",
    "        # 품목별 테스트 텐서를 하나의 텐서로 결합\n",
    "        item_test_batch = torch.stack(item_test_tensors).to(device)  # (52, window_size, feature_size)\n",
    "        \n",
    "        # 모델 예측\n",
    "        with torch.no_grad():\n",
    "            prediction = model(item_test_batch)\n",
    "        \n",
    "        prediction = prediction.cpu().numpy()  # Shape: (52, forecast_size, feature_size)\n",
    "        \n",
    "        # 예측 결과 처리 및 길이 맞춤\n",
    "        product_predict = []\n",
    "        for pred in prediction:\n",
    "            inverse_pred = inverse_normalize(pred, scaler)\n",
    "            # forecast_size는 항상 2이므로, 예측 결과에 0을 추가하여 길이 맞춤\n",
    "            extended_pred = np.append(inverse_pred[:, 0], 0)\n",
    "            product_predict.append(extended_pred)\n",
    "        \n",
    "        flatlist = np.concatenate(product_predict).tolist()\n",
    "        predicts[item] = flatlist\n",
    "    \n",
    "    return predicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 감자 수미\n",
      "Processing 깐마늘(국산)\n",
      "Processing 사과\n",
      "Processing 상추\n",
      "Processing 건고추\n",
      "Processing 대파(일반)\n",
      "Processing 무\n",
      "Processing 배추\n",
      "Processing 양파\n",
      "Processing 배\n"
     ]
    }
   ],
   "source": [
    "potato_preds1 = infer_dlin1(['감자 수미'] ,potato_config1(),potato_scaler1 )\n",
    "garlic_preds1 = infer_dlin1(['깐마늘(국산)'] ,garlic_config1(),garlic_scaler1 ) \n",
    "apple_preds1 = infer_dlin1(['사과'] ,apple_config1(),apple_scaler1 ) \n",
    "lettuce_preds1 = infer_dlin1(['상추'] ,lettuce_config1(),lettuce_scaler1 )\n",
    "\n",
    "pepper_preds1 = infer_dlinAttn1(['건고추'] ,pepper_config1(),pepper_scaler1 )\n",
    "daepa_preds1 = infer_dlinAttn1(['대파(일반)'] ,daepa_config1(),daepa_scaler1 )\n",
    "moo_preds1 = infer_dlinAttn1(['무'] ,moo_config1(),moo_scaler1 )\n",
    "cabbage_preds1 = infer_dlinAttn1(['배추'] ,cabbage_config1(),cabbage_scaler1 )\n",
    "onion_preds1 = infer_dlinAttn1(['양파'] ,onion_config1(),onion_scaler1 ) \n",
    "pear_preds1 = infer_dlinAttn1(['배'] ,pear_config1(),pear_scaler1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# potato_preds2 = infer_dlin2(['감자 수미'] ,potato_config2(),potato_scaler2 )\n",
    "garlic_preds2 = infer_dlin2(['깐마늘(국산)'] ,garlic_config2(),garlic_scaler2 ) \n",
    "apple_preds2 = infer_dlin2(['사과'] ,apple_config2(),apple_scaler2 ) \n",
    "lettuce_preds2 = infer_dlin2(['상추'] ,lettuce_config2(),lettuce_scaler2 )\n",
    "\n",
    "pepper_preds2 = infer_dlinAttn2(['건고추'] ,pepper_config2(),pepper_scaler2 )\n",
    "daepa_preds2 = infer_dlinAttn2(['대파(일반)'] ,daepa_config2(),daepa_scaler2 )\n",
    "moo_preds2 = infer_dlinAttn2(['무'] ,moo_config2(),moo_scaler2 )\n",
    "cabbage_preds2 = infer_dlinAttn2(['배추'] ,cabbage_config2(),cabbage_scaler2 )\n",
    "onion_preds2 = infer_dlinAttn2(['양파'] ,onion_config2(),onion_scaler2 ) \n",
    "# pear_preds2 = infer_dlinAttn2(['배'] ,pear_config2(),pear_scaler2 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제출파일 생성하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_model1 =pd.read_csv('../data/sample_submission.csv')\n",
    "dl_model2 =pd.read_csv('../data/sample_submission.csv') \n",
    "\n",
    "품목_리스트 = ['potato', 'garlic', 'apple', 'lettuce', 'pepper', 'daepa', 'moo', 'cabbage', 'onion', 'pear']\n",
    "\n",
    "# 각 품목별로 예측 결과를 dl_model1과 dl_model2에 업데이트\n",
    "for item in 품목_리스트:\n",
    "    # 동적으로 '_preds1'와 '_preds2' 변수를 참조\n",
    "    preds1 = eval(f\"{item}_preds1\")\n",
    "    preds2 = eval(f\"{item}_preds2\")\n",
    "    \n",
    "    # preds1의 예측값을 dl_model1에 추가\n",
    "    for sub_item, prices in preds1.items():\n",
    "        if sub_item in dl_model1.columns:\n",
    "            dl_model1[sub_item] = prices\n",
    "\n",
    "    # preds2의 예측값을 dl_model2에 추가\n",
    "    for sub_item, prices in preds2.items():\n",
    "        if sub_item in dl_model2.columns:\n",
    "            dl_model2[sub_item] = prices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
